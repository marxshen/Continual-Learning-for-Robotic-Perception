WARNING - core50 incremental finetuning - No observers have been added to this run
INFO - core50 incremental finetuning - Running command 'main'
INFO - core50 incremental finetuning - Started
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0405 18:42:50.655922  1665 solver.cpp:44] Initializing solver from parameters: 
test_iter: 0
test_interval: 469
base_lr: 0.1
display: 225
max_iter: 1800
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 1800
snapshot_prefix: "data/snapshots/train_batch_00"
solver_mode: GPU
random_seed: 0
net: "confs/sII/mid-caffeNet/inc_train_val.prototxt"
test_initialization: false
snapshot_format: HDF5
I0405 18:42:50.659096  1665 solver.cpp:87] Creating training net from net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 18:42:50.660146  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 18:42:50.660248  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 18:42:50.660351  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0405 18:42:50.660418  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0405 18:42:50.660776  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/train_batch_00_filelist.txt"
    batch_size: 256
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I0405 18:42:50.661028  1665 layer_factory.hpp:77] Creating layer data
I0405 18:42:50.661144  1665 net.cpp:84] Creating Layer data
I0405 18:42:50.661214  1665 net.cpp:380] data -> data
I0405 18:42:50.661274  1665 net.cpp:380] data -> label
I0405 18:42:50.661329  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/train_batch_00_filelist.txt
I0405 18:42:50.665768  1665 image_data_layer.cpp:53] Shuffling data
I0405 18:42:50.666329  1665 image_data_layer.cpp:63] A total of 23980 images.
I0405 18:42:50.671357  1665 image_data_layer.cpp:90] output data size: 256,3,128,128
I0405 18:42:50.798693  1665 net.cpp:122] Setting up data
I0405 18:42:50.798956  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 18:42:50.799034  1665 net.cpp:129] Top shape: 256 (256)
I0405 18:42:50.799096  1665 net.cpp:137] Memory required for data: 50332672
I0405 18:42:50.799160  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 18:42:50.799239  1665 net.cpp:84] Creating Layer data_bn
I0405 18:42:50.799302  1665 net.cpp:406] data_bn <- data
I0405 18:42:50.799408  1665 net.cpp:380] data_bn -> data_bn
I0405 18:42:50.799652  1665 net.cpp:122] Setting up data_bn
I0405 18:42:50.799777  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 18:42:50.799839  1665 net.cpp:137] Memory required for data: 100664320
I0405 18:42:50.799914  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 18:42:50.799981  1665 net.cpp:84] Creating Layer data_scale
I0405 18:42:50.800060  1665 net.cpp:406] data_scale <- data_bn
I0405 18:42:50.800122  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 18:42:50.804517  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 18:42:50.804811  1665 net.cpp:122] Setting up data_scale
I0405 18:42:50.804903  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 18:42:50.804957  1665 net.cpp:137] Memory required for data: 150995968
I0405 18:42:50.805016  1665 layer_factory.hpp:77] Creating layer conv1
I0405 18:42:50.805078  1665 net.cpp:84] Creating Layer conv1
I0405 18:42:50.805137  1665 net.cpp:406] conv1 <- data_bn
I0405 18:42:50.805192  1665 net.cpp:380] conv1 -> conv1
I0405 18:42:50.805474  1665 net.cpp:122] Setting up conv1
I0405 18:42:50.805534  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 18:42:50.805586  1665 net.cpp:137] Memory required for data: 419431424
I0405 18:42:50.805640  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 18:42:50.805696  1665 net.cpp:84] Creating Layer conv1_bn
I0405 18:42:50.805773  1665 net.cpp:406] conv1_bn <- conv1
I0405 18:42:50.805824  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 18:42:50.805999  1665 net.cpp:122] Setting up conv1_bn
I0405 18:42:50.806066  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 18:42:50.806118  1665 net.cpp:137] Memory required for data: 687866880
I0405 18:42:50.806183  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 18:42:50.806242  1665 net.cpp:84] Creating Layer conv1_scale
I0405 18:42:50.806295  1665 net.cpp:406] conv1_scale <- conv1
I0405 18:42:50.806352  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 18:42:50.806442  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 18:42:50.806573  1665 net.cpp:122] Setting up conv1_scale
I0405 18:42:50.806645  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 18:42:50.806700  1665 net.cpp:137] Memory required for data: 956302336
I0405 18:42:50.806763  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 18:42:50.806814  1665 net.cpp:84] Creating Layer conv1_relu
I0405 18:42:50.806862  1665 net.cpp:406] conv1_relu <- conv1
I0405 18:42:50.806908  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 18:42:50.806958  1665 net.cpp:122] Setting up conv1_relu
I0405 18:42:50.807008  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 18:42:50.807055  1665 net.cpp:137] Memory required for data: 1224737792
I0405 18:42:50.807101  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 18:42:50.807149  1665 net.cpp:84] Creating Layer conv1_pool
I0405 18:42:50.807196  1665 net.cpp:406] conv1_pool <- conv1
I0405 18:42:50.807260  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 18:42:50.807328  1665 net.cpp:122] Setting up conv1_pool
I0405 18:42:50.807379  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:42:50.807425  1665 net.cpp:137] Memory required for data: 1291846656
I0405 18:42:50.807469  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 18:42:50.807518  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 18:42:50.807574  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 18:42:50.807633  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 18:42:50.807682  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 18:42:50.807780  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 18:42:50.807838  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:42:50.807893  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:42:50.807942  1665 net.cpp:137] Memory required for data: 1426064384
I0405 18:42:50.807992  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 18:42:50.808046  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 18:42:50.808099  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 18:42:50.808151  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 18:42:50.808593  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 18:42:50.808676  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:42:50.808754  1665 net.cpp:137] Memory required for data: 1493173248
I0405 18:42:50.808806  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 18:42:50.808859  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 18:42:50.808913  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 18:42:50.808969  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 18:42:50.809136  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 18:42:50.809204  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:42:50.809255  1665 net.cpp:137] Memory required for data: 1560282112
I0405 18:42:50.809309  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 18:42:50.809372  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 18:42:50.809424  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 18:42:50.809475  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 18:42:50.809551  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 18:42:50.809674  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 18:42:50.809742  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:42:50.809798  1665 net.cpp:137] Memory required for data: 1627390976
I0405 18:42:50.809851  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 18:42:50.809903  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 18:42:50.809954  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 18:42:50.810010  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 18:42:50.810065  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 18:42:50.810120  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:42:50.810173  1665 net.cpp:137] Memory required for data: 1694499840
I0405 18:42:50.810230  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 18:42:50.810283  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 18:42:50.810334  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 18:42:50.810390  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 18:42:50.810847  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 18:42:50.810925  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:42:50.810973  1665 net.cpp:137] Memory required for data: 1761608704
I0405 18:42:50.811022  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 18:42:50.811072  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 18:42:50.811121  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 18:42:50.811168  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 18:42:50.811219  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 18:42:50.811276  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 18:42:50.811326  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:42:50.811375  1665 net.cpp:137] Memory required for data: 1828717568
I0405 18:42:50.811421  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 18:42:50.811470  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 18:42:50.811527  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 18:42:50.811574  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 18:42:50.811762  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 18:42:50.811825  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:42:50.811882  1665 net.cpp:137] Memory required for data: 1895826432
I0405 18:42:50.811933  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 18:42:50.811985  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 18:42:50.812032  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 18:42:50.812080  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 18:42:50.812152  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 18:42:50.812273  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 18:42:50.812337  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:42:50.812386  1665 net.cpp:137] Memory required for data: 1962935296
I0405 18:42:50.812434  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 18:42:50.812485  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 18:42:50.812534  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 18:42:50.812580  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 18:42:50.812651  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 18:42:50.812701  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:42:50.812775  1665 net.cpp:137] Memory required for data: 2030044160
I0405 18:42:50.812829  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 18:42:50.812885  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 18:42:50.812945  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 18:42:50.813004  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 18:42:50.813060  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 18:42:50.813138  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 18:42:50.813196  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:42:50.813253  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:42:50.813304  1665 net.cpp:137] Memory required for data: 2164261888
I0405 18:42:50.813355  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 18:42:50.813416  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 18:42:50.813467  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 18:42:50.813519  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 18:42:50.814270  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 18:42:50.814357  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:42:50.814424  1665 net.cpp:137] Memory required for data: 2197816320
I0405 18:42:50.814477  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 18:42:50.814543  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 18:42:50.814592  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 18:42:50.814644  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 18:42:50.814828  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 18:42:50.814891  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:42:50.814944  1665 net.cpp:137] Memory required for data: 2231370752
I0405 18:42:50.815002  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 18:42:50.815058  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 18:42:50.815244  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 18:42:50.815302  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 18:42:50.815372  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 18:42:50.815495  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 18:42:50.815558  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:42:50.815623  1665 net.cpp:137] Memory required for data: 2264925184
I0405 18:42:50.815676  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 18:42:50.815749  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 18:42:50.815796  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 18:42:50.815843  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 18:42:50.815893  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 18:42:50.815950  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:42:50.816009  1665 net.cpp:137] Memory required for data: 2298479616
I0405 18:42:50.816051  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 18:42:50.816099  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 18:42:50.816148  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 18:42:50.816195  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 18:42:50.817534  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 18:42:50.817620  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:42:50.817672  1665 net.cpp:137] Memory required for data: 2332034048
I0405 18:42:50.817739  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 18:42:50.817816  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 18:42:50.817874  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 18:42:50.817931  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 18:42:50.818154  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 18:42:50.818226  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:42:50.818279  1665 net.cpp:137] Memory required for data: 2365588480
I0405 18:42:50.818333  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 18:42:50.818387  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 18:42:50.818439  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 18:42:50.818501  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 18:42:50.818554  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 18:42:50.818616  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 18:42:50.818671  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:42:50.818744  1665 net.cpp:137] Memory required for data: 2399142912
I0405 18:42:50.818820  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 18:42:50.818881  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 18:42:50.818997  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 18:42:50.819095  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 18:42:50.819289  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 18:42:50.819360  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:42:50.819412  1665 net.cpp:137] Memory required for data: 2432697344
I0405 18:42:50.819483  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 18:42:50.819548  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 18:42:50.819599  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 18:42:50.819651  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 18:42:50.819734  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 18:42:50.819846  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 18:42:50.819960  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:42:50.820019  1665 net.cpp:137] Memory required for data: 2466251776
I0405 18:42:50.820070  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 18:42:50.820123  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 18:42:50.820174  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 18:42:50.820230  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 18:42:50.820286  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 18:42:50.820338  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:42:50.820386  1665 net.cpp:137] Memory required for data: 2499806208
I0405 18:42:50.820436  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 18:42:50.820489  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 18:42:50.820552  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 18:42:50.820600  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 18:42:50.820650  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 18:42:50.820729  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 18:42:50.820832  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:42:50.820888  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:42:50.820945  1665 net.cpp:137] Memory required for data: 2566915072
I0405 18:42:50.820998  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 18:42:50.821063  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 18:42:50.821111  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 18:42:50.821169  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 18:42:50.824740  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 18:42:50.824842  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:42:50.824898  1665 net.cpp:137] Memory required for data: 2583692288
I0405 18:42:50.824950  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 18:42:50.825006  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 18:42:50.825057  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 18:42:50.825127  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 18:42:50.825302  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 18:42:50.825369  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:42:50.825417  1665 net.cpp:137] Memory required for data: 2600469504
I0405 18:42:50.825465  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 18:42:50.825517  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 18:42:50.825567  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 18:42:50.825625  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 18:42:50.825700  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 18:42:50.825821  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 18:42:50.825897  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:42:50.825947  1665 net.cpp:137] Memory required for data: 2617246720
I0405 18:42:50.825995  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 18:42:50.826045  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 18:42:50.826094  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 18:42:50.826140  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 18:42:50.826187  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 18:42:50.826234  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:42:50.826282  1665 net.cpp:137] Memory required for data: 2634023936
I0405 18:42:50.826329  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 18:42:50.826380  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 18:42:50.826436  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 18:42:50.826483  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 18:42:50.832113  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 18:42:50.832206  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:42:50.832257  1665 net.cpp:137] Memory required for data: 2650801152
I0405 18:42:50.832315  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 18:42:50.832363  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 18:42:50.832417  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 18:42:50.832468  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 18:42:50.832921  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 18:42:50.833005  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:42:50.833057  1665 net.cpp:137] Memory required for data: 2667578368
I0405 18:42:50.833106  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 18:42:50.833180  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 18:42:50.833245  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 18:42:50.833304  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 18:42:50.833364  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 18:42:50.833423  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 18:42:50.833477  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:42:50.833523  1665 net.cpp:137] Memory required for data: 2684355584
I0405 18:42:50.833570  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 18:42:50.833617  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 18:42:50.833667  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 18:42:50.833707  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 18:42:50.833885  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 18:42:50.833952  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:42:50.833998  1665 net.cpp:137] Memory required for data: 2701132800
I0405 18:42:50.834058  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 18:42:50.834110  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 18:42:50.834157  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 18:42:50.834203  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 18:42:50.834277  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 18:42:50.834399  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 18:42:50.834450  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:42:50.834498  1665 net.cpp:137] Memory required for data: 2717910016
I0405 18:42:50.834547  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 18:42:50.834597  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 18:42:50.834646  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 18:42:50.834694  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 18:42:50.834744  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 18:42:50.834795  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:42:50.834843  1665 net.cpp:137] Memory required for data: 2734687232
I0405 18:42:50.834890  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 18:42:50.834939  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 18:42:50.834988  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 18:42:50.835036  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 18:42:50.835086  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 18:42:50.835158  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 18:42:50.835213  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:42:50.835259  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:42:50.835306  1665 net.cpp:137] Memory required for data: 2768241664
I0405 18:42:50.835351  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 18:42:50.835400  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 18:42:50.835459  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 18:42:50.835518  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 18:42:50.846299  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 18:42:50.846411  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:42:50.846485  1665 net.cpp:137] Memory required for data: 2776630272
I0405 18:42:50.846541  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 18:42:50.846599  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 18:42:50.846654  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 18:42:50.846711  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 18:42:50.846922  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 18:42:50.846993  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:42:50.847045  1665 net.cpp:137] Memory required for data: 2785018880
I0405 18:42:50.847101  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 18:42:50.847157  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 18:42:50.847213  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 18:42:50.847265  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 18:42:50.847334  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 18:42:50.847455  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 18:42:50.847523  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:42:50.847585  1665 net.cpp:137] Memory required for data: 2793407488
I0405 18:42:50.847640  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 18:42:50.847700  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 18:42:50.847764  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 18:42:50.847818  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 18:42:50.847874  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 18:42:50.847932  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:42:50.847991  1665 net.cpp:137] Memory required for data: 2801796096
I0405 18:42:50.848054  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 18:42:50.848107  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 18:42:50.848158  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 18:42:50.848233  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 18:42:50.869539  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 18:42:50.869642  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:42:50.869696  1665 net.cpp:137] Memory required for data: 2810184704
I0405 18:42:50.869753  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 18:42:50.869810  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 18:42:50.869863  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 18:42:50.869917  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 18:42:50.871125  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 18:42:50.871212  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:42:50.871265  1665 net.cpp:137] Memory required for data: 2818573312
I0405 18:42:50.871320  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 18:42:50.871373  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 18:42:50.871426  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 18:42:50.871479  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 18:42:50.871533  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 18:42:50.871598  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 18:42:50.871665  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:42:50.871726  1665 net.cpp:137] Memory required for data: 2826961920
I0405 18:42:50.871780  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 18:42:50.871832  1665 net.cpp:84] Creating Layer last_bn
I0405 18:42:50.871896  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 18:42:50.871948  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 18:42:50.872115  1665 net.cpp:122] Setting up last_bn
I0405 18:42:50.872179  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:42:50.872242  1665 net.cpp:137] Memory required for data: 2835350528
I0405 18:42:50.872294  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 18:42:50.872349  1665 net.cpp:84] Creating Layer last_scale
I0405 18:42:50.872400  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 18:42:50.872452  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 18:42:50.872520  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 18:42:50.872630  1665 net.cpp:122] Setting up last_scale
I0405 18:42:50.872696  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:42:50.872754  1665 net.cpp:137] Memory required for data: 2843739136
I0405 18:42:50.872815  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 18:42:50.872869  1665 net.cpp:84] Creating Layer last_relu
I0405 18:42:50.872923  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 18:42:50.872993  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 18:42:50.873046  1665 net.cpp:122] Setting up last_relu
I0405 18:42:50.873100  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:42:50.873153  1665 net.cpp:137] Memory required for data: 2852127744
I0405 18:42:50.873205  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 18:42:50.873268  1665 net.cpp:84] Creating Layer global_pool
I0405 18:42:50.873333  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 18:42:50.873389  1665 net.cpp:380] global_pool -> global_pool
I0405 18:42:50.873450  1665 net.cpp:122] Setting up global_pool
I0405 18:42:50.873507  1665 net.cpp:129] Top shape: 256 512 1 1 (131072)
I0405 18:42:50.873561  1665 net.cpp:137] Memory required for data: 2852652032
I0405 18:42:50.873612  1665 layer_factory.hpp:77] Creating layer score
I0405 18:42:50.873667  1665 net.cpp:84] Creating Layer score
I0405 18:42:50.873720  1665 net.cpp:406] score <- global_pool
I0405 18:42:50.873769  1665 net.cpp:380] score -> score
I0405 18:42:50.875062  1665 net.cpp:122] Setting up score
I0405 18:42:50.875139  1665 net.cpp:129] Top shape: 256 1000 (256000)
I0405 18:42:50.875196  1665 net.cpp:137] Memory required for data: 2853676032
I0405 18:42:50.875273  1665 layer_factory.hpp:77] Creating layer loss
I0405 18:42:50.875341  1665 net.cpp:84] Creating Layer loss
I0405 18:42:50.875396  1665 net.cpp:406] loss <- score
I0405 18:42:50.875448  1665 net.cpp:406] loss <- label
I0405 18:42:50.875502  1665 net.cpp:380] loss -> loss
I0405 18:42:50.875564  1665 layer_factory.hpp:77] Creating layer loss
I0405 18:42:50.877038  1665 net.cpp:122] Setting up loss
I0405 18:42:50.877143  1665 net.cpp:129] Top shape: (1)
I0405 18:42:50.877203  1665 net.cpp:132]     with loss weight 1
I0405 18:42:50.877275  1665 net.cpp:137] Memory required for data: 2853676036
I0405 18:42:50.877329  1665 net.cpp:198] loss needs backward computation.
I0405 18:42:50.877383  1665 net.cpp:198] score needs backward computation.
I0405 18:42:50.877436  1665 net.cpp:198] global_pool needs backward computation.
I0405 18:42:50.877498  1665 net.cpp:198] last_relu needs backward computation.
I0405 18:42:50.877552  1665 net.cpp:198] last_scale needs backward computation.
I0405 18:42:50.877602  1665 net.cpp:198] last_bn needs backward computation.
I0405 18:42:50.877653  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 18:42:50.877705  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 18:42:50.877786  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 18:42:50.877844  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 18:42:50.877894  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 18:42:50.877943  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 18:42:50.877990  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 18:42:50.878036  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 18:42:50.878083  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 18:42:50.878129  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 18:42:50.878176  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 18:42:50.878228  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 18:42:50.878275  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 18:42:50.878325  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 18:42:50.878372  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 18:42:50.878422  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 18:42:50.878468  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 18:42:50.878531  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 18:42:50.878579  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 18:42:50.878624  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 18:42:50.878669  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 18:42:50.878732  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 18:42:50.878796  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 18:42:50.878849  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 18:42:50.878906  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 18:42:50.878955  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 18:42:50.879004  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 18:42:50.879050  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 18:42:50.879097  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 18:42:50.879148  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 18:42:50.879195  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 18:42:50.879254  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 18:42:50.879300  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 18:42:50.879348  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 18:42:50.879388  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 18:42:50.879448  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 18:42:50.879496  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 18:42:50.879544  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 18:42:50.879606  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 18:42:50.879653  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 18:42:50.879699  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 18:42:50.879766  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 18:42:50.879817  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 18:42:50.879878  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 18:42:50.879940  1665 net.cpp:198] conv1 needs backward computation.
I0405 18:42:50.879990  1665 net.cpp:198] data_scale needs backward computation.
I0405 18:42:50.880043  1665 net.cpp:200] data_bn does not need backward computation.
I0405 18:42:50.880093  1665 net.cpp:200] data does not need backward computation.
I0405 18:42:50.880141  1665 net.cpp:242] This network produces output loss
I0405 18:42:50.880213  1665 net.cpp:255] Network initialization done.
I0405 18:42:50.881852  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 18:42:50.881995  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 18:42:50.882045  1665 solver.cpp:172] Creating test net (#0) specified by net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 18:42:50.882144  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 18:42:50.882565  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 18:42:50.882856  1665 layer_factory.hpp:77] Creating layer data
I0405 18:42:50.882926  1665 net.cpp:84] Creating Layer data
I0405 18:42:50.882973  1665 net.cpp:380] data -> data
I0405 18:42:50.883020  1665 net.cpp:380] data -> label
I0405 18:42:50.883065  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 18:42:50.890069  1665 image_data_layer.cpp:53] Shuffling data
I0405 18:42:50.891185  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 18:42:50.891914  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 18:42:50.937906  1665 net.cpp:122] Setting up data
I0405 18:42:50.938009  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 18:42:50.938073  1665 net.cpp:129] Top shape: 100 (100)
I0405 18:42:50.938134  1665 net.cpp:137] Memory required for data: 19661200
I0405 18:42:50.938177  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 18:42:50.938246  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 18:42:50.938299  1665 net.cpp:406] label_data_1_split <- label
I0405 18:42:50.938364  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 18:42:50.938424  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 18:42:50.938524  1665 net.cpp:122] Setting up label_data_1_split
I0405 18:42:50.938573  1665 net.cpp:129] Top shape: 100 (100)
I0405 18:42:50.938621  1665 net.cpp:129] Top shape: 100 (100)
I0405 18:42:50.938673  1665 net.cpp:137] Memory required for data: 19662000
I0405 18:42:50.938746  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 18:42:50.938807  1665 net.cpp:84] Creating Layer data_bn
I0405 18:42:50.938858  1665 net.cpp:406] data_bn <- data
I0405 18:42:50.938910  1665 net.cpp:380] data_bn -> data_bn
I0405 18:42:50.939254  1665 net.cpp:122] Setting up data_bn
I0405 18:42:50.939323  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 18:42:50.939388  1665 net.cpp:137] Memory required for data: 39322800
I0405 18:42:50.939466  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 18:42:50.939523  1665 net.cpp:84] Creating Layer data_scale
I0405 18:42:50.939574  1665 net.cpp:406] data_scale <- data_bn
I0405 18:42:50.939627  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 18:42:50.939705  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 18:42:50.939878  1665 net.cpp:122] Setting up data_scale
I0405 18:42:50.939934  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 18:42:50.939983  1665 net.cpp:137] Memory required for data: 58983600
I0405 18:42:50.940037  1665 layer_factory.hpp:77] Creating layer conv1
I0405 18:42:50.940095  1665 net.cpp:84] Creating Layer conv1
I0405 18:42:50.940145  1665 net.cpp:406] conv1 <- data_bn
I0405 18:42:50.940212  1665 net.cpp:380] conv1 -> conv1
I0405 18:42:50.940518  1665 net.cpp:122] Setting up conv1
I0405 18:42:50.940579  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 18:42:50.940631  1665 net.cpp:137] Memory required for data: 163841200
I0405 18:42:50.940685  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 18:42:50.940755  1665 net.cpp:84] Creating Layer conv1_bn
I0405 18:42:50.940806  1665 net.cpp:406] conv1_bn <- conv1
I0405 18:42:50.940857  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 18:42:50.941125  1665 net.cpp:122] Setting up conv1_bn
I0405 18:42:50.941186  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 18:42:50.941272  1665 net.cpp:137] Memory required for data: 268698800
I0405 18:42:50.941330  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 18:42:50.941381  1665 net.cpp:84] Creating Layer conv1_scale
I0405 18:42:50.941431  1665 net.cpp:406] conv1_scale <- conv1
I0405 18:42:50.941481  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 18:42:50.941566  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 18:42:50.941689  1665 net.cpp:122] Setting up conv1_scale
I0405 18:42:50.941771  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 18:42:50.941824  1665 net.cpp:137] Memory required for data: 373556400
I0405 18:42:50.941876  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 18:42:50.941929  1665 net.cpp:84] Creating Layer conv1_relu
I0405 18:42:50.941979  1665 net.cpp:406] conv1_relu <- conv1
I0405 18:42:50.942029  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 18:42:50.942088  1665 net.cpp:122] Setting up conv1_relu
I0405 18:42:50.942142  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 18:42:50.942191  1665 net.cpp:137] Memory required for data: 478414000
I0405 18:42:50.942250  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 18:42:50.942345  1665 net.cpp:84] Creating Layer conv1_pool
I0405 18:42:50.942399  1665 net.cpp:406] conv1_pool <- conv1
I0405 18:42:50.942456  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 18:42:50.942548  1665 net.cpp:122] Setting up conv1_pool
I0405 18:42:50.942603  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:42:50.942665  1665 net.cpp:137] Memory required for data: 504628400
I0405 18:42:50.942740  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 18:42:50.942800  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 18:42:50.942852  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 18:42:50.942922  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 18:42:50.942975  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 18:42:50.943048  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 18:42:50.943100  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:42:50.943153  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:42:50.943205  1665 net.cpp:137] Memory required for data: 557057200
I0405 18:42:50.943255  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 18:42:50.943310  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 18:42:50.943359  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 18:42:50.943410  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 18:42:50.943903  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 18:42:50.943972  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:42:50.944028  1665 net.cpp:137] Memory required for data: 583271600
I0405 18:42:50.944082  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 18:42:50.944135  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 18:42:50.944187  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 18:42:50.944239  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 18:42:50.945739  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 18:42:50.945855  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:42:50.945945  1665 net.cpp:137] Memory required for data: 609486000
I0405 18:42:50.946012  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 18:42:50.946079  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 18:42:50.946156  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 18:42:50.946225  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 18:42:50.946332  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 18:42:50.946501  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 18:42:50.946588  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:42:50.946642  1665 net.cpp:137] Memory required for data: 635700400
I0405 18:42:50.946709  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 18:42:50.946786  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 18:42:50.946854  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 18:42:50.946910  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 18:42:50.946974  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 18:42:50.947036  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:42:50.947100  1665 net.cpp:137] Memory required for data: 661914800
I0405 18:42:50.947172  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 18:42:50.947238  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 18:42:50.947299  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 18:42:50.947360  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 18:42:50.947871  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 18:42:50.947976  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:42:50.948038  1665 net.cpp:137] Memory required for data: 688129200
I0405 18:42:50.948096  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 18:42:50.948158  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 18:42:50.948215  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 18:42:50.948273  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 18:42:50.948362  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 18:42:50.948441  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 18:42:50.948520  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:42:50.948576  1665 net.cpp:137] Memory required for data: 714343600
I0405 18:42:50.948637  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 18:42:50.948712  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 18:42:50.948791  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 18:42:50.948873  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 18:42:50.949086  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 18:42:50.949172  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:42:50.949256  1665 net.cpp:137] Memory required for data: 740558000
I0405 18:42:50.949322  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 18:42:50.949395  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 18:42:50.949455  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 18:42:50.949528  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 18:42:50.949626  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 18:42:50.949801  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 18:42:50.949887  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:42:50.949947  1665 net.cpp:137] Memory required for data: 766772400
I0405 18:42:50.950011  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 18:42:50.950073  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 18:42:50.950134  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 18:42:50.950193  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 18:42:50.950261  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 18:42:50.950325  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:42:50.950388  1665 net.cpp:137] Memory required for data: 792986800
I0405 18:42:50.950448  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 18:42:50.950510  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 18:42:50.950572  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 18:42:50.950646  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 18:42:50.950732  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 18:42:50.950832  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 18:42:50.950893  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:42:50.950954  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:42:50.951012  1665 net.cpp:137] Memory required for data: 845415600
I0405 18:42:50.951071  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 18:42:50.951134  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 18:42:50.951195  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 18:42:50.951275  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 18:42:50.952252  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 18:42:50.952352  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:42:50.952427  1665 net.cpp:137] Memory required for data: 858522800
I0405 18:42:50.952499  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 18:42:50.952559  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 18:42:50.952632  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 18:42:50.952690  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 18:42:50.952926  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 18:42:50.953023  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:42:50.953075  1665 net.cpp:137] Memory required for data: 871630000
I0405 18:42:50.953138  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 18:42:50.953207  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 18:42:50.953269  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 18:42:50.953330  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 18:42:50.953424  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 18:42:50.953584  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 18:42:50.953665  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:42:50.953750  1665 net.cpp:137] Memory required for data: 884737200
I0405 18:42:50.953820  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 18:42:50.953883  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 18:42:50.953944  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 18:42:50.954005  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 18:42:50.954084  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 18:42:50.954172  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:42:50.954452  1665 net.cpp:137] Memory required for data: 897844400
I0405 18:42:50.954551  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 18:42:50.954619  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 18:42:50.954680  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 18:42:50.954756  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 18:42:50.956369  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 18:42:50.956445  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:42:50.956503  1665 net.cpp:137] Memory required for data: 910951600
I0405 18:42:50.956560  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 18:42:50.956622  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 18:42:50.956678  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 18:42:50.956761  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 18:42:50.957016  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 18:42:50.957123  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:42:50.957186  1665 net.cpp:137] Memory required for data: 924058800
I0405 18:42:50.957243  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 18:42:50.957314  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 18:42:50.957371  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 18:42:50.957432  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 18:42:50.957515  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 18:42:50.957600  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 18:42:50.957675  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:42:50.957744  1665 net.cpp:137] Memory required for data: 937166000
I0405 18:42:50.957800  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 18:42:50.957859  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 18:42:50.957916  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 18:42:50.957975  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 18:42:50.958176  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 18:42:50.958292  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:42:50.958344  1665 net.cpp:137] Memory required for data: 950273200
I0405 18:42:50.958406  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 18:42:50.958464  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 18:42:50.958528  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 18:42:50.958614  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 18:42:50.958734  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 18:42:50.958876  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 18:42:50.958957  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:42:50.959013  1665 net.cpp:137] Memory required for data: 963380400
I0405 18:42:50.959071  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 18:42:50.959132  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 18:42:50.959188  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 18:42:50.959246  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 18:42:50.959303  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 18:42:50.959372  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:42:50.959444  1665 net.cpp:137] Memory required for data: 976487600
I0405 18:42:50.959503  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 18:42:50.959558  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 18:42:50.959612  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 18:42:50.959672  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 18:42:50.959749  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 18:42:50.959836  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 18:42:50.959905  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:42:50.959964  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:42:50.960019  1665 net.cpp:137] Memory required for data: 1002702000
I0405 18:42:50.960083  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 18:42:50.960140  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 18:42:50.960194  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 18:42:50.960278  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 18:42:50.964257  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 18:42:50.964352  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:42:50.964424  1665 net.cpp:137] Memory required for data: 1009255600
I0405 18:42:50.964481  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 18:42:50.964542  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 18:42:50.964601  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 18:42:50.964660  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 18:42:50.964890  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 18:42:50.964993  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:42:50.965049  1665 net.cpp:137] Memory required for data: 1015809200
I0405 18:42:50.965106  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 18:42:50.965165  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 18:42:50.965231  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 18:42:50.965286  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 18:42:50.965384  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 18:42:50.965555  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 18:42:50.965623  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:42:50.965680  1665 net.cpp:137] Memory required for data: 1022362800
I0405 18:42:50.965762  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 18:42:50.965822  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 18:42:50.965878  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 18:42:50.965935  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 18:42:50.965994  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 18:42:50.966053  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:42:50.966107  1665 net.cpp:137] Memory required for data: 1028916400
I0405 18:42:50.966159  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 18:42:50.966219  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 18:42:50.966279  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 18:42:50.966338  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 18:42:50.972906  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 18:42:50.973006  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:42:50.973064  1665 net.cpp:137] Memory required for data: 1035470000
I0405 18:42:50.973146  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 18:42:50.973228  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 18:42:50.973302  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 18:42:50.973361  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 18:42:50.973927  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 18:42:50.974020  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:42:50.974078  1665 net.cpp:137] Memory required for data: 1042023600
I0405 18:42:50.974136  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 18:42:50.974202  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 18:42:50.974262  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 18:42:50.974320  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 18:42:50.974380  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 18:42:50.974459  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 18:42:50.974539  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:42:50.974597  1665 net.cpp:137] Memory required for data: 1048577200
I0405 18:42:50.974654  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 18:42:50.974735  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 18:42:50.974793  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 18:42:50.974851  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 18:42:50.975054  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 18:42:50.975140  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:42:50.975203  1665 net.cpp:137] Memory required for data: 1055130800
I0405 18:42:50.975262  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 18:42:50.975334  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 18:42:50.975385  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 18:42:50.975448  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 18:42:50.975536  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 18:42:50.975694  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 18:42:50.975793  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:42:50.975849  1665 net.cpp:137] Memory required for data: 1061684400
I0405 18:42:50.975908  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 18:42:50.975966  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 18:42:50.976022  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 18:42:50.976079  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 18:42:50.976136  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 18:42:50.976193  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:42:50.976255  1665 net.cpp:137] Memory required for data: 1068238000
I0405 18:42:50.976310  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 18:42:50.976367  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 18:42:50.976423  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 18:42:50.976485  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 18:42:50.976545  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 18:42:50.976636  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 18:42:50.976697  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:42:50.976781  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:42:50.976864  1665 net.cpp:137] Memory required for data: 1081345200
I0405 18:42:50.976920  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 18:42:50.976982  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 18:42:50.977038  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 18:42:50.977095  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 18:42:50.989635  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 18:42:50.989749  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:42:50.989810  1665 net.cpp:137] Memory required for data: 1084622000
I0405 18:42:50.989869  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 18:42:50.989929  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 18:42:50.989986  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 18:42:50.990046  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 18:42:50.990264  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 18:42:50.990342  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:42:50.990398  1665 net.cpp:137] Memory required for data: 1087898800
I0405 18:42:50.990466  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 18:42:50.990523  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 18:42:50.990597  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 18:42:50.990655  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 18:42:50.990762  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 18:42:50.990917  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 18:42:50.990978  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:42:50.991034  1665 net.cpp:137] Memory required for data: 1091175600
I0405 18:42:50.991093  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 18:42:50.991151  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 18:42:50.991225  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 18:42:50.991279  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 18:42:50.991353  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 18:42:50.991410  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:42:50.991466  1665 net.cpp:137] Memory required for data: 1094452400
I0405 18:42:50.991521  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 18:42:50.991587  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 18:42:50.991659  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 18:42:50.991771  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 18:42:51.017668  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 18:42:51.017798  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:42:51.017889  1665 net.cpp:137] Memory required for data: 1097729200
I0405 18:42:51.017951  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 18:42:51.018018  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 18:42:51.018095  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 18:42:51.018168  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 18:42:51.019680  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 18:42:51.019814  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:42:51.019887  1665 net.cpp:137] Memory required for data: 1101006000
I0405 18:42:51.019961  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 18:42:51.020015  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 18:42:51.020076  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 18:42:51.020138  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 18:42:51.020206  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 18:42:51.020298  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 18:42:51.020360  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:42:51.020419  1665 net.cpp:137] Memory required for data: 1104282800
I0405 18:42:51.020478  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 18:42:51.020541  1665 net.cpp:84] Creating Layer last_bn
I0405 18:42:51.020601  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 18:42:51.020661  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 18:42:51.020879  1665 net.cpp:122] Setting up last_bn
I0405 18:42:51.020958  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:42:51.021020  1665 net.cpp:137] Memory required for data: 1107559600
I0405 18:42:51.021098  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 18:42:51.021153  1665 net.cpp:84] Creating Layer last_scale
I0405 18:42:51.021205  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 18:42:51.021260  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 18:42:51.021368  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 18:42:51.021514  1665 net.cpp:122] Setting up last_scale
I0405 18:42:51.021591  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:42:51.021644  1665 net.cpp:137] Memory required for data: 1110836400
I0405 18:42:51.021698  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 18:42:51.022451  1665 net.cpp:84] Creating Layer last_relu
I0405 18:42:51.022545  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 18:42:51.022612  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 18:42:51.022676  1665 net.cpp:122] Setting up last_relu
I0405 18:42:51.022763  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:42:51.022866  1665 net.cpp:137] Memory required for data: 1114113200
I0405 18:42:51.022951  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 18:42:51.023010  1665 net.cpp:84] Creating Layer global_pool
I0405 18:42:51.023069  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 18:42:51.023130  1665 net.cpp:380] global_pool -> global_pool
I0405 18:42:51.023232  1665 net.cpp:122] Setting up global_pool
I0405 18:42:51.023298  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 18:42:51.023360  1665 net.cpp:137] Memory required for data: 1114318000
I0405 18:42:51.023418  1665 layer_factory.hpp:77] Creating layer score
I0405 18:42:51.023479  1665 net.cpp:84] Creating Layer score
I0405 18:42:51.023540  1665 net.cpp:406] score <- global_pool
I0405 18:42:51.023600  1665 net.cpp:380] score -> score
I0405 18:42:51.025032  1665 net.cpp:122] Setting up score
I0405 18:42:51.025133  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 18:42:51.025208  1665 net.cpp:137] Memory required for data: 1114718000
I0405 18:42:51.025290  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 18:42:51.025347  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 18:42:51.025401  1665 net.cpp:406] score_score_0_split <- score
I0405 18:42:51.025454  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 18:42:51.025511  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 18:42:51.025600  1665 net.cpp:122] Setting up score_score_0_split
I0405 18:42:51.025671  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 18:42:51.025754  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 18:42:51.025808  1665 net.cpp:137] Memory required for data: 1115518000
I0405 18:42:51.025861  1665 layer_factory.hpp:77] Creating layer loss
I0405 18:42:51.025914  1665 net.cpp:84] Creating Layer loss
I0405 18:42:51.025980  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 18:42:51.026033  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 18:42:51.026093  1665 net.cpp:380] loss -> loss
I0405 18:42:51.026149  1665 layer_factory.hpp:77] Creating layer loss
I0405 18:42:51.027341  1665 net.cpp:122] Setting up loss
I0405 18:42:51.027441  1665 net.cpp:129] Top shape: (1)
I0405 18:42:51.027529  1665 net.cpp:132]     with loss weight 1
I0405 18:42:51.027613  1665 net.cpp:137] Memory required for data: 1115518004
I0405 18:42:51.027667  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 18:42:51.027748  1665 net.cpp:84] Creating Layer accuracy
I0405 18:42:51.027803  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 18:42:51.027856  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 18:42:51.027910  1665 net.cpp:380] accuracy -> accuracy
I0405 18:42:51.027967  1665 net.cpp:122] Setting up accuracy
I0405 18:42:51.028021  1665 net.cpp:129] Top shape: (1)
I0405 18:42:51.028072  1665 net.cpp:137] Memory required for data: 1115518008
I0405 18:42:51.028123  1665 net.cpp:200] accuracy does not need backward computation.
I0405 18:42:51.028177  1665 net.cpp:198] loss needs backward computation.
I0405 18:42:51.028234  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 18:42:51.028286  1665 net.cpp:198] score needs backward computation.
I0405 18:42:51.028349  1665 net.cpp:198] global_pool needs backward computation.
I0405 18:42:51.028421  1665 net.cpp:198] last_relu needs backward computation.
I0405 18:42:51.028481  1665 net.cpp:198] last_scale needs backward computation.
I0405 18:42:51.028535  1665 net.cpp:198] last_bn needs backward computation.
I0405 18:42:51.028587  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 18:42:51.028641  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 18:42:51.028750  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 18:42:51.028834  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 18:42:51.028883  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 18:42:51.028935  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 18:42:51.028990  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 18:42:51.029042  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 18:42:51.029094  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 18:42:51.029145  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 18:42:51.029201  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 18:42:51.029253  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 18:42:51.029309  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 18:42:51.029361  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 18:42:51.029413  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 18:42:51.029465  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 18:42:51.029516  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 18:42:51.029568  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 18:42:51.029655  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 18:42:51.029726  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 18:42:51.029778  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 18:42:51.029829  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 18:42:51.029881  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 18:42:51.029968  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 18:42:51.030052  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 18:42:51.030104  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 18:42:51.030156  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 18:42:51.030208  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 18:42:51.030261  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 18:42:51.030311  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 18:42:51.030364  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 18:42:51.030416  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 18:42:51.030467  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 18:42:51.030519  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 18:42:51.030570  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 18:42:51.030622  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 18:42:51.030680  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 18:42:51.030752  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 18:42:51.030814  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 18:42:51.030867  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 18:42:51.030920  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 18:42:51.030979  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 18:42:51.031036  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 18:42:51.031095  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 18:42:51.031152  1665 net.cpp:198] conv1 needs backward computation.
I0405 18:42:51.031204  1665 net.cpp:198] data_scale needs backward computation.
I0405 18:42:51.031258  1665 net.cpp:200] data_bn does not need backward computation.
I0405 18:42:51.031312  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 18:42:51.031366  1665 net.cpp:200] data does not need backward computation.
I0405 18:42:51.031417  1665 net.cpp:242] This network produces output accuracy
I0405 18:42:51.031468  1665 net.cpp:242] This network produces output loss
I0405 18:42:51.031561  1665 net.cpp:255] Network initialization done.
I0405 18:42:51.031807  1665 solver.cpp:56] Solver scaffolding done.
I0405 18:42:53.464655  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: data/resnet10_cvgj_iter_320000.caffemodel
I0405 18:42:53.464867  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 18:42:53.934432  1665 solver.cpp:218] Iteration 0 (1.67828e-09 iter/s, 0.465034s/225 iters), loss = 13.0434
I0405 18:42:53.934645  1665 solver.cpp:237]     Train net output #0: loss = 13.0434 (* 1 = 13.0434 loss)
I0405 18:42:53.934753  1665 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0405 18:44:32.352423  1665 solver.cpp:218] Iteration 225 (2.28613 iter/s, 98.4197s/225 iters), loss = 0.00297894
I0405 18:44:32.352624  1665 solver.cpp:237]     Train net output #0: loss = 0.00297893 (* 1 = 0.00297893 loss)
I0405 18:44:32.352699  1665 sgd_solver.cpp:105] Iteration 225, lr = 0.0875
I0405 18:46:10.775846  1665 solver.cpp:218] Iteration 450 (2.28598 iter/s, 98.4259s/225 iters), loss = 0.000123236
I0405 18:46:10.776106  1665 solver.cpp:237]     Train net output #0: loss = 0.000123233 (* 1 = 0.000123233 loss)
I0405 18:46:10.776198  1665 sgd_solver.cpp:105] Iteration 450, lr = 0.075
I0405 18:46:18.650147  1665 solver.cpp:330] Iteration 469, Testing net (#0)
I0405 18:47:49.214361  1665 solver.cpp:218] Iteration 675 (2.28562 iter/s, 98.4414s/225 iters), loss = 4.83333e-05
I0405 18:47:49.214692  1665 solver.cpp:237]     Train net output #0: loss = 4.83325e-05 (* 1 = 4.83325e-05 loss)
I0405 18:47:49.214784  1665 sgd_solver.cpp:105] Iteration 675, lr = 0.0625
I0405 18:49:27.664520  1665 solver.cpp:218] Iteration 900 (2.28539 iter/s, 98.4514s/225 iters), loss = 2.80325e-05
I0405 18:49:27.665040  1665 solver.cpp:237]     Train net output #0: loss = 2.80318e-05 (* 1 = 2.80318e-05 loss)
I0405 18:49:27.665127  1665 sgd_solver.cpp:105] Iteration 900, lr = 0.05
I0405 18:49:43.853605  1665 solver.cpp:330] Iteration 938, Testing net (#0)
I0405 18:51:06.104880  1665 solver.cpp:218] Iteration 1125 (2.28569 iter/s, 98.4385s/225 iters), loss = 9.45873e-05
I0405 18:51:06.105142  1665 solver.cpp:237]     Train net output #0: loss = 9.45865e-05 (* 1 = 9.45865e-05 loss)
I0405 18:51:06.105233  1665 sgd_solver.cpp:105] Iteration 1125, lr = 0.0375
I0405 18:52:44.538909  1665 solver.cpp:218] Iteration 1350 (2.2858 iter/s, 98.4337s/225 iters), loss = 5.78383e-05
I0405 18:52:44.539153  1665 solver.cpp:237]     Train net output #0: loss = 5.78374e-05 (* 1 = 5.78374e-05 loss)
I0405 18:52:44.539222  1665 sgd_solver.cpp:105] Iteration 1350, lr = 0.025
I0405 18:53:09.039250  1665 solver.cpp:330] Iteration 1407, Testing net (#0)
I0405 18:54:22.972708  1665 solver.cpp:218] Iteration 1575 (2.28579 iter/s, 98.4344s/225 iters), loss = 1.87811e-05
I0405 18:54:22.972955  1665 solver.cpp:237]     Train net output #0: loss = 1.87803e-05 (* 1 = 1.87803e-05 loss)
I0405 18:54:22.973021  1665 sgd_solver.cpp:105] Iteration 1575, lr = 0.0125
I0405 18:56:00.975837  1665 solver.cpp:457] Snapshotting to HDF5 file data/snapshots/train_batch_00_iter_1800.caffemodel.h5
I0405 18:56:01.035845  1665 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file data/snapshots/train_batch_00_iter_1800.solverstate.h5
W0405 18:56:01.861805  1665 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W0405 18:56:01.862208  1665 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W0405 18:56:01.862347  1665 _caffe.cpp:142] Net('confs/sII/mid-caffeNet/inc_train_val.prototxt', 1, weights='data/snapshots/train_batch_00_iter_1800.caffemodel.h5')
I0405 18:56:01.866268  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 18:56:01.866412  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 18:56:01.866565  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 18:56:01.866930  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 18:56:01.867198  1665 layer_factory.hpp:77] Creating layer data
I0405 18:56:01.867285  1665 net.cpp:84] Creating Layer data
I0405 18:56:01.867347  1665 net.cpp:380] data -> data
I0405 18:56:01.867416  1665 net.cpp:380] data -> label
I0405 18:56:01.867475  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 18:56:01.875861  1665 image_data_layer.cpp:53] Shuffling data
I0405 18:56:01.876994  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 18:56:01.877939  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 18:56:01.922137  1665 net.cpp:122] Setting up data
I0405 18:56:01.922374  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 18:56:01.922467  1665 net.cpp:129] Top shape: 100 (100)
I0405 18:56:01.922535  1665 net.cpp:137] Memory required for data: 19661200
I0405 18:56:01.922602  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 18:56:01.922700  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 18:56:01.922796  1665 net.cpp:406] label_data_1_split <- label
I0405 18:56:01.922876  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 18:56:01.922955  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 18:56:01.923126  1665 net.cpp:122] Setting up label_data_1_split
I0405 18:56:01.923204  1665 net.cpp:129] Top shape: 100 (100)
I0405 18:56:01.923276  1665 net.cpp:129] Top shape: 100 (100)
I0405 18:56:01.923360  1665 net.cpp:137] Memory required for data: 19662000
I0405 18:56:01.923432  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 18:56:01.923508  1665 net.cpp:84] Creating Layer data_bn
I0405 18:56:01.923583  1665 net.cpp:406] data_bn <- data
I0405 18:56:01.923657  1665 net.cpp:380] data_bn -> data_bn
I0405 18:56:01.923997  1665 net.cpp:122] Setting up data_bn
I0405 18:56:01.924114  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 18:56:01.924209  1665 net.cpp:137] Memory required for data: 39322800
I0405 18:56:01.924293  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 18:56:01.924382  1665 net.cpp:84] Creating Layer data_scale
I0405 18:56:01.924459  1665 net.cpp:406] data_scale <- data_bn
I0405 18:56:01.924533  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 18:56:01.925967  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 18:56:01.926211  1665 net.cpp:122] Setting up data_scale
I0405 18:56:01.926379  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 18:56:01.926473  1665 net.cpp:137] Memory required for data: 58983600
I0405 18:56:01.926553  1665 layer_factory.hpp:77] Creating layer conv1
I0405 18:56:01.926633  1665 net.cpp:84] Creating Layer conv1
I0405 18:56:01.926708  1665 net.cpp:406] conv1 <- data_bn
I0405 18:56:01.926776  1665 net.cpp:380] conv1 -> conv1
I0405 18:56:01.927131  1665 net.cpp:122] Setting up conv1
I0405 18:56:01.927237  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 18:56:01.927314  1665 net.cpp:137] Memory required for data: 163841200
I0405 18:56:01.927415  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 18:56:01.927515  1665 net.cpp:84] Creating Layer conv1_bn
I0405 18:56:01.927588  1665 net.cpp:406] conv1_bn <- conv1
I0405 18:56:01.927661  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 18:56:01.927913  1665 net.cpp:122] Setting up conv1_bn
I0405 18:56:01.928016  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 18:56:01.928107  1665 net.cpp:137] Memory required for data: 268698800
I0405 18:56:01.928189  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 18:56:01.928267  1665 net.cpp:84] Creating Layer conv1_scale
I0405 18:56:01.928346  1665 net.cpp:406] conv1_scale <- conv1
I0405 18:56:01.928433  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 18:56:01.928539  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 18:56:01.928689  1665 net.cpp:122] Setting up conv1_scale
I0405 18:56:01.928810  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 18:56:01.928897  1665 net.cpp:137] Memory required for data: 373556400
I0405 18:56:01.928970  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 18:56:01.929046  1665 net.cpp:84] Creating Layer conv1_relu
I0405 18:56:01.929126  1665 net.cpp:406] conv1_relu <- conv1
I0405 18:56:01.929198  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 18:56:01.929273  1665 net.cpp:122] Setting up conv1_relu
I0405 18:56:01.929354  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 18:56:01.929440  1665 net.cpp:137] Memory required for data: 478414000
I0405 18:56:01.929518  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 18:56:01.929594  1665 net.cpp:84] Creating Layer conv1_pool
I0405 18:56:01.929666  1665 net.cpp:406] conv1_pool <- conv1
I0405 18:56:01.929787  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 18:56:01.929888  1665 net.cpp:122] Setting up conv1_pool
I0405 18:56:01.929967  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:01.930042  1665 net.cpp:137] Memory required for data: 504628400
I0405 18:56:01.930114  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 18:56:01.930189  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 18:56:01.930264  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 18:56:01.930346  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 18:56:01.930435  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 18:56:01.930539  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 18:56:01.930614  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:01.930688  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:01.930800  1665 net.cpp:137] Memory required for data: 557057200
I0405 18:56:01.930891  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 18:56:01.930968  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 18:56:01.931042  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 18:56:01.931116  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 18:56:01.931666  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 18:56:01.931802  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:01.931885  1665 net.cpp:137] Memory required for data: 583271600
I0405 18:56:01.931959  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 18:56:01.932036  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 18:56:01.932111  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 18:56:01.932184  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 18:56:01.932389  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 18:56:01.932478  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:01.932551  1665 net.cpp:137] Memory required for data: 609486000
I0405 18:56:01.932693  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 18:56:01.932804  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 18:56:01.932901  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 18:56:01.932966  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 18:56:01.933058  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 18:56:01.933182  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 18:56:01.933260  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:01.933326  1665 net.cpp:137] Memory required for data: 635700400
I0405 18:56:01.933385  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 18:56:01.933451  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 18:56:01.933516  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 18:56:01.933578  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 18:56:01.933655  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 18:56:01.933722  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:01.933787  1665 net.cpp:137] Memory required for data: 661914800
I0405 18:56:01.933851  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 18:56:01.933929  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 18:56:01.933993  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 18:56:01.934069  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 18:56:01.934517  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 18:56:01.934603  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:01.934679  1665 net.cpp:137] Memory required for data: 688129200
I0405 18:56:01.934762  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 18:56:01.934849  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 18:56:01.934912  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 18:56:01.934989  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 18:56:01.935067  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 18:56:01.935150  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 18:56:01.935230  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:01.935294  1665 net.cpp:137] Memory required for data: 714343600
I0405 18:56:01.935360  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 18:56:01.935425  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 18:56:01.935488  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 18:56:01.935575  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 18:56:01.935808  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 18:56:01.935886  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:01.935954  1665 net.cpp:137] Memory required for data: 740558000
I0405 18:56:01.936040  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 18:56:01.936106  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 18:56:01.936177  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 18:56:01.936241  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 18:56:01.936327  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 18:56:01.936450  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 18:56:01.936530  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:01.936594  1665 net.cpp:137] Memory required for data: 766772400
I0405 18:56:01.936657  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 18:56:01.936729  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 18:56:01.936794  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 18:56:01.936872  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 18:56:01.936940  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 18:56:01.937005  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:01.937067  1665 net.cpp:137] Memory required for data: 792986800
I0405 18:56:01.937139  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 18:56:01.937208  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 18:56:01.937280  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 18:56:01.937350  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 18:56:01.937419  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 18:56:01.937503  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 18:56:01.937569  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:01.937634  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:01.937698  1665 net.cpp:137] Memory required for data: 845415600
I0405 18:56:01.937834  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 18:56:01.937947  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 18:56:01.938019  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 18:56:01.938084  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 18:56:01.938985  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 18:56:01.939080  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:01.939143  1665 net.cpp:137] Memory required for data: 858522800
I0405 18:56:01.939205  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 18:56:01.939270  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 18:56:01.939332  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 18:56:01.939400  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 18:56:01.939633  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 18:56:01.939738  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:01.939810  1665 net.cpp:137] Memory required for data: 871630000
I0405 18:56:01.939882  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 18:56:01.939944  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 18:56:01.940003  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 18:56:01.940062  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 18:56:01.940157  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 18:56:01.940294  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 18:56:01.940376  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:01.940438  1665 net.cpp:137] Memory required for data: 884737200
I0405 18:56:01.940500  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 18:56:01.940560  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 18:56:01.940618  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 18:56:01.940676  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 18:56:01.940752  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 18:56:01.940816  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:01.940881  1665 net.cpp:137] Memory required for data: 897844400
I0405 18:56:01.940943  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 18:56:01.941007  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 18:56:01.941068  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 18:56:01.941133  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 18:56:01.942701  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 18:56:01.942807  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:01.942881  1665 net.cpp:137] Memory required for data: 910951600
I0405 18:56:01.942940  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 18:56:01.943009  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 18:56:01.943073  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 18:56:01.943135  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 18:56:01.943437  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 18:56:01.943537  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:01.943608  1665 net.cpp:137] Memory required for data: 924058800
I0405 18:56:01.943671  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 18:56:01.943747  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 18:56:01.943805  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 18:56:01.943867  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 18:56:01.943926  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 18:56:01.944016  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 18:56:01.944078  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:01.944135  1665 net.cpp:137] Memory required for data: 937166000
I0405 18:56:01.944196  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 18:56:01.944258  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 18:56:01.944316  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 18:56:01.944375  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 18:56:01.944568  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 18:56:01.944646  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:01.944706  1665 net.cpp:137] Memory required for data: 950273200
I0405 18:56:01.944789  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 18:56:01.944859  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 18:56:01.944919  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 18:56:01.944980  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 18:56:01.945076  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 18:56:01.945245  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 18:56:01.945330  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:01.945397  1665 net.cpp:137] Memory required for data: 963380400
I0405 18:56:01.945461  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 18:56:01.945542  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 18:56:01.945598  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 18:56:01.945663  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 18:56:01.945741  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 18:56:01.945803  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:01.945866  1665 net.cpp:137] Memory required for data: 976487600
I0405 18:56:01.945924  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 18:56:01.945986  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 18:56:01.946048  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 18:56:01.946110  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 18:56:01.946173  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 18:56:01.946262  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 18:56:01.946342  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:01.946405  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:01.946463  1665 net.cpp:137] Memory required for data: 1002702000
I0405 18:56:01.946522  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 18:56:01.946586  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 18:56:01.946646  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 18:56:01.946708  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 18:56:01.950480  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 18:56:01.950577  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:01.950637  1665 net.cpp:137] Memory required for data: 1009255600
I0405 18:56:01.950696  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 18:56:01.950763  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 18:56:01.950824  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 18:56:01.950899  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 18:56:01.951098  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 18:56:01.951169  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:01.951221  1665 net.cpp:137] Memory required for data: 1015809200
I0405 18:56:01.951282  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 18:56:01.951344  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 18:56:01.951401  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 18:56:01.951460  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 18:56:01.951557  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 18:56:01.951730  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 18:56:01.951807  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:01.951869  1665 net.cpp:137] Memory required for data: 1022362800
I0405 18:56:01.951927  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 18:56:01.951997  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 18:56:01.952052  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 18:56:01.952113  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 18:56:01.952172  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 18:56:01.952230  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:01.952287  1665 net.cpp:137] Memory required for data: 1028916400
I0405 18:56:01.952343  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 18:56:01.952405  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 18:56:01.952461  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 18:56:01.952519  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 18:56:01.958844  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 18:56:01.958940  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:01.959000  1665 net.cpp:137] Memory required for data: 1035470000
I0405 18:56:01.959060  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 18:56:01.959123  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 18:56:01.959182  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 18:56:01.959242  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 18:56:01.959776  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 18:56:01.959867  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:01.959936  1665 net.cpp:137] Memory required for data: 1042023600
I0405 18:56:01.959996  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 18:56:01.960064  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 18:56:01.960124  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 18:56:01.960182  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 18:56:01.960242  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 18:56:01.960325  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 18:56:01.960397  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:01.960453  1665 net.cpp:137] Memory required for data: 1048577200
I0405 18:56:01.960510  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 18:56:01.960569  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 18:56:01.960626  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 18:56:01.960685  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 18:56:01.960901  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 18:56:01.960979  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:01.961040  1665 net.cpp:137] Memory required for data: 1055130800
I0405 18:56:01.961103  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 18:56:01.961166  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 18:56:01.961223  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 18:56:01.961282  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 18:56:01.961377  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 18:56:01.961527  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 18:56:01.961601  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:01.961661  1665 net.cpp:137] Memory required for data: 1061684400
I0405 18:56:01.961733  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 18:56:01.961796  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 18:56:01.961891  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 18:56:01.961953  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 18:56:01.962016  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 18:56:01.962077  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:01.962136  1665 net.cpp:137] Memory required for data: 1068238000
I0405 18:56:01.962195  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 18:56:01.962257  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 18:56:01.962316  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 18:56:01.962378  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 18:56:01.962440  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 18:56:01.962533  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 18:56:01.962599  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:01.962679  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:01.962759  1665 net.cpp:137] Memory required for data: 1081345200
I0405 18:56:01.962843  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 18:56:01.962920  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 18:56:01.962980  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 18:56:01.963042  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 18:56:01.974952  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 18:56:01.975064  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:01.975144  1665 net.cpp:137] Memory required for data: 1084622000
I0405 18:56:01.975214  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 18:56:01.975286  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 18:56:01.975360  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 18:56:01.975437  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 18:56:01.975649  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 18:56:01.975766  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:01.975837  1665 net.cpp:137] Memory required for data: 1087898800
I0405 18:56:01.975899  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 18:56:01.975960  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 18:56:01.976019  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 18:56:01.976079  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 18:56:01.976162  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 18:56:01.976281  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 18:56:01.976348  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:01.976408  1665 net.cpp:137] Memory required for data: 1091175600
I0405 18:56:01.976469  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 18:56:01.976543  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 18:56:01.976605  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 18:56:01.976680  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 18:56:01.976760  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 18:56:01.976822  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:01.976886  1665 net.cpp:137] Memory required for data: 1094452400
I0405 18:56:01.976945  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 18:56:01.977010  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 18:56:01.977071  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 18:56:01.977129  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 18:56:01.998757  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 18:56:01.998873  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:01.998951  1665 net.cpp:137] Memory required for data: 1097729200
I0405 18:56:01.999033  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 18:56:01.999101  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 18:56:01.999164  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 18:56:01.999228  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 18:56:02.000429  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 18:56:02.000525  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:02.000604  1665 net.cpp:137] Memory required for data: 1101006000
I0405 18:56:02.000667  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 18:56:02.000758  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 18:56:02.000823  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 18:56:02.000887  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 18:56:02.000947  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 18:56:02.001039  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 18:56:02.001101  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:02.001164  1665 net.cpp:137] Memory required for data: 1104282800
I0405 18:56:02.001226  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 18:56:02.001291  1665 net.cpp:84] Creating Layer last_bn
I0405 18:56:02.001361  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 18:56:02.001425  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 18:56:02.001596  1665 net.cpp:122] Setting up last_bn
I0405 18:56:02.001675  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:02.001760  1665 net.cpp:137] Memory required for data: 1107559600
I0405 18:56:02.001830  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 18:56:02.001894  1665 net.cpp:84] Creating Layer last_scale
I0405 18:56:02.001957  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 18:56:02.002022  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 18:56:02.002117  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 18:56:02.002249  1665 net.cpp:122] Setting up last_scale
I0405 18:56:02.002344  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:02.002405  1665 net.cpp:137] Memory required for data: 1110836400
I0405 18:56:02.002470  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 18:56:02.002532  1665 net.cpp:84] Creating Layer last_relu
I0405 18:56:02.002598  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 18:56:02.002688  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 18:56:02.002763  1665 net.cpp:122] Setting up last_relu
I0405 18:56:02.002826  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:02.002907  1665 net.cpp:137] Memory required for data: 1114113200
I0405 18:56:02.002966  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 18:56:02.003029  1665 net.cpp:84] Creating Layer global_pool
I0405 18:56:02.003093  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 18:56:02.003172  1665 net.cpp:380] global_pool -> global_pool
I0405 18:56:02.003262  1665 net.cpp:122] Setting up global_pool
I0405 18:56:02.003336  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 18:56:02.003399  1665 net.cpp:137] Memory required for data: 1114318000
I0405 18:56:02.003466  1665 layer_factory.hpp:77] Creating layer score
I0405 18:56:02.003532  1665 net.cpp:84] Creating Layer score
I0405 18:56:02.003597  1665 net.cpp:406] score <- global_pool
I0405 18:56:02.003659  1665 net.cpp:380] score -> score
I0405 18:56:02.004925  1665 net.cpp:122] Setting up score
I0405 18:56:02.005034  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 18:56:02.005091  1665 net.cpp:137] Memory required for data: 1114718000
I0405 18:56:02.005172  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 18:56:02.005234  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 18:56:02.005300  1665 net.cpp:406] score_score_0_split <- score
I0405 18:56:02.005411  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 18:56:02.005479  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 18:56:02.005551  1665 net.cpp:122] Setting up score_score_0_split
I0405 18:56:02.005651  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 18:56:02.005703  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 18:56:02.005795  1665 net.cpp:137] Memory required for data: 1115518000
I0405 18:56:02.005846  1665 layer_factory.hpp:77] Creating layer loss
I0405 18:56:02.005901  1665 net.cpp:84] Creating Layer loss
I0405 18:56:02.005952  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 18:56:02.006032  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 18:56:02.006085  1665 net.cpp:380] loss -> loss
I0405 18:56:02.006139  1665 layer_factory.hpp:77] Creating layer loss
I0405 18:56:02.007258  1665 net.cpp:122] Setting up loss
I0405 18:56:02.007367  1665 net.cpp:129] Top shape: (1)
I0405 18:56:02.007422  1665 net.cpp:132]     with loss weight 1
I0405 18:56:02.007491  1665 net.cpp:137] Memory required for data: 1115518004
I0405 18:56:02.007545  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 18:56:02.007601  1665 net.cpp:84] Creating Layer accuracy
I0405 18:56:02.007655  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 18:56:02.007709  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 18:56:02.007814  1665 net.cpp:380] accuracy -> accuracy
I0405 18:56:02.007872  1665 net.cpp:122] Setting up accuracy
I0405 18:56:02.007925  1665 net.cpp:129] Top shape: (1)
I0405 18:56:02.007974  1665 net.cpp:137] Memory required for data: 1115518008
I0405 18:56:02.008047  1665 net.cpp:200] accuracy does not need backward computation.
I0405 18:56:02.008106  1665 net.cpp:198] loss needs backward computation.
I0405 18:56:02.008183  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 18:56:02.008237  1665 net.cpp:198] score needs backward computation.
I0405 18:56:02.008291  1665 net.cpp:198] global_pool needs backward computation.
I0405 18:56:02.008349  1665 net.cpp:198] last_relu needs backward computation.
I0405 18:56:02.008402  1665 net.cpp:198] last_scale needs backward computation.
I0405 18:56:02.008466  1665 net.cpp:198] last_bn needs backward computation.
I0405 18:56:02.008518  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 18:56:02.008582  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 18:56:02.008633  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 18:56:02.008685  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 18:56:02.008761  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 18:56:02.008813  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 18:56:02.008893  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 18:56:02.008944  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 18:56:02.009004  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 18:56:02.009055  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 18:56:02.009130  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 18:56:02.009189  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 18:56:02.009263  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 18:56:02.009317  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 18:56:02.009375  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 18:56:02.009428  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 18:56:02.009479  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 18:56:02.009532  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 18:56:02.009588  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 18:56:02.009640  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 18:56:02.009693  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 18:56:02.009766  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 18:56:02.009819  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 18:56:02.009891  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 18:56:02.009948  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 18:56:02.010008  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 18:56:02.010058  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 18:56:02.010108  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 18:56:02.010162  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 18:56:02.010216  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 18:56:02.010268  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 18:56:02.010324  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 18:56:02.010371  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 18:56:02.010426  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 18:56:02.010478  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 18:56:02.010530  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 18:56:02.010583  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 18:56:02.010637  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 18:56:02.010689  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 18:56:02.010764  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 18:56:02.010818  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 18:56:02.010884  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 18:56:02.010944  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 18:56:02.010998  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 18:56:02.011051  1665 net.cpp:198] conv1 needs backward computation.
I0405 18:56:02.011106  1665 net.cpp:198] data_scale needs backward computation.
I0405 18:56:02.011157  1665 net.cpp:200] data_bn does not need backward computation.
I0405 18:56:02.011219  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 18:56:02.011273  1665 net.cpp:200] data does not need backward computation.
I0405 18:56:02.011328  1665 net.cpp:242] This network produces output accuracy
I0405 18:56:02.011389  1665 net.cpp:242] This network produces output loss
I0405 18:56:02.011472  1665 net.cpp:255] Network initialization done.
I0405 18:56:02.014667  1665 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0405 18:56:02.101061  1665 blocking_queue.cpp:49] Waiting for data
I0405 18:56:39.985059  1665 solver.cpp:44] Initializing solver from parameters: 
test_iter: 0
test_interval: 469
base_lr: 0.001
display: 225
max_iter: 1800
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 1800
snapshot_prefix: "data/snapshots/train_batch_01"
solver_mode: GPU
random_seed: 0
net: "confs/sII/mid-caffeNet/inc_train_val.prototxt"
test_initialization: false
snapshot_format: HDF5
I0405 18:56:39.987478  1665 solver.cpp:87] Creating training net from net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 18:56:39.988529  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 18:56:39.988664  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 18:56:39.988852  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0405 18:56:39.988976  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0405 18:56:39.989246  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/train_batch_01_filelist.txt"
    batch_size: 256
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I0405 18:56:39.989508  1665 layer_factory.hpp:77] Creating layer data
I0405 18:56:39.989600  1665 net.cpp:84] Creating Layer data
I0405 18:56:39.989658  1665 net.cpp:380] data -> data
I0405 18:56:39.989740  1665 net.cpp:380] data -> label
I0405 18:56:39.989816  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/train_batch_01_filelist.txt
I0405 18:56:39.997056  1665 image_data_layer.cpp:53] Shuffling data
I0405 18:56:39.997938  1665 image_data_layer.cpp:63] A total of 35973 images.
I0405 18:56:40.000002  1665 image_data_layer.cpp:90] output data size: 256,3,128,128
I0405 18:56:40.125710  1665 net.cpp:122] Setting up data
I0405 18:56:40.125954  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 18:56:40.126039  1665 net.cpp:129] Top shape: 256 (256)
I0405 18:56:40.126102  1665 net.cpp:137] Memory required for data: 50332672
I0405 18:56:40.126164  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 18:56:40.126233  1665 net.cpp:84] Creating Layer data_bn
I0405 18:56:40.126296  1665 net.cpp:406] data_bn <- data
I0405 18:56:40.126385  1665 net.cpp:380] data_bn -> data_bn
I0405 18:56:40.126608  1665 net.cpp:122] Setting up data_bn
I0405 18:56:40.126709  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 18:56:40.126797  1665 net.cpp:137] Memory required for data: 100664320
I0405 18:56:40.126863  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 18:56:40.126946  1665 net.cpp:84] Creating Layer data_scale
I0405 18:56:40.127022  1665 net.cpp:406] data_scale <- data_bn
I0405 18:56:40.127089  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 18:56:40.131748  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 18:56:40.132071  1665 net.cpp:122] Setting up data_scale
I0405 18:56:40.132174  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 18:56:40.132249  1665 net.cpp:137] Memory required for data: 150995968
I0405 18:56:40.132316  1665 layer_factory.hpp:77] Creating layer conv1
I0405 18:56:40.132386  1665 net.cpp:84] Creating Layer conv1
I0405 18:56:40.132449  1665 net.cpp:406] conv1 <- data_bn
I0405 18:56:40.132529  1665 net.cpp:380] conv1 -> conv1
I0405 18:56:40.132897  1665 net.cpp:122] Setting up conv1
I0405 18:56:40.132997  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 18:56:40.133060  1665 net.cpp:137] Memory required for data: 419431424
I0405 18:56:40.133121  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 18:56:40.133186  1665 net.cpp:84] Creating Layer conv1_bn
I0405 18:56:40.133247  1665 net.cpp:406] conv1_bn <- conv1
I0405 18:56:40.133327  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 18:56:40.133550  1665 net.cpp:122] Setting up conv1_bn
I0405 18:56:40.133631  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 18:56:40.133700  1665 net.cpp:137] Memory required for data: 687866880
I0405 18:56:40.133788  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 18:56:40.133846  1665 net.cpp:84] Creating Layer conv1_scale
I0405 18:56:40.133900  1665 net.cpp:406] conv1_scale <- conv1
I0405 18:56:40.133960  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 18:56:40.134047  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 18:56:40.134222  1665 net.cpp:122] Setting up conv1_scale
I0405 18:56:40.134299  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 18:56:40.134358  1665 net.cpp:137] Memory required for data: 956302336
I0405 18:56:40.134419  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 18:56:40.134476  1665 net.cpp:84] Creating Layer conv1_relu
I0405 18:56:40.134528  1665 net.cpp:406] conv1_relu <- conv1
I0405 18:56:40.134582  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 18:56:40.134636  1665 net.cpp:122] Setting up conv1_relu
I0405 18:56:40.134701  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 18:56:40.134830  1665 net.cpp:137] Memory required for data: 1224737792
I0405 18:56:40.134896  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 18:56:40.135008  1665 net.cpp:84] Creating Layer conv1_pool
I0405 18:56:40.135076  1665 net.cpp:406] conv1_pool <- conv1
I0405 18:56:40.135144  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 18:56:40.135264  1665 net.cpp:122] Setting up conv1_pool
I0405 18:56:40.135339  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:56:40.135404  1665 net.cpp:137] Memory required for data: 1291846656
I0405 18:56:40.135476  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 18:56:40.135545  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 18:56:40.135610  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 18:56:40.135699  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 18:56:40.135800  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 18:56:40.135901  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 18:56:40.135989  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:56:40.136057  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:56:40.136127  1665 net.cpp:137] Memory required for data: 1426064384
I0405 18:56:40.136186  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 18:56:40.136248  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 18:56:40.136304  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 18:56:40.136363  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 18:56:40.136940  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 18:56:40.137029  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:56:40.137089  1665 net.cpp:137] Memory required for data: 1493173248
I0405 18:56:40.137146  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 18:56:40.137208  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 18:56:40.137264  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 18:56:40.137322  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 18:56:40.137565  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 18:56:40.137656  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:56:40.137722  1665 net.cpp:137] Memory required for data: 1560282112
I0405 18:56:40.137790  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 18:56:40.137850  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 18:56:40.137905  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 18:56:40.137966  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 18:56:40.138052  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 18:56:40.138190  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 18:56:40.138278  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:56:40.138330  1665 net.cpp:137] Memory required for data: 1627390976
I0405 18:56:40.138397  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 18:56:40.138468  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 18:56:40.138523  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 18:56:40.138578  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 18:56:40.138636  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 18:56:40.138693  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:56:40.138761  1665 net.cpp:137] Memory required for data: 1694499840
I0405 18:56:40.138815  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 18:56:40.138875  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 18:56:40.138931  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 18:56:40.138986  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 18:56:40.139551  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 18:56:40.139647  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:56:40.139705  1665 net.cpp:137] Memory required for data: 1761608704
I0405 18:56:40.139771  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 18:56:40.139840  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 18:56:40.139897  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 18:56:40.139961  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 18:56:40.140022  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 18:56:40.140102  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 18:56:40.140178  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:56:40.140234  1665 net.cpp:137] Memory required for data: 1828717568
I0405 18:56:40.140290  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 18:56:40.140347  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 18:56:40.140403  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 18:56:40.140460  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 18:56:40.140653  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 18:56:40.140775  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:56:40.140851  1665 net.cpp:137] Memory required for data: 1895826432
I0405 18:56:40.140913  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 18:56:40.140977  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 18:56:40.141033  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 18:56:40.141091  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 18:56:40.141177  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 18:56:40.141321  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 18:56:40.141388  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:56:40.141445  1665 net.cpp:137] Memory required for data: 1962935296
I0405 18:56:40.141505  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 18:56:40.141566  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 18:56:40.141623  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 18:56:40.141680  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 18:56:40.141755  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 18:56:40.141813  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:56:40.141867  1665 net.cpp:137] Memory required for data: 2030044160
I0405 18:56:40.141922  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 18:56:40.141993  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 18:56:40.142047  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 18:56:40.142103  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 18:56:40.142168  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 18:56:40.142253  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 18:56:40.142335  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:56:40.142393  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 18:56:40.142449  1665 net.cpp:137] Memory required for data: 2164261888
I0405 18:56:40.142505  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 18:56:40.142567  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 18:56:40.142623  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 18:56:40.142693  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 18:56:40.143586  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 18:56:40.143682  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:56:40.143767  1665 net.cpp:137] Memory required for data: 2197816320
I0405 18:56:40.143839  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 18:56:40.143900  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 18:56:40.143965  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 18:56:40.144026  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 18:56:40.144193  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 18:56:40.144270  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:56:40.144326  1665 net.cpp:137] Memory required for data: 2231370752
I0405 18:56:40.144385  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 18:56:40.144446  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 18:56:40.144505  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 18:56:40.144572  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 18:56:40.144657  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 18:56:40.144836  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 18:56:40.144901  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:56:40.144963  1665 net.cpp:137] Memory required for data: 2264925184
I0405 18:56:40.145021  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 18:56:40.145079  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 18:56:40.145135  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 18:56:40.145192  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 18:56:40.145249  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 18:56:40.145306  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:56:40.145367  1665 net.cpp:137] Memory required for data: 2298479616
I0405 18:56:40.145422  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 18:56:40.145486  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 18:56:40.145545  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 18:56:40.145606  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 18:56:40.147053  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 18:56:40.147145  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:56:40.147205  1665 net.cpp:137] Memory required for data: 2332034048
I0405 18:56:40.147267  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 18:56:40.147328  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 18:56:40.147403  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 18:56:40.147462  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 18:56:40.147799  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 18:56:40.147891  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:56:40.147960  1665 net.cpp:137] Memory required for data: 2365588480
I0405 18:56:40.148022  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 18:56:40.148082  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 18:56:40.148138  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 18:56:40.148195  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 18:56:40.148252  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 18:56:40.148329  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 18:56:40.148394  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:56:40.148452  1665 net.cpp:137] Memory required for data: 2399142912
I0405 18:56:40.148509  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 18:56:40.148574  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 18:56:40.148630  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 18:56:40.148689  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 18:56:40.148892  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 18:56:40.148968  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:56:40.149025  1665 net.cpp:137] Memory required for data: 2432697344
I0405 18:56:40.149086  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 18:56:40.149147  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 18:56:40.149202  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 18:56:40.149258  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 18:56:40.149353  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 18:56:40.149489  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 18:56:40.149576  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:56:40.149636  1665 net.cpp:137] Memory required for data: 2466251776
I0405 18:56:40.149695  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 18:56:40.149757  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 18:56:40.149813  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 18:56:40.149870  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 18:56:40.149926  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 18:56:40.149986  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:56:40.150041  1665 net.cpp:137] Memory required for data: 2499806208
I0405 18:56:40.150096  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 18:56:40.150161  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 18:56:40.150216  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 18:56:40.150274  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 18:56:40.150337  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 18:56:40.150420  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 18:56:40.150485  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:56:40.150542  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 18:56:40.150597  1665 net.cpp:137] Memory required for data: 2566915072
I0405 18:56:40.150653  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 18:56:40.150734  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 18:56:40.150795  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 18:56:40.150853  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 18:56:40.154578  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 18:56:40.154774  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:56:40.154844  1665 net.cpp:137] Memory required for data: 2583692288
I0405 18:56:40.154927  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 18:56:40.155009  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 18:56:40.155076  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 18:56:40.155139  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 18:56:40.155357  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 18:56:40.155450  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:56:40.155514  1665 net.cpp:137] Memory required for data: 2600469504
I0405 18:56:40.155581  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 18:56:40.155688  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 18:56:40.155773  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 18:56:40.155845  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 18:56:40.156013  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 18:56:40.156168  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 18:56:40.156250  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:56:40.156308  1665 net.cpp:137] Memory required for data: 2617246720
I0405 18:56:40.156368  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 18:56:40.156435  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 18:56:40.156492  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 18:56:40.156560  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 18:56:40.156628  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 18:56:40.156682  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:56:40.156759  1665 net.cpp:137] Memory required for data: 2634023936
I0405 18:56:40.156816  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 18:56:40.156904  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 18:56:40.156976  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 18:56:40.157037  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 18:56:40.163177  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 18:56:40.163259  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:56:40.163316  1665 net.cpp:137] Memory required for data: 2650801152
I0405 18:56:40.163372  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 18:56:40.163437  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 18:56:40.163504  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 18:56:40.163563  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 18:56:40.164115  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 18:56:40.164199  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:56:40.164254  1665 net.cpp:137] Memory required for data: 2667578368
I0405 18:56:40.164309  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 18:56:40.164366  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 18:56:40.164420  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 18:56:40.164476  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 18:56:40.164541  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 18:56:40.164615  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 18:56:40.164683  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:56:40.164758  1665 net.cpp:137] Memory required for data: 2684355584
I0405 18:56:40.164813  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 18:56:40.164870  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 18:56:40.164922  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 18:56:40.164981  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 18:56:40.165172  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 18:56:40.165256  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:56:40.165324  1665 net.cpp:137] Memory required for data: 2701132800
I0405 18:56:40.165381  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 18:56:40.165473  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 18:56:40.165537  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 18:56:40.165597  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 18:56:40.165685  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 18:56:40.165823  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 18:56:40.165899  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:56:40.165957  1665 net.cpp:137] Memory required for data: 2717910016
I0405 18:56:40.166013  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 18:56:40.166070  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 18:56:40.166137  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 18:56:40.166198  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 18:56:40.166252  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 18:56:40.166316  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:56:40.166375  1665 net.cpp:137] Memory required for data: 2734687232
I0405 18:56:40.166427  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 18:56:40.166489  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 18:56:40.166543  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 18:56:40.166599  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 18:56:40.166666  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 18:56:40.166759  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 18:56:40.166821  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:56:40.166880  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 18:56:40.166962  1665 net.cpp:137] Memory required for data: 2768241664
I0405 18:56:40.167016  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 18:56:40.167075  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 18:56:40.167132  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 18:56:40.167193  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 18:56:40.179172  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 18:56:40.179287  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:56:40.179360  1665 net.cpp:137] Memory required for data: 2776630272
I0405 18:56:40.179420  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 18:56:40.179491  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 18:56:40.179553  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 18:56:40.179615  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 18:56:40.179818  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 18:56:40.179906  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:56:40.179965  1665 net.cpp:137] Memory required for data: 2785018880
I0405 18:56:40.180028  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 18:56:40.180091  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 18:56:40.180152  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 18:56:40.180222  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 18:56:40.180302  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 18:56:40.180461  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 18:56:40.180527  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:56:40.180588  1665 net.cpp:137] Memory required for data: 2793407488
I0405 18:56:40.180649  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 18:56:40.180711  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 18:56:40.180805  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 18:56:40.180867  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 18:56:40.180930  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 18:56:40.181011  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:56:40.181071  1665 net.cpp:137] Memory required for data: 2801796096
I0405 18:56:40.181131  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 18:56:40.181196  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 18:56:40.181264  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 18:56:40.181327  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 18:56:40.204890  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 18:56:40.205029  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:56:40.205101  1665 net.cpp:137] Memory required for data: 2810184704
I0405 18:56:40.205174  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 18:56:40.205242  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 18:56:40.205303  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 18:56:40.205372  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 18:56:40.206738  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 18:56:40.206842  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:56:40.206909  1665 net.cpp:137] Memory required for data: 2818573312
I0405 18:56:40.206986  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 18:56:40.207048  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 18:56:40.207109  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 18:56:40.207170  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 18:56:40.207229  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 18:56:40.207309  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 18:56:40.207384  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:56:40.207442  1665 net.cpp:137] Memory required for data: 2826961920
I0405 18:56:40.207497  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 18:56:40.207556  1665 net.cpp:84] Creating Layer last_bn
I0405 18:56:40.207614  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 18:56:40.207695  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 18:56:40.207911  1665 net.cpp:122] Setting up last_bn
I0405 18:56:40.207985  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:56:40.208043  1665 net.cpp:137] Memory required for data: 2835350528
I0405 18:56:40.208103  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 18:56:40.208163  1665 net.cpp:84] Creating Layer last_scale
I0405 18:56:40.208220  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 18:56:40.208278  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 18:56:40.208364  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 18:56:40.208518  1665 net.cpp:122] Setting up last_scale
I0405 18:56:40.208598  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:56:40.208662  1665 net.cpp:137] Memory required for data: 2843739136
I0405 18:56:40.208739  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 18:56:40.208799  1665 net.cpp:84] Creating Layer last_relu
I0405 18:56:40.208855  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 18:56:40.208911  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 18:56:40.208976  1665 net.cpp:122] Setting up last_relu
I0405 18:56:40.209034  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 18:56:40.209089  1665 net.cpp:137] Memory required for data: 2852127744
I0405 18:56:40.209146  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 18:56:40.209203  1665 net.cpp:84] Creating Layer global_pool
I0405 18:56:40.209285  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 18:56:40.209342  1665 net.cpp:380] global_pool -> global_pool
I0405 18:56:40.209416  1665 net.cpp:122] Setting up global_pool
I0405 18:56:40.209497  1665 net.cpp:129] Top shape: 256 512 1 1 (131072)
I0405 18:56:40.209548  1665 net.cpp:137] Memory required for data: 2852652032
I0405 18:56:40.209604  1665 layer_factory.hpp:77] Creating layer score
I0405 18:56:40.209663  1665 net.cpp:84] Creating Layer score
I0405 18:56:40.209722  1665 net.cpp:406] score <- global_pool
I0405 18:56:40.209784  1665 net.cpp:380] score -> score
I0405 18:56:40.211419  1665 net.cpp:122] Setting up score
I0405 18:56:40.211551  1665 net.cpp:129] Top shape: 256 1000 (256000)
I0405 18:56:40.211624  1665 net.cpp:137] Memory required for data: 2853676032
I0405 18:56:40.211689  1665 layer_factory.hpp:77] Creating layer loss
I0405 18:56:40.211778  1665 net.cpp:84] Creating Layer loss
I0405 18:56:40.211836  1665 net.cpp:406] loss <- score
I0405 18:56:40.211891  1665 net.cpp:406] loss <- label
I0405 18:56:40.211967  1665 net.cpp:380] loss -> loss
I0405 18:56:40.212029  1665 layer_factory.hpp:77] Creating layer loss
I0405 18:56:40.213377  1665 net.cpp:122] Setting up loss
I0405 18:56:40.213483  1665 net.cpp:129] Top shape: (1)
I0405 18:56:40.213549  1665 net.cpp:132]     with loss weight 1
I0405 18:56:40.213626  1665 net.cpp:137] Memory required for data: 2853676036
I0405 18:56:40.213681  1665 net.cpp:198] loss needs backward computation.
I0405 18:56:40.213755  1665 net.cpp:198] score needs backward computation.
I0405 18:56:40.213811  1665 net.cpp:198] global_pool needs backward computation.
I0405 18:56:40.214100  1665 net.cpp:198] last_relu needs backward computation.
I0405 18:56:40.214215  1665 net.cpp:198] last_scale needs backward computation.
I0405 18:56:40.214280  1665 net.cpp:198] last_bn needs backward computation.
I0405 18:56:40.214335  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 18:56:40.214391  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 18:56:40.214452  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 18:56:40.214514  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 18:56:40.214566  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 18:56:40.214619  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 18:56:40.214684  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 18:56:40.214778  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 18:56:40.214843  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 18:56:40.214906  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 18:56:40.214975  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 18:56:40.215040  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 18:56:40.215135  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 18:56:40.215200  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 18:56:40.215265  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 18:56:40.215338  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 18:56:40.215417  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 18:56:40.215485  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 18:56:40.215548  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 18:56:40.215611  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 18:56:40.215677  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 18:56:40.215755  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 18:56:40.215819  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 18:56:40.215898  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 18:56:40.215979  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 18:56:40.216033  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 18:56:40.216099  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 18:56:40.216152  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 18:56:40.216205  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 18:56:40.216285  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 18:56:40.216342  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 18:56:40.216398  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 18:56:40.216451  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 18:56:40.216504  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 18:56:40.216558  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 18:56:40.216611  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 18:56:40.216665  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 18:56:40.216727  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 18:56:40.216784  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 18:56:40.216838  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 18:56:40.216899  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 18:56:40.216958  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 18:56:40.217011  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 18:56:40.217073  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 18:56:40.217133  1665 net.cpp:198] conv1 needs backward computation.
I0405 18:56:40.217187  1665 net.cpp:198] data_scale needs backward computation.
I0405 18:56:40.217242  1665 net.cpp:200] data_bn does not need backward computation.
I0405 18:56:40.217295  1665 net.cpp:200] data does not need backward computation.
I0405 18:56:40.217348  1665 net.cpp:242] This network produces output loss
I0405 18:56:40.217432  1665 net.cpp:255] Network initialization done.
I0405 18:56:40.219015  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 18:56:40.219254  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 18:56:40.219331  1665 solver.cpp:172] Creating test net (#0) specified by net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 18:56:40.219465  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 18:56:40.219791  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 18:56:40.220060  1665 layer_factory.hpp:77] Creating layer data
I0405 18:56:40.220135  1665 net.cpp:84] Creating Layer data
I0405 18:56:40.220235  1665 net.cpp:380] data -> data
I0405 18:56:40.220352  1665 net.cpp:380] data -> label
I0405 18:56:40.220403  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 18:56:40.227041  1665 image_data_layer.cpp:53] Shuffling data
I0405 18:56:40.228235  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 18:56:40.229045  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 18:56:40.275701  1665 net.cpp:122] Setting up data
I0405 18:56:40.275854  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 18:56:40.275923  1665 net.cpp:129] Top shape: 100 (100)
I0405 18:56:40.275993  1665 net.cpp:137] Memory required for data: 19661200
I0405 18:56:40.276049  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 18:56:40.276108  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 18:56:40.276168  1665 net.cpp:406] label_data_1_split <- label
I0405 18:56:40.276226  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 18:56:40.276283  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 18:56:40.276391  1665 net.cpp:122] Setting up label_data_1_split
I0405 18:56:40.276474  1665 net.cpp:129] Top shape: 100 (100)
I0405 18:56:40.276540  1665 net.cpp:129] Top shape: 100 (100)
I0405 18:56:40.276597  1665 net.cpp:137] Memory required for data: 19662000
I0405 18:56:40.276662  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 18:56:40.276780  1665 net.cpp:84] Creating Layer data_bn
I0405 18:56:40.276845  1665 net.cpp:406] data_bn <- data
I0405 18:56:40.276908  1665 net.cpp:380] data_bn -> data_bn
I0405 18:56:40.277213  1665 net.cpp:122] Setting up data_bn
I0405 18:56:40.277307  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 18:56:40.277366  1665 net.cpp:137] Memory required for data: 39322800
I0405 18:56:40.277434  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 18:56:40.277498  1665 net.cpp:84] Creating Layer data_scale
I0405 18:56:40.277572  1665 net.cpp:406] data_scale <- data_bn
I0405 18:56:40.277637  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 18:56:40.279255  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 18:56:40.279529  1665 net.cpp:122] Setting up data_scale
I0405 18:56:40.279631  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 18:56:40.279700  1665 net.cpp:137] Memory required for data: 58983600
I0405 18:56:40.279786  1665 layer_factory.hpp:77] Creating layer conv1
I0405 18:56:40.279856  1665 net.cpp:84] Creating Layer conv1
I0405 18:56:40.279917  1665 net.cpp:406] conv1 <- data_bn
I0405 18:56:40.279994  1665 net.cpp:380] conv1 -> conv1
I0405 18:56:40.280391  1665 net.cpp:122] Setting up conv1
I0405 18:56:40.280503  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 18:56:40.280566  1665 net.cpp:137] Memory required for data: 163841200
I0405 18:56:40.280627  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 18:56:40.280688  1665 net.cpp:84] Creating Layer conv1_bn
I0405 18:56:40.280763  1665 net.cpp:406] conv1_bn <- conv1
I0405 18:56:40.280824  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 18:56:40.281064  1665 net.cpp:122] Setting up conv1_bn
I0405 18:56:40.281160  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 18:56:40.281229  1665 net.cpp:137] Memory required for data: 268698800
I0405 18:56:40.281307  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 18:56:40.281368  1665 net.cpp:84] Creating Layer conv1_scale
I0405 18:56:40.281424  1665 net.cpp:406] conv1_scale <- conv1
I0405 18:56:40.281488  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 18:56:40.281595  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 18:56:40.281803  1665 net.cpp:122] Setting up conv1_scale
I0405 18:56:40.281891  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 18:56:40.281947  1665 net.cpp:137] Memory required for data: 373556400
I0405 18:56:40.282006  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 18:56:40.282078  1665 net.cpp:84] Creating Layer conv1_relu
I0405 18:56:40.282128  1665 net.cpp:406] conv1_relu <- conv1
I0405 18:56:40.282186  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 18:56:40.282243  1665 net.cpp:122] Setting up conv1_relu
I0405 18:56:40.282310  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 18:56:40.282390  1665 net.cpp:137] Memory required for data: 478414000
I0405 18:56:40.282485  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 18:56:40.282543  1665 net.cpp:84] Creating Layer conv1_pool
I0405 18:56:40.282599  1665 net.cpp:406] conv1_pool <- conv1
I0405 18:56:40.282654  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 18:56:40.282770  1665 net.cpp:122] Setting up conv1_pool
I0405 18:56:40.282850  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:40.282908  1665 net.cpp:137] Memory required for data: 504628400
I0405 18:56:40.282963  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 18:56:40.283025  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 18:56:40.283082  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 18:56:40.283160  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 18:56:40.283221  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 18:56:40.283319  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 18:56:40.283385  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:40.283454  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:40.283512  1665 net.cpp:137] Memory required for data: 557057200
I0405 18:56:40.283568  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 18:56:40.283637  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 18:56:40.283691  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 18:56:40.283764  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 18:56:40.284329  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 18:56:40.284422  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:40.284489  1665 net.cpp:137] Memory required for data: 583271600
I0405 18:56:40.284559  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 18:56:40.284618  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 18:56:40.284677  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 18:56:40.284777  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 18:56:40.284982  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 18:56:40.285087  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:40.285174  1665 net.cpp:137] Memory required for data: 609486000
I0405 18:56:40.285240  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 18:56:40.285306  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 18:56:40.285372  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 18:56:40.285436  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 18:56:40.285538  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 18:56:40.285697  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 18:56:40.285800  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:40.285863  1665 net.cpp:137] Memory required for data: 635700400
I0405 18:56:40.285957  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 18:56:40.286036  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 18:56:40.286100  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 18:56:40.286164  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 18:56:40.286227  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 18:56:40.286301  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:40.286356  1665 net.cpp:137] Memory required for data: 661914800
I0405 18:56:40.286417  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 18:56:40.286491  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 18:56:40.286553  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 18:56:40.286618  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 18:56:40.287185  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 18:56:40.287281  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:40.287340  1665 net.cpp:137] Memory required for data: 688129200
I0405 18:56:40.287407  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 18:56:40.287503  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 18:56:40.287561  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 18:56:40.287621  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 18:56:40.287679  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 18:56:40.287791  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 18:56:40.287868  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:40.287928  1665 net.cpp:137] Memory required for data: 714343600
I0405 18:56:40.287991  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 18:56:40.288058  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 18:56:40.288136  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 18:56:40.288202  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 18:56:40.288425  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 18:56:40.288522  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:40.288612  1665 net.cpp:137] Memory required for data: 740558000
I0405 18:56:40.288691  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 18:56:40.288758  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 18:56:40.288821  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 18:56:40.288883  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 18:56:40.288995  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 18:56:40.289142  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 18:56:40.289228  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:40.289290  1665 net.cpp:137] Memory required for data: 766772400
I0405 18:56:40.289353  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 18:56:40.289418  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 18:56:40.289505  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 18:56:40.289568  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 18:56:40.289633  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 18:56:40.289696  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:40.289783  1665 net.cpp:137] Memory required for data: 792986800
I0405 18:56:40.289866  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 18:56:40.289947  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 18:56:40.290012  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 18:56:40.290074  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 18:56:40.290134  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 18:56:40.290222  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 18:56:40.290285  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:40.290345  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 18:56:40.290401  1665 net.cpp:137] Memory required for data: 845415600
I0405 18:56:40.290463  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 18:56:40.290526  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 18:56:40.290586  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 18:56:40.290655  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 18:56:40.291545  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 18:56:40.291652  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:40.291746  1665 net.cpp:137] Memory required for data: 858522800
I0405 18:56:40.291815  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 18:56:40.291921  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 18:56:40.291985  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 18:56:40.292050  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 18:56:40.292294  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 18:56:40.292380  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:40.292443  1665 net.cpp:137] Memory required for data: 871630000
I0405 18:56:40.292506  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 18:56:40.292572  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 18:56:40.292635  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 18:56:40.292698  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 18:56:40.292820  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 18:56:40.292999  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 18:56:40.293078  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:40.293140  1665 net.cpp:137] Memory required for data: 884737200
I0405 18:56:40.293205  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 18:56:40.293288  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 18:56:40.293373  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 18:56:40.293434  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 18:56:40.293498  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 18:56:40.293561  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:40.293622  1665 net.cpp:137] Memory required for data: 897844400
I0405 18:56:40.293682  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 18:56:40.293769  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 18:56:40.293833  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 18:56:40.293895  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 18:56:40.295694  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 18:56:40.295820  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:40.295917  1665 net.cpp:137] Memory required for data: 910951600
I0405 18:56:40.295995  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 18:56:40.296062  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 18:56:40.296123  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 18:56:40.296187  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 18:56:40.296459  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 18:56:40.296550  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:40.296613  1665 net.cpp:137] Memory required for data: 924058800
I0405 18:56:40.296679  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 18:56:40.296778  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 18:56:40.296849  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 18:56:40.296908  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 18:56:40.296970  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 18:56:40.297053  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 18:56:40.297120  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:40.297180  1665 net.cpp:137] Memory required for data: 937166000
I0405 18:56:40.297240  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 18:56:40.297304  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 18:56:40.297364  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 18:56:40.297426  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 18:56:40.297685  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 18:56:40.297781  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:40.297843  1665 net.cpp:137] Memory required for data: 950273200
I0405 18:56:40.297914  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 18:56:40.297981  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 18:56:40.298032  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 18:56:40.298095  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 18:56:40.298192  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 18:56:40.298328  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 18:56:40.298405  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:40.298467  1665 net.cpp:137] Memory required for data: 963380400
I0405 18:56:40.298537  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 18:56:40.298594  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 18:56:40.298648  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 18:56:40.298704  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 18:56:40.298789  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 18:56:40.298851  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:40.298911  1665 net.cpp:137] Memory required for data: 976487600
I0405 18:56:40.299000  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 18:56:40.299064  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 18:56:40.299126  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 18:56:40.299188  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 18:56:40.299266  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 18:56:40.299362  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 18:56:40.299430  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:40.299496  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 18:56:40.299557  1665 net.cpp:137] Memory required for data: 1002702000
I0405 18:56:40.299621  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 18:56:40.299688  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 18:56:40.299770  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 18:56:40.299834  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 18:56:40.303855  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 18:56:40.303958  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:40.304018  1665 net.cpp:137] Memory required for data: 1009255600
I0405 18:56:40.304080  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 18:56:40.304143  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 18:56:40.304203  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 18:56:40.304265  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 18:56:40.304493  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 18:56:40.304563  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:40.304621  1665 net.cpp:137] Memory required for data: 1015809200
I0405 18:56:40.304683  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 18:56:40.304764  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 18:56:40.304821  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 18:56:40.304888  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 18:56:40.304986  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 18:56:40.305145  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 18:56:40.305241  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:40.305296  1665 net.cpp:137] Memory required for data: 1022362800
I0405 18:56:40.305354  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 18:56:40.305418  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 18:56:40.305482  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 18:56:40.305538  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 18:56:40.305595  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 18:56:40.305673  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:40.305748  1665 net.cpp:137] Memory required for data: 1028916400
I0405 18:56:40.305804  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 18:56:40.305864  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 18:56:40.305922  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 18:56:40.305986  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 18:56:40.312422  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 18:56:40.312534  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:40.312597  1665 net.cpp:137] Memory required for data: 1035470000
I0405 18:56:40.312691  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 18:56:40.312791  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 18:56:40.312857  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 18:56:40.312919  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 18:56:40.313393  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 18:56:40.313494  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:40.313556  1665 net.cpp:137] Memory required for data: 1042023600
I0405 18:56:40.313638  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 18:56:40.313697  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 18:56:40.313774  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 18:56:40.313850  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 18:56:40.313911  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 18:56:40.313998  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 18:56:40.314054  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:40.314108  1665 net.cpp:137] Memory required for data: 1048577200
I0405 18:56:40.314163  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 18:56:40.314220  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 18:56:40.314275  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 18:56:40.314329  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 18:56:40.314538  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 18:56:40.314620  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:40.314687  1665 net.cpp:137] Memory required for data: 1055130800
I0405 18:56:40.314828  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 18:56:40.314926  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 18:56:40.314999  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 18:56:40.315081  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 18:56:40.315207  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 18:56:40.315390  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 18:56:40.315487  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:40.315560  1665 net.cpp:137] Memory required for data: 1061684400
I0405 18:56:40.315640  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 18:56:40.315732  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 18:56:40.315809  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 18:56:40.315883  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 18:56:40.315985  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 18:56:40.316047  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:40.316135  1665 net.cpp:137] Memory required for data: 1068238000
I0405 18:56:40.316200  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 18:56:40.316265  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 18:56:40.316327  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 18:56:40.316393  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 18:56:40.316532  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 18:56:40.316653  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 18:56:40.316766  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:40.316833  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 18:56:40.316896  1665 net.cpp:137] Memory required for data: 1081345200
I0405 18:56:40.316962  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 18:56:40.317034  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 18:56:40.317101  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 18:56:40.317168  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 18:56:40.329789  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 18:56:40.329888  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:40.329957  1665 net.cpp:137] Memory required for data: 1084622000
I0405 18:56:40.330019  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 18:56:40.330073  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 18:56:40.330126  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 18:56:40.330200  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 18:56:40.330389  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 18:56:40.330505  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:40.330570  1665 net.cpp:137] Memory required for data: 1087898800
I0405 18:56:40.330624  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 18:56:40.330687  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 18:56:40.330760  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 18:56:40.330821  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 18:56:40.330924  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 18:56:40.331084  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 18:56:40.331167  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:40.331225  1665 net.cpp:137] Memory required for data: 1091175600
I0405 18:56:40.331286  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 18:56:40.331355  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 18:56:40.331409  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 18:56:40.331475  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 18:56:40.331535  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 18:56:40.331595  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:40.331667  1665 net.cpp:137] Memory required for data: 1094452400
I0405 18:56:40.331751  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 18:56:40.331821  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 18:56:40.331885  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 18:56:40.331951  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 18:56:40.357074  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 18:56:40.357190  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:40.357250  1665 net.cpp:137] Memory required for data: 1097729200
I0405 18:56:40.357308  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 18:56:40.357370  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 18:56:40.357426  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 18:56:40.357491  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 18:56:40.358950  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 18:56:40.359048  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:40.359113  1665 net.cpp:137] Memory required for data: 1101006000
I0405 18:56:40.359179  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 18:56:40.359241  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 18:56:40.359303  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 18:56:40.359367  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 18:56:40.359427  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 18:56:40.359529  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 18:56:40.359612  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:40.359674  1665 net.cpp:137] Memory required for data: 1104282800
I0405 18:56:40.359750  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 18:56:40.359815  1665 net.cpp:84] Creating Layer last_bn
I0405 18:56:40.359879  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 18:56:40.359946  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 18:56:40.360172  1665 net.cpp:122] Setting up last_bn
I0405 18:56:40.360258  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:40.360321  1665 net.cpp:137] Memory required for data: 1107559600
I0405 18:56:40.360385  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 18:56:40.360456  1665 net.cpp:84] Creating Layer last_scale
I0405 18:56:40.360513  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 18:56:40.360579  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 18:56:40.360682  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 18:56:40.360836  1665 net.cpp:122] Setting up last_scale
I0405 18:56:40.360915  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:40.360976  1665 net.cpp:137] Memory required for data: 1110836400
I0405 18:56:40.361045  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 18:56:40.361104  1665 net.cpp:84] Creating Layer last_relu
I0405 18:56:40.361160  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 18:56:40.361214  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 18:56:40.361271  1665 net.cpp:122] Setting up last_relu
I0405 18:56:40.361335  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 18:56:40.361421  1665 net.cpp:137] Memory required for data: 1114113200
I0405 18:56:40.361481  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 18:56:40.361538  1665 net.cpp:84] Creating Layer global_pool
I0405 18:56:40.361593  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 18:56:40.361651  1665 net.cpp:380] global_pool -> global_pool
I0405 18:56:40.361757  1665 net.cpp:122] Setting up global_pool
I0405 18:56:40.361825  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 18:56:40.361887  1665 net.cpp:137] Memory required for data: 1114318000
I0405 18:56:40.361948  1665 layer_factory.hpp:77] Creating layer score
I0405 18:56:40.362013  1665 net.cpp:84] Creating Layer score
I0405 18:56:40.362073  1665 net.cpp:406] score <- global_pool
I0405 18:56:40.362135  1665 net.cpp:380] score -> score
I0405 18:56:40.363569  1665 net.cpp:122] Setting up score
I0405 18:56:40.363685  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 18:56:40.363791  1665 net.cpp:137] Memory required for data: 1114718000
I0405 18:56:40.363857  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 18:56:40.363934  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 18:56:40.364003  1665 net.cpp:406] score_score_0_split <- score
I0405 18:56:40.364075  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 18:56:40.364137  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 18:56:40.364235  1665 net.cpp:122] Setting up score_score_0_split
I0405 18:56:40.364315  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 18:56:40.364374  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 18:56:40.364431  1665 net.cpp:137] Memory required for data: 1115518000
I0405 18:56:40.364490  1665 layer_factory.hpp:77] Creating layer loss
I0405 18:56:40.364559  1665 net.cpp:84] Creating Layer loss
I0405 18:56:40.364614  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 18:56:40.364672  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 18:56:40.364748  1665 net.cpp:380] loss -> loss
I0405 18:56:40.364811  1665 layer_factory.hpp:77] Creating layer loss
I0405 18:56:40.366138  1665 net.cpp:122] Setting up loss
I0405 18:56:40.366243  1665 net.cpp:129] Top shape: (1)
I0405 18:56:40.366307  1665 net.cpp:132]     with loss weight 1
I0405 18:56:40.366375  1665 net.cpp:137] Memory required for data: 1115518004
I0405 18:56:40.366434  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 18:56:40.366500  1665 net.cpp:84] Creating Layer accuracy
I0405 18:56:40.366559  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 18:56:40.366619  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 18:56:40.366680  1665 net.cpp:380] accuracy -> accuracy
I0405 18:56:40.366762  1665 net.cpp:122] Setting up accuracy
I0405 18:56:40.366822  1665 net.cpp:129] Top shape: (1)
I0405 18:56:40.366894  1665 net.cpp:137] Memory required for data: 1115518008
I0405 18:56:40.366950  1665 net.cpp:200] accuracy does not need backward computation.
I0405 18:56:40.367008  1665 net.cpp:198] loss needs backward computation.
I0405 18:56:40.367066  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 18:56:40.367125  1665 net.cpp:198] score needs backward computation.
I0405 18:56:40.367199  1665 net.cpp:198] global_pool needs backward computation.
I0405 18:56:40.367256  1665 net.cpp:198] last_relu needs backward computation.
I0405 18:56:40.367316  1665 net.cpp:198] last_scale needs backward computation.
I0405 18:56:40.367373  1665 net.cpp:198] last_bn needs backward computation.
I0405 18:56:40.367436  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 18:56:40.367509  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 18:56:40.367568  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 18:56:40.367625  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 18:56:40.367683  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 18:56:40.367760  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 18:56:40.367820  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 18:56:40.367877  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 18:56:40.367940  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 18:56:40.368000  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 18:56:40.368062  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 18:56:40.368124  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 18:56:40.368183  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 18:56:40.368257  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 18:56:40.368335  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 18:56:40.368394  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 18:56:40.368459  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 18:56:40.368520  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 18:56:40.368578  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 18:56:40.368638  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 18:56:40.368695  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 18:56:40.368770  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 18:56:40.368831  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 18:56:40.368894  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 18:56:40.368955  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 18:56:40.369014  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 18:56:40.369089  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 18:56:40.369145  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 18:56:40.369206  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 18:56:40.369266  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 18:56:40.369328  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 18:56:40.369386  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 18:56:40.369463  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 18:56:40.369521  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 18:56:40.369596  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 18:56:40.369652  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 18:56:40.369709  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 18:56:40.369779  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 18:56:40.369854  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 18:56:40.369912  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 18:56:40.369974  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 18:56:40.370036  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 18:56:40.370095  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 18:56:40.370151  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 18:56:40.370208  1665 net.cpp:198] conv1 needs backward computation.
I0405 18:56:40.370266  1665 net.cpp:198] data_scale needs backward computation.
I0405 18:56:40.370327  1665 net.cpp:200] data_bn does not need backward computation.
I0405 18:56:40.370388  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 18:56:40.370457  1665 net.cpp:200] data does not need backward computation.
I0405 18:56:40.370512  1665 net.cpp:242] This network produces output accuracy
I0405 18:56:40.370570  1665 net.cpp:242] This network produces output loss
I0405 18:56:40.370661  1665 net.cpp:255] Network initialization done.
I0405 18:56:40.370949  1665 solver.cpp:56] Solver scaffolding done.
I0405 18:56:40.416373  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: data/resnet10_cvgj_iter_320000.caffemodel
I0405 18:56:40.416621  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 18:56:40.889839  1665 solver.cpp:218] Iteration 0 (1.66762e-09 iter/s, 0.468022s/225 iters), loss = 13.4378
I0405 18:56:40.890064  1665 solver.cpp:237]     Train net output #0: loss = 13.4378 (* 1 = 13.4378 loss)
I0405 18:56:40.890141  1665 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I0405 18:58:19.358297  1665 solver.cpp:218] Iteration 225 (2.28496 iter/s, 98.4702s/225 iters), loss = 0.0896435
I0405 18:58:19.358543  1665 solver.cpp:237]     Train net output #0: loss = 0.0896435 (* 1 = 0.0896435 loss)
I0405 18:58:19.358615  1665 sgd_solver.cpp:105] Iteration 225, lr = 0.000875
I0405 18:59:57.824517  1665 solver.cpp:218] Iteration 450 (2.285 iter/s, 98.4682s/225 iters), loss = 0.0255531
I0405 18:59:57.824821  1665 solver.cpp:237]     Train net output #0: loss = 0.0255531 (* 1 = 0.0255531 loss)
I0405 18:59:57.824893  1665 sgd_solver.cpp:105] Iteration 450, lr = 0.00075
I0405 19:00:05.704727  1665 solver.cpp:330] Iteration 469, Testing net (#0)
I0405 19:01:36.297574  1665 solver.cpp:218] Iteration 675 (2.28484 iter/s, 98.4751s/225 iters), loss = 0.0206996
I0405 19:01:36.297868  1665 solver.cpp:237]     Train net output #0: loss = 0.0206996 (* 1 = 0.0206996 loss)
I0405 19:01:36.297966  1665 sgd_solver.cpp:105] Iteration 675, lr = 0.000625
I0405 19:03:14.761270  1665 solver.cpp:218] Iteration 900 (2.28505 iter/s, 98.4659s/225 iters), loss = 0.0135326
I0405 19:03:14.761525  1665 solver.cpp:237]     Train net output #0: loss = 0.0135326 (* 1 = 0.0135326 loss)
I0405 19:03:14.761603  1665 sgd_solver.cpp:105] Iteration 900, lr = 0.0005
I0405 19:03:30.956574  1665 solver.cpp:330] Iteration 938, Testing net (#0)
I0405 19:04:53.223485  1665 solver.cpp:218] Iteration 1125 (2.28509 iter/s, 98.4645s/225 iters), loss = 0.0133412
I0405 19:04:53.223688  1665 solver.cpp:237]     Train net output #0: loss = 0.0133412 (* 1 = 0.0133412 loss)
I0405 19:04:53.223806  1665 sgd_solver.cpp:105] Iteration 1125, lr = 0.000375
I0405 19:06:31.693184  1665 solver.cpp:218] Iteration 1350 (2.28494 iter/s, 98.4708s/225 iters), loss = 0.00960917
I0405 19:06:31.693477  1665 solver.cpp:237]     Train net output #0: loss = 0.00960915 (* 1 = 0.00960915 loss)
I0405 19:06:31.693574  1665 sgd_solver.cpp:105] Iteration 1350, lr = 0.00025
I0405 19:06:56.201529  1665 solver.cpp:330] Iteration 1407, Testing net (#0)
I0405 19:08:10.155462  1665 solver.cpp:218] Iteration 1575 (2.28518 iter/s, 98.4607s/225 iters), loss = 0.0148291
I0405 19:08:10.155763  1665 solver.cpp:237]     Train net output #0: loss = 0.0148291 (* 1 = 0.0148291 loss)
I0405 19:08:10.155885  1665 sgd_solver.cpp:105] Iteration 1575, lr = 0.000125
I0405 19:09:48.187301  1665 solver.cpp:457] Snapshotting to HDF5 file data/snapshots/train_batch_01_iter_1800.caffemodel.h5
I0405 19:09:48.256345  1665 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file data/snapshots/train_batch_01_iter_1800.solverstate.h5
W0405 19:09:49.342604  1665 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W0405 19:09:49.342792  1665 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W0405 19:09:49.342849  1665 _caffe.cpp:142] Net('confs/sII/mid-caffeNet/inc_train_val.prototxt', 1, weights='data/snapshots/train_batch_01_iter_1800.caffemodel.h5')
I0405 19:09:49.346189  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:09:49.346305  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 19:09:49.346447  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 19:09:49.346822  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 19:09:49.347062  1665 layer_factory.hpp:77] Creating layer data
I0405 19:09:49.347124  1665 net.cpp:84] Creating Layer data
I0405 19:09:49.347168  1665 net.cpp:380] data -> data
I0405 19:09:49.347213  1665 net.cpp:380] data -> label
I0405 19:09:49.347259  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 19:09:49.354457  1665 image_data_layer.cpp:53] Shuffling data
I0405 19:09:49.355545  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 19:09:49.356472  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 19:09:49.400786  1665 net.cpp:122] Setting up data
I0405 19:09:49.400990  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:09:49.401065  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:09:49.401121  1665 net.cpp:137] Memory required for data: 19661200
I0405 19:09:49.401178  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 19:09:49.401242  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 19:09:49.401299  1665 net.cpp:406] label_data_1_split <- label
I0405 19:09:49.401356  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 19:09:49.401422  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 19:09:49.401511  1665 net.cpp:122] Setting up label_data_1_split
I0405 19:09:49.401587  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:09:49.401695  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:09:49.401782  1665 net.cpp:137] Memory required for data: 19662000
I0405 19:09:49.401834  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 19:09:49.401890  1665 net.cpp:84] Creating Layer data_bn
I0405 19:09:49.401945  1665 net.cpp:406] data_bn <- data
I0405 19:09:49.402081  1665 net.cpp:380] data_bn -> data_bn
I0405 19:09:49.402295  1665 net.cpp:122] Setting up data_bn
I0405 19:09:49.402370  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:09:49.402426  1665 net.cpp:137] Memory required for data: 39322800
I0405 19:09:49.402489  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:09:49.402562  1665 net.cpp:84] Creating Layer data_scale
I0405 19:09:49.402617  1665 net.cpp:406] data_scale <- data_bn
I0405 19:09:49.402685  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 19:09:49.404521  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:09:49.404744  1665 net.cpp:122] Setting up data_scale
I0405 19:09:49.404826  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:09:49.404892  1665 net.cpp:137] Memory required for data: 58983600
I0405 19:09:49.404948  1665 layer_factory.hpp:77] Creating layer conv1
I0405 19:09:49.405020  1665 net.cpp:84] Creating Layer conv1
I0405 19:09:49.405086  1665 net.cpp:406] conv1 <- data_bn
I0405 19:09:49.405141  1665 net.cpp:380] conv1 -> conv1
I0405 19:09:49.405488  1665 net.cpp:122] Setting up conv1
I0405 19:09:49.405566  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:09:49.405619  1665 net.cpp:137] Memory required for data: 163841200
I0405 19:09:49.405699  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 19:09:49.405817  1665 net.cpp:84] Creating Layer conv1_bn
I0405 19:09:49.405889  1665 net.cpp:406] conv1_bn <- conv1
I0405 19:09:49.405956  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 19:09:49.406152  1665 net.cpp:122] Setting up conv1_bn
I0405 19:09:49.406225  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:09:49.406280  1665 net.cpp:137] Memory required for data: 268698800
I0405 19:09:49.406348  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:09:49.406404  1665 net.cpp:84] Creating Layer conv1_scale
I0405 19:09:49.406458  1665 net.cpp:406] conv1_scale <- conv1
I0405 19:09:49.406513  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 19:09:49.406601  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:09:49.406783  1665 net.cpp:122] Setting up conv1_scale
I0405 19:09:49.406848  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:09:49.406903  1665 net.cpp:137] Memory required for data: 373556400
I0405 19:09:49.406960  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 19:09:49.407017  1665 net.cpp:84] Creating Layer conv1_relu
I0405 19:09:49.407071  1665 net.cpp:406] conv1_relu <- conv1
I0405 19:09:49.407127  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 19:09:49.407187  1665 net.cpp:122] Setting up conv1_relu
I0405 19:09:49.407244  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:09:49.407299  1665 net.cpp:137] Memory required for data: 478414000
I0405 19:09:49.407352  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 19:09:49.407423  1665 net.cpp:84] Creating Layer conv1_pool
I0405 19:09:49.407475  1665 net.cpp:406] conv1_pool <- conv1
I0405 19:09:49.407532  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 19:09:49.407603  1665 net.cpp:122] Setting up conv1_pool
I0405 19:09:49.407663  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:09:49.407740  1665 net.cpp:137] Memory required for data: 504628400
I0405 19:09:49.407806  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 19:09:49.407862  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 19:09:49.407918  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 19:09:49.407984  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 19:09:49.408041  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 19:09:49.408115  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 19:09:49.408175  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:09:49.408241  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:09:49.408295  1665 net.cpp:137] Memory required for data: 557057200
I0405 19:09:49.408349  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 19:09:49.408406  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 19:09:49.408459  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 19:09:49.408546  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 19:09:49.409015  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 19:09:49.409093  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:09:49.409148  1665 net.cpp:137] Memory required for data: 583271600
I0405 19:09:49.409214  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 19:09:49.409276  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 19:09:49.409332  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 19:09:49.409399  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 19:09:49.409565  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 19:09:49.409637  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:09:49.409698  1665 net.cpp:137] Memory required for data: 609486000
I0405 19:09:49.409760  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:09:49.409821  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 19:09:49.409884  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 19:09:49.409940  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 19:09:49.410025  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:09:49.410148  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 19:09:49.410223  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:09:49.410277  1665 net.cpp:137] Memory required for data: 635700400
I0405 19:09:49.410332  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 19:09:49.410390  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 19:09:49.410445  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 19:09:49.410501  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 19:09:49.410557  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 19:09:49.410631  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:09:49.410693  1665 net.cpp:137] Memory required for data: 661914800
I0405 19:09:49.410771  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 19:09:49.410832  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 19:09:49.410887  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 19:09:49.410957  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 19:09:49.411406  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 19:09:49.411489  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:09:49.411545  1665 net.cpp:137] Memory required for data: 688129200
I0405 19:09:49.411598  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 19:09:49.411659  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 19:09:49.411717  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 19:09:49.411820  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 19:09:49.411876  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 19:09:49.411943  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 19:09:49.412005  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:09:49.412058  1665 net.cpp:137] Memory required for data: 714343600
I0405 19:09:49.412111  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 19:09:49.412169  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 19:09:49.412226  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 19:09:49.412290  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 19:09:49.412473  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 19:09:49.412544  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:09:49.412597  1665 net.cpp:137] Memory required for data: 740558000
I0405 19:09:49.412652  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:09:49.412708  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 19:09:49.412776  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 19:09:49.412832  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 19:09:49.412905  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:09:49.413018  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 19:09:49.413087  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:09:49.413139  1665 net.cpp:137] Memory required for data: 766772400
I0405 19:09:49.413192  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 19:09:49.413245  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 19:09:49.413307  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 19:09:49.413363  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 19:09:49.413425  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 19:09:49.413477  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:09:49.413530  1665 net.cpp:137] Memory required for data: 792986800
I0405 19:09:49.413583  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:09:49.413637  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:09:49.413697  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 19:09:49.413767  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:09:49.413826  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:09:49.413902  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:09:49.413956  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:09:49.414011  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:09:49.414063  1665 net.cpp:137] Memory required for data: 845415600
I0405 19:09:49.414125  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 19:09:49.414211  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 19:09:49.414263  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:09:49.414316  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 19:09:49.415048  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 19:09:49.415119  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:09:49.415172  1665 net.cpp:137] Memory required for data: 858522800
I0405 19:09:49.415225  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 19:09:49.415280  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 19:09:49.415344  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 19:09:49.415407  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 19:09:49.415565  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 19:09:49.415633  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:09:49.415684  1665 net.cpp:137] Memory required for data: 871630000
I0405 19:09:49.415758  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:09:49.415817  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 19:09:49.415871  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 19:09:49.415925  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 19:09:49.416002  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:09:49.416146  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 19:09:49.416213  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:09:49.416268  1665 net.cpp:137] Memory required for data: 884737200
I0405 19:09:49.416332  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 19:09:49.416389  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 19:09:49.416448  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 19:09:49.416514  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 19:09:49.416569  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 19:09:49.416622  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:09:49.416682  1665 net.cpp:137] Memory required for data: 897844400
I0405 19:09:49.416748  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 19:09:49.416805  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 19:09:49.416858  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 19:09:49.416913  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 19:09:49.418637  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 19:09:49.418774  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:09:49.418829  1665 net.cpp:137] Memory required for data: 910951600
I0405 19:09:49.418882  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 19:09:49.419006  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 19:09:49.419087  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:09:49.419186  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 19:09:49.419469  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 19:09:49.419575  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:09:49.419649  1665 net.cpp:137] Memory required for data: 924058800
I0405 19:09:49.419706  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 19:09:49.419795  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 19:09:49.419849  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 19:09:49.419903  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 19:09:49.419956  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 19:09:49.420033  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 19:09:49.420097  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:09:49.420157  1665 net.cpp:137] Memory required for data: 937166000
I0405 19:09:49.420212  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 19:09:49.420269  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 19:09:49.420320  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 19:09:49.420377  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 19:09:49.420543  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 19:09:49.420629  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:09:49.420688  1665 net.cpp:137] Memory required for data: 950273200
I0405 19:09:49.420761  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:09:49.420817  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 19:09:49.420892  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 19:09:49.420954  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 19:09:49.421031  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:09:49.421146  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 19:09:49.421216  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:09:49.421269  1665 net.cpp:137] Memory required for data: 963380400
I0405 19:09:49.421324  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 19:09:49.421384  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 19:09:49.421439  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 19:09:49.421501  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 19:09:49.421559  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 19:09:49.421612  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:09:49.421671  1665 net.cpp:137] Memory required for data: 976487600
I0405 19:09:49.421747  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:09:49.421813  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:09:49.421883  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 19:09:49.421938  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:09:49.421995  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:09:49.422066  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:09:49.422122  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:09:49.422178  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:09:49.422231  1665 net.cpp:137] Memory required for data: 1002702000
I0405 19:09:49.422284  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 19:09:49.422343  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 19:09:49.422396  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:09:49.422462  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 19:09:49.425784  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 19:09:49.425884  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:09:49.425952  1665 net.cpp:137] Memory required for data: 1009255600
I0405 19:09:49.426005  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 19:09:49.426064  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 19:09:49.426120  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 19:09:49.426174  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 19:09:49.426352  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 19:09:49.426447  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:09:49.426512  1665 net.cpp:137] Memory required for data: 1015809200
I0405 19:09:49.426569  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:09:49.426625  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 19:09:49.426684  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 19:09:49.426759  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 19:09:49.426836  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:09:49.426962  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 19:09:49.427026  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:09:49.427098  1665 net.cpp:137] Memory required for data: 1022362800
I0405 19:09:49.427151  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 19:09:49.427218  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 19:09:49.427268  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 19:09:49.427320  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 19:09:49.427372  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 19:09:49.427426  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:09:49.427490  1665 net.cpp:137] Memory required for data: 1028916400
I0405 19:09:49.427546  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 19:09:49.427611  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 19:09:49.427672  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 19:09:49.427748  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 19:09:49.433306  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 19:09:49.433411  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:09:49.433483  1665 net.cpp:137] Memory required for data: 1035470000
I0405 19:09:49.433538  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 19:09:49.433598  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 19:09:49.433657  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:09:49.433706  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 19:09:49.434159  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 19:09:49.434227  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:09:49.434281  1665 net.cpp:137] Memory required for data: 1042023600
I0405 19:09:49.434335  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 19:09:49.434391  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 19:09:49.434446  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 19:09:49.434499  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 19:09:49.434553  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 19:09:49.434613  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 19:09:49.434674  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:09:49.434746  1665 net.cpp:137] Memory required for data: 1048577200
I0405 19:09:49.434801  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 19:09:49.434854  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 19:09:49.434917  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 19:09:49.434968  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 19:09:49.435140  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 19:09:49.435204  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:09:49.435264  1665 net.cpp:137] Memory required for data: 1055130800
I0405 19:09:49.435319  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:09:49.435376  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 19:09:49.435432  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 19:09:49.435483  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 19:09:49.435559  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:09:49.435675  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 19:09:49.435779  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:09:49.435834  1665 net.cpp:137] Memory required for data: 1061684400
I0405 19:09:49.435886  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 19:09:49.435941  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 19:09:49.436003  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 19:09:49.436064  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 19:09:49.436120  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 19:09:49.436180  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:09:49.436249  1665 net.cpp:137] Memory required for data: 1068238000
I0405 19:09:49.436300  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:09:49.436353  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:09:49.436408  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 19:09:49.436460  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:09:49.436516  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:09:49.436592  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:09:49.436648  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:09:49.436707  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:09:49.436791  1665 net.cpp:137] Memory required for data: 1081345200
I0405 19:09:49.436839  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 19:09:49.436897  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 19:09:49.436950  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:09:49.437006  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 19:09:49.447752  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 19:09:49.447849  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:09:49.447908  1665 net.cpp:137] Memory required for data: 1084622000
I0405 19:09:49.447962  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 19:09:49.448024  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 19:09:49.448079  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 19:09:49.448138  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 19:09:49.448307  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 19:09:49.448364  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:09:49.448417  1665 net.cpp:137] Memory required for data: 1087898800
I0405 19:09:49.448465  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:09:49.448521  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 19:09:49.448592  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 19:09:49.448662  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 19:09:49.448761  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:09:49.448881  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 19:09:49.448949  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:09:49.449003  1665 net.cpp:137] Memory required for data: 1091175600
I0405 19:09:49.449057  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 19:09:49.449113  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 19:09:49.449173  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 19:09:49.449225  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 19:09:49.449281  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 19:09:49.449329  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:09:49.449414  1665 net.cpp:137] Memory required for data: 1094452400
I0405 19:09:49.449470  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 19:09:49.449525  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 19:09:49.449579  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 19:09:49.449640  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 19:09:49.470978  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 19:09:49.471083  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:09:49.471143  1665 net.cpp:137] Memory required for data: 1097729200
I0405 19:09:49.471201  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 19:09:49.471262  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 19:09:49.471320  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:09:49.471379  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 19:09:49.472577  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 19:09:49.472676  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:09:49.472757  1665 net.cpp:137] Memory required for data: 1101006000
I0405 19:09:49.472818  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 19:09:49.472877  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 19:09:49.472934  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 19:09:49.472991  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 19:09:49.473048  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 19:09:49.473119  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 19:09:49.473186  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:09:49.473242  1665 net.cpp:137] Memory required for data: 1104282800
I0405 19:09:49.473296  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 19:09:49.473353  1665 net.cpp:84] Creating Layer last_bn
I0405 19:09:49.473407  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 19:09:49.473482  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 19:09:49.473659  1665 net.cpp:122] Setting up last_bn
I0405 19:09:49.473752  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:09:49.473810  1665 net.cpp:137] Memory required for data: 1107559600
I0405 19:09:49.473870  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:09:49.473930  1665 net.cpp:84] Creating Layer last_scale
I0405 19:09:49.473986  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 19:09:49.474047  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 19:09:49.474143  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:09:49.474282  1665 net.cpp:122] Setting up last_scale
I0405 19:09:49.474351  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:09:49.474416  1665 net.cpp:137] Memory required for data: 1110836400
I0405 19:09:49.474476  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 19:09:49.474539  1665 net.cpp:84] Creating Layer last_relu
I0405 19:09:49.474622  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 19:09:49.474710  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 19:09:49.474807  1665 net.cpp:122] Setting up last_relu
I0405 19:09:49.474875  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:09:49.474941  1665 net.cpp:137] Memory required for data: 1114113200
I0405 19:09:49.475000  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 19:09:49.475064  1665 net.cpp:84] Creating Layer global_pool
I0405 19:09:49.475123  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 19:09:49.475186  1665 net.cpp:380] global_pool -> global_pool
I0405 19:09:49.475267  1665 net.cpp:122] Setting up global_pool
I0405 19:09:49.475327  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 19:09:49.475392  1665 net.cpp:137] Memory required for data: 1114318000
I0405 19:09:49.475451  1665 layer_factory.hpp:77] Creating layer score
I0405 19:09:49.475512  1665 net.cpp:84] Creating Layer score
I0405 19:09:49.475571  1665 net.cpp:406] score <- global_pool
I0405 19:09:49.475641  1665 net.cpp:380] score -> score
I0405 19:09:49.476900  1665 net.cpp:122] Setting up score
I0405 19:09:49.476999  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:09:49.477056  1665 net.cpp:137] Memory required for data: 1114718000
I0405 19:09:49.477126  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 19:09:49.477182  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 19:09:49.477237  1665 net.cpp:406] score_score_0_split <- score
I0405 19:09:49.477293  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 19:09:49.477365  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 19:09:49.477478  1665 net.cpp:122] Setting up score_score_0_split
I0405 19:09:49.477550  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:09:49.477602  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:09:49.477661  1665 net.cpp:137] Memory required for data: 1115518000
I0405 19:09:49.477727  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:09:49.477787  1665 net.cpp:84] Creating Layer loss
I0405 19:09:49.477845  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 19:09:49.477897  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 19:09:49.477953  1665 net.cpp:380] loss -> loss
I0405 19:09:49.478011  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:09:49.479128  1665 net.cpp:122] Setting up loss
I0405 19:09:49.479202  1665 net.cpp:129] Top shape: (1)
I0405 19:09:49.479259  1665 net.cpp:132]     with loss weight 1
I0405 19:09:49.479321  1665 net.cpp:137] Memory required for data: 1115518004
I0405 19:09:49.479373  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 19:09:49.479436  1665 net.cpp:84] Creating Layer accuracy
I0405 19:09:49.479494  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 19:09:49.479550  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 19:09:49.479607  1665 net.cpp:380] accuracy -> accuracy
I0405 19:09:49.479672  1665 net.cpp:122] Setting up accuracy
I0405 19:09:49.479740  1665 net.cpp:129] Top shape: (1)
I0405 19:09:49.479792  1665 net.cpp:137] Memory required for data: 1115518008
I0405 19:09:49.479857  1665 net.cpp:200] accuracy does not need backward computation.
I0405 19:09:49.479912  1665 net.cpp:198] loss needs backward computation.
I0405 19:09:49.479965  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 19:09:49.480018  1665 net.cpp:198] score needs backward computation.
I0405 19:09:49.480072  1665 net.cpp:198] global_pool needs backward computation.
I0405 19:09:49.480135  1665 net.cpp:198] last_relu needs backward computation.
I0405 19:09:49.480199  1665 net.cpp:198] last_scale needs backward computation.
I0405 19:09:49.480253  1665 net.cpp:198] last_bn needs backward computation.
I0405 19:09:49.480304  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 19:09:49.480357  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 19:09:49.480412  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 19:09:49.480468  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 19:09:49.480526  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 19:09:49.480579  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 19:09:49.480679  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 19:09:49.480765  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 19:09:49.480823  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 19:09:49.480898  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 19:09:49.480949  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 19:09:49.481000  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 19:09:49.481055  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 19:09:49.481108  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 19:09:49.481170  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 19:09:49.481235  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 19:09:49.481289  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 19:09:49.481343  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 19:09:49.481395  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 19:09:49.481451  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 19:09:49.481506  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 19:09:49.481559  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 19:09:49.481611  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 19:09:49.481670  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 19:09:49.481746  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 19:09:49.481803  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 19:09:49.481854  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 19:09:49.481906  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 19:09:49.481977  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 19:09:49.482030  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 19:09:49.482081  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 19:09:49.482136  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 19:09:49.482192  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 19:09:49.482256  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 19:09:49.482319  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 19:09:49.482373  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 19:09:49.482424  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 19:09:49.482478  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 19:09:49.482530  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 19:09:49.482599  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 19:09:49.482653  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 19:09:49.482703  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 19:09:49.482777  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 19:09:49.482836  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 19:09:49.482890  1665 net.cpp:198] conv1 needs backward computation.
I0405 19:09:49.482946  1665 net.cpp:198] data_scale needs backward computation.
I0405 19:09:49.483001  1665 net.cpp:200] data_bn does not need backward computation.
I0405 19:09:49.483068  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 19:09:49.483124  1665 net.cpp:200] data does not need backward computation.
I0405 19:09:49.483175  1665 net.cpp:242] This network produces output accuracy
I0405 19:09:49.483227  1665 net.cpp:242] This network produces output loss
I0405 19:09:49.483311  1665 net.cpp:255] Network initialization done.
I0405 19:10:27.720824  1665 solver.cpp:44] Initializing solver from parameters: 
test_iter: 0
test_interval: 469
base_lr: 0.001
display: 225
max_iter: 1800
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 1800
snapshot_prefix: "data/snapshots/train_batch_02"
solver_mode: GPU
random_seed: 0
net: "confs/sII/mid-caffeNet/inc_train_val.prototxt"
test_initialization: false
snapshot_format: HDF5
I0405 19:10:27.723654  1665 solver.cpp:87] Creating training net from net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:10:27.724799  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:10:27.724920  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 19:10:27.725047  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0405 19:10:27.725134  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0405 19:10:27.725405  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/train_batch_02_filelist.txt"
    batch_size: 256
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I0405 19:10:27.725648  1665 layer_factory.hpp:77] Creating layer data
I0405 19:10:27.725739  1665 net.cpp:84] Creating Layer data
I0405 19:10:27.725807  1665 net.cpp:380] data -> data
I0405 19:10:27.725860  1665 net.cpp:380] data -> label
I0405 19:10:27.725915  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/train_batch_02_filelist.txt
I0405 19:10:27.733952  1665 image_data_layer.cpp:53] Shuffling data
I0405 19:10:27.735206  1665 image_data_layer.cpp:63] A total of 47963 images.
I0405 19:10:27.737397  1665 image_data_layer.cpp:90] output data size: 256,3,128,128
I0405 19:10:27.867022  1665 net.cpp:122] Setting up data
I0405 19:10:27.867287  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 19:10:27.867377  1665 net.cpp:129] Top shape: 256 (256)
I0405 19:10:27.867444  1665 net.cpp:137] Memory required for data: 50332672
I0405 19:10:27.867509  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 19:10:27.867583  1665 net.cpp:84] Creating Layer data_bn
I0405 19:10:27.867647  1665 net.cpp:406] data_bn <- data
I0405 19:10:27.867863  1665 net.cpp:380] data_bn -> data_bn
I0405 19:10:27.868105  1665 net.cpp:122] Setting up data_bn
I0405 19:10:27.868208  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 19:10:27.868273  1665 net.cpp:137] Memory required for data: 100664320
I0405 19:10:27.868346  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:10:27.868429  1665 net.cpp:84] Creating Layer data_scale
I0405 19:10:27.868507  1665 net.cpp:406] data_scale <- data_bn
I0405 19:10:27.868583  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 19:10:27.873199  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:10:27.873447  1665 net.cpp:122] Setting up data_scale
I0405 19:10:27.873567  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 19:10:27.873648  1665 net.cpp:137] Memory required for data: 150995968
I0405 19:10:27.873740  1665 layer_factory.hpp:77] Creating layer conv1
I0405 19:10:27.873817  1665 net.cpp:84] Creating Layer conv1
I0405 19:10:27.873883  1665 net.cpp:406] conv1 <- data_bn
I0405 19:10:27.873950  1665 net.cpp:380] conv1 -> conv1
I0405 19:10:27.874275  1665 net.cpp:122] Setting up conv1
I0405 19:10:27.874372  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 19:10:27.874460  1665 net.cpp:137] Memory required for data: 419431424
I0405 19:10:27.874528  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 19:10:27.874603  1665 net.cpp:84] Creating Layer conv1_bn
I0405 19:10:27.874670  1665 net.cpp:406] conv1_bn <- conv1
I0405 19:10:27.874748  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 19:10:27.874974  1665 net.cpp:122] Setting up conv1_bn
I0405 19:10:27.875073  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 19:10:27.875139  1665 net.cpp:137] Memory required for data: 687866880
I0405 19:10:27.875208  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:10:27.875277  1665 net.cpp:84] Creating Layer conv1_scale
I0405 19:10:27.875341  1665 net.cpp:406] conv1_scale <- conv1
I0405 19:10:27.875406  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 19:10:27.875500  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:10:27.875661  1665 net.cpp:122] Setting up conv1_scale
I0405 19:10:27.875743  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 19:10:27.875811  1665 net.cpp:137] Memory required for data: 956302336
I0405 19:10:27.875888  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 19:10:27.875957  1665 net.cpp:84] Creating Layer conv1_relu
I0405 19:10:27.876020  1665 net.cpp:406] conv1_relu <- conv1
I0405 19:10:27.876088  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 19:10:27.876168  1665 net.cpp:122] Setting up conv1_relu
I0405 19:10:27.876240  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 19:10:27.876296  1665 net.cpp:137] Memory required for data: 1224737792
I0405 19:10:27.876359  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 19:10:27.876431  1665 net.cpp:84] Creating Layer conv1_pool
I0405 19:10:27.876499  1665 net.cpp:406] conv1_pool <- conv1
I0405 19:10:27.876564  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 19:10:27.876658  1665 net.cpp:122] Setting up conv1_pool
I0405 19:10:27.876737  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:10:27.876801  1665 net.cpp:137] Memory required for data: 1291846656
I0405 19:10:27.876864  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 19:10:27.876933  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 19:10:27.876996  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 19:10:27.877070  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 19:10:27.877137  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 19:10:27.877231  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 19:10:27.877312  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:10:27.877375  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:10:27.877439  1665 net.cpp:137] Memory required for data: 1426064384
I0405 19:10:27.877501  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 19:10:27.877571  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 19:10:27.877635  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 19:10:27.877701  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 19:10:27.878283  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 19:10:27.878381  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:10:27.878446  1665 net.cpp:137] Memory required for data: 1493173248
I0405 19:10:27.878510  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 19:10:27.878579  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 19:10:27.878644  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 19:10:27.878710  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 19:10:27.878959  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 19:10:27.879047  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:10:27.879112  1665 net.cpp:137] Memory required for data: 1560282112
I0405 19:10:27.879179  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:10:27.879261  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 19:10:27.879324  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 19:10:27.879398  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 19:10:27.879482  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:10:27.879643  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 19:10:27.879736  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:10:27.879804  1665 net.cpp:137] Memory required for data: 1627390976
I0405 19:10:27.879873  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 19:10:27.879940  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 19:10:27.880002  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 19:10:27.880072  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 19:10:27.880139  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 19:10:27.880206  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:10:27.880270  1665 net.cpp:137] Memory required for data: 1694499840
I0405 19:10:27.880334  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 19:10:27.880403  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 19:10:27.880470  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 19:10:27.880535  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 19:10:27.881072  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 19:10:27.881173  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:10:27.881245  1665 net.cpp:137] Memory required for data: 1761608704
I0405 19:10:27.881304  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 19:10:27.881371  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 19:10:27.881435  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 19:10:27.881498  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 19:10:27.881564  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 19:10:27.881650  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 19:10:27.881749  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:10:27.881822  1665 net.cpp:137] Memory required for data: 1828717568
I0405 19:10:27.881882  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 19:10:27.881995  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 19:10:27.882073  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 19:10:27.882138  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 19:10:27.882341  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 19:10:27.882426  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:10:27.882489  1665 net.cpp:137] Memory required for data: 1895826432
I0405 19:10:27.882558  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:10:27.882634  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 19:10:27.882699  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 19:10:27.882797  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 19:10:27.882899  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:10:27.883044  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 19:10:27.883128  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:10:27.883193  1665 net.cpp:137] Memory required for data: 1962935296
I0405 19:10:27.883258  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 19:10:27.883327  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 19:10:27.883391  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 19:10:27.883456  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 19:10:27.883527  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 19:10:27.883589  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:10:27.883651  1665 net.cpp:137] Memory required for data: 2030044160
I0405 19:10:27.883731  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:10:27.883801  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:10:27.883864  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 19:10:27.883929  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:10:27.883996  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:10:27.884107  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:10:27.884193  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:10:27.884250  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:10:27.884313  1665 net.cpp:137] Memory required for data: 2164261888
I0405 19:10:27.884382  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 19:10:27.884470  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 19:10:27.884531  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:10:27.884603  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 19:10:27.885452  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 19:10:27.885555  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:10:27.885622  1665 net.cpp:137] Memory required for data: 2197816320
I0405 19:10:27.885689  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 19:10:27.885772  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 19:10:27.885840  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 19:10:27.885906  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 19:10:27.886113  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 19:10:27.886199  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:10:27.886265  1665 net.cpp:137] Memory required for data: 2231370752
I0405 19:10:27.886332  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:10:27.886399  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 19:10:27.886463  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 19:10:27.886538  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 19:10:27.886633  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:10:27.886797  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 19:10:27.886870  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:10:27.886934  1665 net.cpp:137] Memory required for data: 2264925184
I0405 19:10:27.886998  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 19:10:27.887069  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 19:10:27.887133  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 19:10:27.887197  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 19:10:27.887264  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 19:10:27.887328  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:10:27.887392  1665 net.cpp:137] Memory required for data: 2298479616
I0405 19:10:27.887472  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 19:10:27.887539  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 19:10:27.887598  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 19:10:27.887665  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 19:10:27.889199  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 19:10:27.889295  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:10:27.889361  1665 net.cpp:137] Memory required for data: 2332034048
I0405 19:10:27.889427  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 19:10:27.889497  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 19:10:27.889562  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:10:27.889637  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 19:10:27.889961  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 19:10:27.890051  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:10:27.890117  1665 net.cpp:137] Memory required for data: 2365588480
I0405 19:10:27.890182  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 19:10:27.890249  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 19:10:27.890312  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 19:10:27.890400  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 19:10:27.890470  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 19:10:27.890563  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 19:10:27.890648  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:10:27.890727  1665 net.cpp:137] Memory required for data: 2399142912
I0405 19:10:27.890792  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 19:10:27.890858  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 19:10:27.890921  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 19:10:27.890985  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 19:10:27.891191  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 19:10:27.891273  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:10:27.891336  1665 net.cpp:137] Memory required for data: 2432697344
I0405 19:10:27.891410  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:10:27.891506  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 19:10:27.891572  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 19:10:27.891636  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 19:10:27.891749  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:10:27.891894  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 19:10:27.891979  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:10:27.892051  1665 net.cpp:137] Memory required for data: 2466251776
I0405 19:10:27.892124  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 19:10:27.892197  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 19:10:27.892256  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 19:10:27.892314  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 19:10:27.892380  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 19:10:27.892446  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:10:27.892509  1665 net.cpp:137] Memory required for data: 2499806208
I0405 19:10:27.892572  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:10:27.892638  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:10:27.892701  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 19:10:27.892791  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:10:27.892846  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:10:27.892941  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:10:27.893012  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:10:27.893080  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:10:27.893142  1665 net.cpp:137] Memory required for data: 2566915072
I0405 19:10:27.893204  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 19:10:27.893273  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 19:10:27.893337  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:10:27.893401  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 19:10:27.897122  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 19:10:27.897219  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:10:27.897291  1665 net.cpp:137] Memory required for data: 2583692288
I0405 19:10:27.897351  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 19:10:27.897411  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 19:10:27.897476  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 19:10:27.897536  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 19:10:27.897768  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 19:10:27.897855  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:10:27.897912  1665 net.cpp:137] Memory required for data: 2600469504
I0405 19:10:27.897971  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:10:27.898036  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 19:10:27.898165  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 19:10:27.898241  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 19:10:27.898337  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:10:27.898488  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 19:10:27.898566  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:10:27.898624  1665 net.cpp:137] Memory required for data: 2617246720
I0405 19:10:27.898685  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 19:10:27.898757  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 19:10:27.898815  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 19:10:27.898880  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 19:10:27.898959  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 19:10:27.899017  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:10:27.899080  1665 net.cpp:137] Memory required for data: 2634023936
I0405 19:10:27.899144  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 19:10:27.899211  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 19:10:27.899268  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 19:10:27.899327  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 19:10:27.905447  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 19:10:27.905542  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:10:27.905611  1665 net.cpp:137] Memory required for data: 2650801152
I0405 19:10:27.905671  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 19:10:27.905746  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 19:10:27.905829  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:10:27.905889  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 19:10:27.906340  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 19:10:27.906427  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:10:27.906495  1665 net.cpp:137] Memory required for data: 2667578368
I0405 19:10:27.906581  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 19:10:27.906643  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 19:10:27.906702  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 19:10:27.906780  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 19:10:27.906842  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 19:10:27.906922  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 19:10:27.906997  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:10:27.907057  1665 net.cpp:137] Memory required for data: 2684355584
I0405 19:10:27.907112  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 19:10:27.907172  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 19:10:27.907229  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 19:10:27.907295  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 19:10:27.907500  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 19:10:27.907577  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:10:27.907631  1665 net.cpp:137] Memory required for data: 2701132800
I0405 19:10:27.907693  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:10:27.907773  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 19:10:27.907838  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 19:10:27.907903  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 19:10:27.907996  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:10:27.908164  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 19:10:27.908249  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:10:27.908316  1665 net.cpp:137] Memory required for data: 2717910016
I0405 19:10:27.908382  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 19:10:27.908452  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 19:10:27.908516  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 19:10:27.908579  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 19:10:27.908645  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 19:10:27.908710  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:10:27.908794  1665 net.cpp:137] Memory required for data: 2734687232
I0405 19:10:27.908857  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:10:27.908928  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:10:27.908991  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 19:10:27.909056  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:10:27.909127  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:10:27.909224  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:10:27.909294  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:10:27.909358  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:10:27.909421  1665 net.cpp:137] Memory required for data: 2768241664
I0405 19:10:27.909483  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 19:10:27.909556  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 19:10:27.909621  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:10:27.909706  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 19:10:27.921612  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 19:10:27.921758  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:10:27.921833  1665 net.cpp:137] Memory required for data: 2776630272
I0405 19:10:27.921924  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 19:10:27.921988  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 19:10:27.922060  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 19:10:27.922127  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 19:10:27.922322  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 19:10:27.922408  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:10:27.922468  1665 net.cpp:137] Memory required for data: 2785018880
I0405 19:10:27.922531  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:10:27.922601  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 19:10:27.922688  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 19:10:27.922755  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 19:10:27.922854  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:10:27.923118  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 19:10:27.923491  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:10:27.923578  1665 net.cpp:137] Memory required for data: 2793407488
I0405 19:10:27.923660  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 19:10:27.923749  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 19:10:27.923818  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 19:10:27.923884  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 19:10:27.923949  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 19:10:27.924012  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:10:27.924085  1665 net.cpp:137] Memory required for data: 2801796096
I0405 19:10:27.924149  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 19:10:27.924221  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 19:10:27.924285  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 19:10:27.924352  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 19:10:27.955132  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 19:10:27.955269  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:10:27.955371  1665 net.cpp:137] Memory required for data: 2810184704
I0405 19:10:27.955430  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 19:10:27.955483  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 19:10:27.955539  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:10:27.955596  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 19:10:27.957478  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 19:10:27.957569  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:10:27.957623  1665 net.cpp:137] Memory required for data: 2818573312
I0405 19:10:27.957679  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 19:10:27.957746  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 19:10:27.957799  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 19:10:27.957857  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 19:10:27.957912  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 19:10:27.957988  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 19:10:27.958065  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:10:27.958117  1665 net.cpp:137] Memory required for data: 2826961920
I0405 19:10:27.958173  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 19:10:27.958228  1665 net.cpp:84] Creating Layer last_bn
I0405 19:10:27.958283  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 19:10:27.958338  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 19:10:27.958566  1665 net.cpp:122] Setting up last_bn
I0405 19:10:27.958632  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:10:27.958688  1665 net.cpp:137] Memory required for data: 2835350528
I0405 19:10:27.958765  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:10:27.958823  1665 net.cpp:84] Creating Layer last_scale
I0405 19:10:27.958875  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 19:10:27.958928  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 19:10:27.959018  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:10:27.959174  1665 net.cpp:122] Setting up last_scale
I0405 19:10:27.959240  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:10:27.959292  1665 net.cpp:137] Memory required for data: 2843739136
I0405 19:10:27.959347  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 19:10:27.959405  1665 net.cpp:84] Creating Layer last_relu
I0405 19:10:27.959457  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 19:10:27.959511  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 19:10:27.959566  1665 net.cpp:122] Setting up last_relu
I0405 19:10:27.959620  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:10:27.959672  1665 net.cpp:137] Memory required for data: 2852127744
I0405 19:10:27.959730  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 19:10:27.959787  1665 net.cpp:84] Creating Layer global_pool
I0405 19:10:27.959856  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 19:10:27.959908  1665 net.cpp:380] global_pool -> global_pool
I0405 19:10:27.959983  1665 net.cpp:122] Setting up global_pool
I0405 19:10:27.960034  1665 net.cpp:129] Top shape: 256 512 1 1 (131072)
I0405 19:10:27.960083  1665 net.cpp:137] Memory required for data: 2852652032
I0405 19:10:27.960139  1665 layer_factory.hpp:77] Creating layer score
I0405 19:10:27.960196  1665 net.cpp:84] Creating Layer score
I0405 19:10:27.960248  1665 net.cpp:406] score <- global_pool
I0405 19:10:27.960319  1665 net.cpp:380] score -> score
I0405 19:10:27.961858  1665 net.cpp:122] Setting up score
I0405 19:10:27.961951  1665 net.cpp:129] Top shape: 256 1000 (256000)
I0405 19:10:27.962000  1665 net.cpp:137] Memory required for data: 2853676032
I0405 19:10:27.962062  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:10:27.962152  1665 net.cpp:84] Creating Layer loss
I0405 19:10:27.962200  1665 net.cpp:406] loss <- score
I0405 19:10:27.962246  1665 net.cpp:406] loss <- label
I0405 19:10:27.962293  1665 net.cpp:380] loss -> loss
I0405 19:10:27.962345  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:10:27.963783  1665 net.cpp:122] Setting up loss
I0405 19:10:27.963872  1665 net.cpp:129] Top shape: (1)
I0405 19:10:27.963922  1665 net.cpp:132]     with loss weight 1
I0405 19:10:27.963986  1665 net.cpp:137] Memory required for data: 2853676036
I0405 19:10:27.964035  1665 net.cpp:198] loss needs backward computation.
I0405 19:10:27.964083  1665 net.cpp:198] score needs backward computation.
I0405 19:10:27.964133  1665 net.cpp:198] global_pool needs backward computation.
I0405 19:10:27.964180  1665 net.cpp:198] last_relu needs backward computation.
I0405 19:10:27.964231  1665 net.cpp:198] last_scale needs backward computation.
I0405 19:10:27.964277  1665 net.cpp:198] last_bn needs backward computation.
I0405 19:10:27.964326  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 19:10:27.964376  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 19:10:27.964422  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 19:10:27.964475  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 19:10:27.964526  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 19:10:27.964576  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 19:10:27.964624  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 19:10:27.964673  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 19:10:27.964735  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 19:10:27.964788  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 19:10:27.964836  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 19:10:27.964885  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 19:10:27.964934  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 19:10:27.964982  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 19:10:27.965031  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 19:10:27.965090  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 19:10:27.965139  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 19:10:27.965188  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 19:10:27.965238  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 19:10:27.965287  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 19:10:27.965335  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 19:10:27.965384  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 19:10:27.965431  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 19:10:27.965481  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 19:10:27.965526  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 19:10:27.965576  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 19:10:27.965624  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 19:10:27.965673  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 19:10:27.965751  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 19:10:27.965817  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 19:10:27.965867  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 19:10:27.965916  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 19:10:27.965965  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 19:10:27.966013  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 19:10:27.966061  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 19:10:27.966111  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 19:10:27.966161  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 19:10:27.966217  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 19:10:27.966264  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 19:10:27.966312  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 19:10:27.966361  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 19:10:27.966415  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 19:10:27.966464  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 19:10:27.966511  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 19:10:27.966559  1665 net.cpp:198] conv1 needs backward computation.
I0405 19:10:27.966609  1665 net.cpp:198] data_scale needs backward computation.
I0405 19:10:27.966658  1665 net.cpp:200] data_bn does not need backward computation.
I0405 19:10:27.966707  1665 net.cpp:200] data does not need backward computation.
I0405 19:10:27.966771  1665 net.cpp:242] This network produces output loss
I0405 19:10:27.966863  1665 net.cpp:255] Network initialization done.
I0405 19:10:27.968391  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:10:27.968520  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 19:10:27.968574  1665 solver.cpp:172] Creating test net (#0) specified by net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:10:27.968705  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 19:10:27.969136  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 19:10:27.969451  1665 layer_factory.hpp:77] Creating layer data
I0405 19:10:27.969507  1665 net.cpp:84] Creating Layer data
I0405 19:10:27.969568  1665 net.cpp:380] data -> data
I0405 19:10:27.969624  1665 net.cpp:380] data -> label
I0405 19:10:27.969688  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 19:10:27.976927  1665 image_data_layer.cpp:53] Shuffling data
I0405 19:10:27.977989  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 19:10:27.978658  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 19:10:28.022842  1665 net.cpp:122] Setting up data
I0405 19:10:28.023001  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:10:28.023092  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:10:28.023154  1665 net.cpp:137] Memory required for data: 19661200
I0405 19:10:28.023217  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 19:10:28.023418  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 19:10:28.023502  1665 net.cpp:406] label_data_1_split <- label
I0405 19:10:28.023579  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 19:10:28.023648  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 19:10:28.023782  1665 net.cpp:122] Setting up label_data_1_split
I0405 19:10:28.023875  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:10:28.023933  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:10:28.023996  1665 net.cpp:137] Memory required for data: 19662000
I0405 19:10:28.024061  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 19:10:28.024134  1665 net.cpp:84] Creating Layer data_bn
I0405 19:10:28.024217  1665 net.cpp:406] data_bn <- data
I0405 19:10:28.024284  1665 net.cpp:380] data_bn -> data_bn
I0405 19:10:28.025929  1665 net.cpp:122] Setting up data_bn
I0405 19:10:28.026057  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:10:28.026135  1665 net.cpp:137] Memory required for data: 39322800
I0405 19:10:28.026211  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:10:28.026281  1665 net.cpp:84] Creating Layer data_scale
I0405 19:10:28.026346  1665 net.cpp:406] data_scale <- data_bn
I0405 19:10:28.026417  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 19:10:28.026528  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:10:28.026767  1665 net.cpp:122] Setting up data_scale
I0405 19:10:28.026847  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:10:28.026911  1665 net.cpp:137] Memory required for data: 58983600
I0405 19:10:28.026980  1665 layer_factory.hpp:77] Creating layer conv1
I0405 19:10:28.027048  1665 net.cpp:84] Creating Layer conv1
I0405 19:10:28.027115  1665 net.cpp:406] conv1 <- data_bn
I0405 19:10:28.027184  1665 net.cpp:380] conv1 -> conv1
I0405 19:10:28.027604  1665 net.cpp:122] Setting up conv1
I0405 19:10:28.027693  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:10:28.027765  1665 net.cpp:137] Memory required for data: 163841200
I0405 19:10:28.027832  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 19:10:28.027899  1665 net.cpp:84] Creating Layer conv1_bn
I0405 19:10:28.027961  1665 net.cpp:406] conv1_bn <- conv1
I0405 19:10:28.028026  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 19:10:28.028275  1665 net.cpp:122] Setting up conv1_bn
I0405 19:10:28.028373  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:10:28.028465  1665 net.cpp:137] Memory required for data: 268698800
I0405 19:10:28.028556  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:10:28.028621  1665 net.cpp:84] Creating Layer conv1_scale
I0405 19:10:28.028744  1665 net.cpp:406] conv1_scale <- conv1
I0405 19:10:28.028839  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 19:10:28.028952  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:10:28.029152  1665 net.cpp:122] Setting up conv1_scale
I0405 19:10:28.029237  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:10:28.029301  1665 net.cpp:137] Memory required for data: 373556400
I0405 19:10:28.029366  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 19:10:28.029433  1665 net.cpp:84] Creating Layer conv1_relu
I0405 19:10:28.029520  1665 net.cpp:406] conv1_relu <- conv1
I0405 19:10:28.029592  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 19:10:28.029656  1665 net.cpp:122] Setting up conv1_relu
I0405 19:10:28.029742  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:10:28.029819  1665 net.cpp:137] Memory required for data: 478414000
I0405 19:10:28.029911  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 19:10:28.029980  1665 net.cpp:84] Creating Layer conv1_pool
I0405 19:10:28.030051  1665 net.cpp:406] conv1_pool <- conv1
I0405 19:10:28.030113  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 19:10:28.030226  1665 net.cpp:122] Setting up conv1_pool
I0405 19:10:28.030295  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:10:28.030357  1665 net.cpp:137] Memory required for data: 504628400
I0405 19:10:28.030416  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 19:10:28.030498  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 19:10:28.030568  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 19:10:28.030637  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 19:10:28.030715  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 19:10:28.030817  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 19:10:28.030894  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:10:28.030966  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:10:28.031024  1665 net.cpp:137] Memory required for data: 557057200
I0405 19:10:28.031087  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 19:10:28.031154  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 19:10:28.031234  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 19:10:28.031299  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 19:10:28.032009  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 19:10:28.032115  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:10:28.032173  1665 net.cpp:137] Memory required for data: 583271600
I0405 19:10:28.032240  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 19:10:28.032308  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 19:10:28.032389  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 19:10:28.032456  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 19:10:28.032737  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 19:10:28.032958  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:10:28.033042  1665 net.cpp:137] Memory required for data: 609486000
I0405 19:10:28.033133  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:10:28.033210  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 19:10:28.033283  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 19:10:28.033346  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 19:10:28.033481  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:10:28.033695  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 19:10:28.033790  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:10:28.033864  1665 net.cpp:137] Memory required for data: 635700400
I0405 19:10:28.033941  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 19:10:28.034015  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 19:10:28.034083  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 19:10:28.034162  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 19:10:28.034226  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 19:10:28.034299  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:10:28.034371  1665 net.cpp:137] Memory required for data: 661914800
I0405 19:10:28.034435  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 19:10:28.034512  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 19:10:28.034591  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 19:10:28.034663  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 19:10:28.035393  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 19:10:28.035485  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:10:28.035558  1665 net.cpp:137] Memory required for data: 688129200
I0405 19:10:28.035627  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 19:10:28.035697  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 19:10:28.035784  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 19:10:28.035851  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 19:10:28.035918  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 19:10:28.036010  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 19:10:28.036098  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:10:28.036171  1665 net.cpp:137] Memory required for data: 714343600
I0405 19:10:28.036234  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 19:10:28.036304  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 19:10:28.036397  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 19:10:28.036490  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 19:10:28.036795  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 19:10:28.036890  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:10:28.036959  1665 net.cpp:137] Memory required for data: 740558000
I0405 19:10:28.037032  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:10:28.037106  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 19:10:28.037180  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 19:10:28.037261  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 19:10:28.037371  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:10:28.037540  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 19:10:28.037621  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:10:28.037689  1665 net.cpp:137] Memory required for data: 766772400
I0405 19:10:28.037782  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 19:10:28.037856  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 19:10:28.037928  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 19:10:28.037997  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 19:10:28.038069  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 19:10:28.038139  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:10:28.038210  1665 net.cpp:137] Memory required for data: 792986800
I0405 19:10:28.038327  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:10:28.038398  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:10:28.038465  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 19:10:28.038539  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:10:28.038810  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:10:28.038944  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:10:28.039034  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:10:28.039108  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:10:28.039173  1665 net.cpp:137] Memory required for data: 845415600
I0405 19:10:28.039280  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 19:10:28.039360  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 19:10:28.039428  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:10:28.039503  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 19:10:28.040750  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 19:10:28.040861  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:10:28.040951  1665 net.cpp:137] Memory required for data: 858522800
I0405 19:10:28.041016  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 19:10:28.041092  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 19:10:28.041163  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 19:10:28.041249  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 19:10:28.041503  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 19:10:28.041582  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:10:28.041654  1665 net.cpp:137] Memory required for data: 871630000
I0405 19:10:28.041724  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:10:28.041802  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 19:10:28.041875  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 19:10:28.041942  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 19:10:28.042047  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:10:28.042222  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 19:10:28.042309  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:10:28.042377  1665 net.cpp:137] Memory required for data: 884737200
I0405 19:10:28.042448  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 19:10:28.042518  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 19:10:28.042582  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 19:10:28.042654  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 19:10:28.042752  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 19:10:28.042825  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:10:28.042888  1665 net.cpp:137] Memory required for data: 897844400
I0405 19:10:28.042953  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 19:10:28.043025  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 19:10:28.043107  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 19:10:28.043179  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 19:10:28.045372  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 19:10:28.045487  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:10:28.045560  1665 net.cpp:137] Memory required for data: 910951600
I0405 19:10:28.045625  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 19:10:28.045694  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 19:10:28.045778  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:10:28.045859  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 19:10:28.046239  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 19:10:28.046329  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:10:28.046388  1665 net.cpp:137] Memory required for data: 924058800
I0405 19:10:28.046453  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 19:10:28.046521  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 19:10:28.046587  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 19:10:28.046651  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 19:10:28.046732  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 19:10:28.046828  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 19:10:28.046909  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:10:28.046974  1665 net.cpp:137] Memory required for data: 937166000
I0405 19:10:28.047051  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 19:10:28.047120  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 19:10:28.047186  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 19:10:28.047253  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 19:10:28.047513  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 19:10:28.047619  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:10:28.047679  1665 net.cpp:137] Memory required for data: 950273200
I0405 19:10:28.047771  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:10:28.047839  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 19:10:28.047904  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 19:10:28.047971  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 19:10:28.048069  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:10:28.048233  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 19:10:28.048310  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:10:28.048372  1665 net.cpp:137] Memory required for data: 963380400
I0405 19:10:28.048434  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 19:10:28.048525  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 19:10:28.048586  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 19:10:28.048648  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 19:10:28.048709  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 19:10:28.048799  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:10:28.048859  1665 net.cpp:137] Memory required for data: 976487600
I0405 19:10:28.048923  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:10:28.048991  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:10:28.049063  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 19:10:28.049131  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:10:28.049206  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:10:28.049300  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:10:28.049371  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:10:28.049437  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:10:28.049502  1665 net.cpp:137] Memory required for data: 1002702000
I0405 19:10:28.049566  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 19:10:28.049638  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 19:10:28.049723  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:10:28.049809  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 19:10:28.054961  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 19:10:28.055101  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:10:28.055167  1665 net.cpp:137] Memory required for data: 1009255600
I0405 19:10:28.055236  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 19:10:28.055325  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 19:10:28.055385  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 19:10:28.055454  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 19:10:28.055701  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 19:10:28.055789  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:10:28.055856  1665 net.cpp:137] Memory required for data: 1015809200
I0405 19:10:28.055943  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:10:28.056020  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 19:10:28.056104  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 19:10:28.056170  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 19:10:28.056278  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:10:28.056460  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 19:10:28.056546  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:10:28.056617  1665 net.cpp:137] Memory required for data: 1022362800
I0405 19:10:28.056689  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 19:10:28.056774  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 19:10:28.056840  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 19:10:28.056908  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 19:10:28.056978  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 19:10:28.057041  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:10:28.057109  1665 net.cpp:137] Memory required for data: 1028916400
I0405 19:10:28.057185  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 19:10:28.057252  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 19:10:28.057332  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 19:10:28.057400  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 19:10:28.066174  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 19:10:28.066283  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:10:28.066346  1665 net.cpp:137] Memory required for data: 1035470000
I0405 19:10:28.066413  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 19:10:28.066483  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 19:10:28.066558  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:10:28.066620  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 19:10:28.067281  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 19:10:28.067363  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:10:28.067421  1665 net.cpp:137] Memory required for data: 1042023600
I0405 19:10:28.067481  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 19:10:28.067543  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 19:10:28.067607  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 19:10:28.067673  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 19:10:28.067755  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 19:10:28.067854  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 19:10:28.067919  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:10:28.067981  1665 net.cpp:137] Memory required for data: 1048577200
I0405 19:10:28.068042  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 19:10:28.068127  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 19:10:28.068218  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 19:10:28.068284  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 19:10:28.068536  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 19:10:28.068606  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:10:28.068670  1665 net.cpp:137] Memory required for data: 1055130800
I0405 19:10:28.068759  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:10:28.068838  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 19:10:28.068904  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 19:10:28.068969  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 19:10:28.069073  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:10:28.069236  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 19:10:28.069316  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:10:28.069377  1665 net.cpp:137] Memory required for data: 1061684400
I0405 19:10:28.069453  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 19:10:28.069515  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 19:10:28.069579  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 19:10:28.069648  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 19:10:28.069728  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 19:10:28.069808  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:10:28.069873  1665 net.cpp:137] Memory required for data: 1068238000
I0405 19:10:28.069938  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:10:28.070008  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:10:28.070077  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 19:10:28.070147  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:10:28.070214  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:10:28.070320  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:10:28.070407  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:10:28.070472  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:10:28.070538  1665 net.cpp:137] Memory required for data: 1081345200
I0405 19:10:28.070605  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 19:10:28.070677  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 19:10:28.070765  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:10:28.070834  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 19:10:28.087908  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 19:10:28.088019  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:10:28.088088  1665 net.cpp:137] Memory required for data: 1084622000
I0405 19:10:28.088156  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 19:10:28.088223  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 19:10:28.088289  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 19:10:28.088354  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 19:10:28.088587  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 19:10:28.088673  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:10:28.088775  1665 net.cpp:137] Memory required for data: 1087898800
I0405 19:10:28.088852  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:10:28.088922  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 19:10:28.088989  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 19:10:28.089056  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 19:10:28.089162  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:10:28.089318  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 19:10:28.089398  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:10:28.089475  1665 net.cpp:137] Memory required for data: 1091175600
I0405 19:10:28.089543  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 19:10:28.089612  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 19:10:28.089679  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 19:10:28.089769  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 19:10:28.089872  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 19:10:28.089943  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:10:28.090006  1665 net.cpp:137] Memory required for data: 1094452400
I0405 19:10:28.090075  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 19:10:28.090148  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 19:10:28.090225  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 19:10:28.090293  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 19:10:28.124145  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 19:10:28.124295  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:10:28.124375  1665 net.cpp:137] Memory required for data: 1097729200
I0405 19:10:28.124449  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 19:10:28.124543  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 19:10:28.124614  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:10:28.124686  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 19:10:28.126605  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 19:10:28.126730  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:10:28.126801  1665 net.cpp:137] Memory required for data: 1101006000
I0405 19:10:28.126875  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 19:10:28.126942  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 19:10:28.127010  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 19:10:28.127084  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 19:10:28.127152  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 19:10:28.127251  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 19:10:28.127339  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:10:28.127399  1665 net.cpp:137] Memory required for data: 1104282800
I0405 19:10:28.127462  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 19:10:28.127529  1665 net.cpp:84] Creating Layer last_bn
I0405 19:10:28.127604  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 19:10:28.127688  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 19:10:28.127977  1665 net.cpp:122] Setting up last_bn
I0405 19:10:28.128062  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:10:28.128125  1665 net.cpp:137] Memory required for data: 1107559600
I0405 19:10:28.128195  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:10:28.128263  1665 net.cpp:84] Creating Layer last_scale
I0405 19:10:28.128329  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 19:10:28.128396  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 19:10:28.128502  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:10:28.128660  1665 net.cpp:122] Setting up last_scale
I0405 19:10:28.128804  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:10:28.128885  1665 net.cpp:137] Memory required for data: 1110836400
I0405 19:10:28.128952  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 19:10:28.129021  1665 net.cpp:84] Creating Layer last_relu
I0405 19:10:28.129097  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 19:10:28.129173  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 19:10:28.129238  1665 net.cpp:122] Setting up last_relu
I0405 19:10:28.129302  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:10:28.129369  1665 net.cpp:137] Memory required for data: 1114113200
I0405 19:10:28.129432  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 19:10:28.129499  1665 net.cpp:84] Creating Layer global_pool
I0405 19:10:28.129564  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 19:10:28.129635  1665 net.cpp:380] global_pool -> global_pool
I0405 19:10:28.129752  1665 net.cpp:122] Setting up global_pool
I0405 19:10:28.129830  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 19:10:28.129894  1665 net.cpp:137] Memory required for data: 1114318000
I0405 19:10:28.129962  1665 layer_factory.hpp:77] Creating layer score
I0405 19:10:28.130079  1665 net.cpp:84] Creating Layer score
I0405 19:10:28.130156  1665 net.cpp:406] score <- global_pool
I0405 19:10:28.130223  1665 net.cpp:380] score -> score
I0405 19:10:28.131827  1665 net.cpp:122] Setting up score
I0405 19:10:28.131911  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:10:28.131971  1665 net.cpp:137] Memory required for data: 1114718000
I0405 19:10:28.132040  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 19:10:28.132107  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 19:10:28.132167  1665 net.cpp:406] score_score_0_split <- score
I0405 19:10:28.132228  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 19:10:28.132290  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 19:10:28.132385  1665 net.cpp:122] Setting up score_score_0_split
I0405 19:10:28.132459  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:10:28.132519  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:10:28.132591  1665 net.cpp:137] Memory required for data: 1115518000
I0405 19:10:28.132652  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:10:28.132712  1665 net.cpp:84] Creating Layer loss
I0405 19:10:28.132792  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 19:10:28.132850  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 19:10:28.132920  1665 net.cpp:380] loss -> loss
I0405 19:10:28.132992  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:10:28.134296  1665 net.cpp:122] Setting up loss
I0405 19:10:28.134397  1665 net.cpp:129] Top shape: (1)
I0405 19:10:28.134502  1665 net.cpp:132]     with loss weight 1
I0405 19:10:28.134588  1665 net.cpp:137] Memory required for data: 1115518004
I0405 19:10:28.134647  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 19:10:28.134735  1665 net.cpp:84] Creating Layer accuracy
I0405 19:10:28.134799  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 19:10:28.134865  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 19:10:28.134927  1665 net.cpp:380] accuracy -> accuracy
I0405 19:10:28.134992  1665 net.cpp:122] Setting up accuracy
I0405 19:10:28.135064  1665 net.cpp:129] Top shape: (1)
I0405 19:10:28.135125  1665 net.cpp:137] Memory required for data: 1115518008
I0405 19:10:28.135185  1665 net.cpp:200] accuracy does not need backward computation.
I0405 19:10:28.135247  1665 net.cpp:198] loss needs backward computation.
I0405 19:10:28.135309  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 19:10:28.135370  1665 net.cpp:198] score needs backward computation.
I0405 19:10:28.135430  1665 net.cpp:198] global_pool needs backward computation.
I0405 19:10:28.135490  1665 net.cpp:198] last_relu needs backward computation.
I0405 19:10:28.135548  1665 net.cpp:198] last_scale needs backward computation.
I0405 19:10:28.135612  1665 net.cpp:198] last_bn needs backward computation.
I0405 19:10:28.135671  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 19:10:28.135748  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 19:10:28.135809  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 19:10:28.135879  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 19:10:28.135939  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 19:10:28.136003  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 19:10:28.136070  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 19:10:28.136134  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 19:10:28.136194  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 19:10:28.136255  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 19:10:28.136315  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 19:10:28.136375  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 19:10:28.136437  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 19:10:28.136498  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 19:10:28.136565  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 19:10:28.136626  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 19:10:28.136706  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 19:10:28.136806  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 19:10:28.136868  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 19:10:28.136926  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 19:10:28.136984  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 19:10:28.137056  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 19:10:28.137123  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 19:10:28.137185  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 19:10:28.137245  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 19:10:28.137306  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 19:10:28.137374  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 19:10:28.137435  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 19:10:28.137495  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 19:10:28.137560  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 19:10:28.137624  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 19:10:28.137689  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 19:10:28.137774  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 19:10:28.137835  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 19:10:28.137912  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 19:10:28.137969  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 19:10:28.138029  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 19:10:28.138098  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 19:10:28.138181  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 19:10:28.138247  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 19:10:28.138309  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 19:10:28.138370  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 19:10:28.138448  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 19:10:28.138509  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 19:10:28.138568  1665 net.cpp:198] conv1 needs backward computation.
I0405 19:10:28.138629  1665 net.cpp:198] data_scale needs backward computation.
I0405 19:10:28.138696  1665 net.cpp:200] data_bn does not need backward computation.
I0405 19:10:28.138775  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 19:10:28.138837  1665 net.cpp:200] data does not need backward computation.
I0405 19:10:28.138895  1665 net.cpp:242] This network produces output accuracy
I0405 19:10:28.138960  1665 net.cpp:242] This network produces output loss
I0405 19:10:28.139065  1665 net.cpp:255] Network initialization done.
I0405 19:10:28.139366  1665 solver.cpp:56] Solver scaffolding done.
I0405 19:10:28.180799  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: data/resnet10_cvgj_iter_320000.caffemodel
I0405 19:10:28.181025  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 19:10:28.653245  1665 solver.cpp:218] Iteration 0 (1.6694e-09 iter/s, 0.467907s/225 iters), loss = 13.0965
I0405 19:10:28.653470  1665 solver.cpp:237]     Train net output #0: loss = 13.0965 (* 1 = 13.0965 loss)
I0405 19:10:28.653558  1665 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I0405 19:12:07.138962  1665 solver.cpp:218] Iteration 225 (2.2846 iter/s, 98.4855s/225 iters), loss = 0.223808
I0405 19:12:07.139190  1665 solver.cpp:237]     Train net output #0: loss = 0.223808 (* 1 = 0.223808 loss)
I0405 19:12:07.139289  1665 sgd_solver.cpp:105] Iteration 225, lr = 0.000875
I0405 19:13:45.607230  1665 solver.cpp:218] Iteration 450 (2.285 iter/s, 98.4684s/225 iters), loss = 0.0705148
I0405 19:13:45.607465  1665 solver.cpp:237]     Train net output #0: loss = 0.0705148 (* 1 = 0.0705148 loss)
I0405 19:13:45.607565  1665 sgd_solver.cpp:105] Iteration 450, lr = 0.00075
I0405 19:13:53.487967  1665 solver.cpp:330] Iteration 469, Testing net (#0)
I0405 19:15:24.079586  1665 solver.cpp:218] Iteration 675 (2.28489 iter/s, 98.4728s/225 iters), loss = 0.0368877
I0405 19:15:24.079916  1665 solver.cpp:237]     Train net output #0: loss = 0.0368877 (* 1 = 0.0368877 loss)
I0405 19:15:24.079986  1665 sgd_solver.cpp:105] Iteration 675, lr = 0.000625
I0405 19:17:02.552999  1665 solver.cpp:218] Iteration 900 (2.28487 iter/s, 98.4741s/225 iters), loss = 0.0286173
I0405 19:17:02.553246  1665 solver.cpp:237]     Train net output #0: loss = 0.0286173 (* 1 = 0.0286173 loss)
I0405 19:17:02.553367  1665 sgd_solver.cpp:105] Iteration 900, lr = 0.0005
I0405 19:17:18.748014  1665 solver.cpp:330] Iteration 938, Testing net (#0)
I0405 19:18:41.025878  1665 solver.cpp:218] Iteration 1125 (2.28487 iter/s, 98.4738s/225 iters), loss = 0.0425283
I0405 19:18:41.026167  1665 solver.cpp:237]     Train net output #0: loss = 0.0425283 (* 1 = 0.0425283 loss)
I0405 19:18:41.026254  1665 sgd_solver.cpp:105] Iteration 1125, lr = 0.000375
I0405 19:20:19.499862  1665 solver.cpp:218] Iteration 1350 (2.28484 iter/s, 98.4751s/225 iters), loss = 0.0293441
I0405 19:20:19.500272  1665 solver.cpp:237]     Train net output #0: loss = 0.0293441 (* 1 = 0.0293441 loss)
I0405 19:20:19.500350  1665 sgd_solver.cpp:105] Iteration 1350, lr = 0.00025
I0405 19:20:44.007537  1665 solver.cpp:330] Iteration 1407, Testing net (#0)
I0405 19:21:57.973742  1665 solver.cpp:218] Iteration 1575 (2.28485 iter/s, 98.4749s/225 iters), loss = 0.0361351
I0405 19:21:57.974140  1665 solver.cpp:237]     Train net output #0: loss = 0.0361351 (* 1 = 0.0361351 loss)
I0405 19:21:57.974222  1665 sgd_solver.cpp:105] Iteration 1575, lr = 0.000125
I0405 19:23:36.023448  1665 solver.cpp:457] Snapshotting to HDF5 file data/snapshots/train_batch_02_iter_1800.caffemodel.h5
I0405 19:23:36.106401  1665 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file data/snapshots/train_batch_02_iter_1800.solverstate.h5
W0405 19:23:37.546180  1665 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W0405 19:23:37.546610  1665 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W0405 19:23:37.546761  1665 _caffe.cpp:142] Net('confs/sII/mid-caffeNet/inc_train_val.prototxt', 1, weights='data/snapshots/train_batch_02_iter_1800.caffemodel.h5')
I0405 19:23:37.551353  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:23:37.551555  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 19:23:37.551687  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 19:23:37.552057  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 19:23:37.552352  1665 layer_factory.hpp:77] Creating layer data
I0405 19:23:37.552470  1665 net.cpp:84] Creating Layer data
I0405 19:23:37.552546  1665 net.cpp:380] data -> data
I0405 19:23:37.552599  1665 net.cpp:380] data -> label
I0405 19:23:37.552686  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 19:23:37.560804  1665 image_data_layer.cpp:53] Shuffling data
I0405 19:23:37.562026  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 19:23:37.563014  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 19:23:37.609380  1665 net.cpp:122] Setting up data
I0405 19:23:37.609711  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:23:37.609830  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:23:37.609889  1665 net.cpp:137] Memory required for data: 19661200
I0405 19:23:37.609961  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 19:23:37.610057  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 19:23:37.610139  1665 net.cpp:406] label_data_1_split <- label
I0405 19:23:37.610221  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 19:23:37.610301  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 19:23:37.610445  1665 net.cpp:122] Setting up label_data_1_split
I0405 19:23:37.610556  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:23:37.610618  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:23:37.610675  1665 net.cpp:137] Memory required for data: 19662000
I0405 19:23:37.610754  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 19:23:37.610821  1665 net.cpp:84] Creating Layer data_bn
I0405 19:23:37.610879  1665 net.cpp:406] data_bn <- data
I0405 19:23:37.610939  1665 net.cpp:380] data_bn -> data_bn
I0405 19:23:37.611161  1665 net.cpp:122] Setting up data_bn
I0405 19:23:37.611263  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:23:37.611335  1665 net.cpp:137] Memory required for data: 39322800
I0405 19:23:37.611397  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:23:37.611476  1665 net.cpp:84] Creating Layer data_scale
I0405 19:23:37.611536  1665 net.cpp:406] data_scale <- data_bn
I0405 19:23:37.611596  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 19:23:37.611680  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:23:37.611873  1665 net.cpp:122] Setting up data_scale
I0405 19:23:37.611986  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:23:37.612046  1665 net.cpp:137] Memory required for data: 58983600
I0405 19:23:37.612107  1665 layer_factory.hpp:77] Creating layer conv1
I0405 19:23:37.612183  1665 net.cpp:84] Creating Layer conv1
I0405 19:23:37.612246  1665 net.cpp:406] conv1 <- data_bn
I0405 19:23:37.612306  1665 net.cpp:380] conv1 -> conv1
I0405 19:23:37.614385  1665 net.cpp:122] Setting up conv1
I0405 19:23:37.614564  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:23:37.614673  1665 net.cpp:137] Memory required for data: 163841200
I0405 19:23:37.614784  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 19:23:37.614847  1665 net.cpp:84] Creating Layer conv1_bn
I0405 19:23:37.614907  1665 net.cpp:406] conv1_bn <- conv1
I0405 19:23:37.614967  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 19:23:37.615154  1665 net.cpp:122] Setting up conv1_bn
I0405 19:23:37.615272  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:23:37.615332  1665 net.cpp:137] Memory required for data: 268698800
I0405 19:23:37.615393  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:23:37.615459  1665 net.cpp:84] Creating Layer conv1_scale
I0405 19:23:37.615520  1665 net.cpp:406] conv1_scale <- conv1
I0405 19:23:37.615604  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 19:23:37.615701  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:23:37.615873  1665 net.cpp:122] Setting up conv1_scale
I0405 19:23:37.615974  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:23:37.616032  1665 net.cpp:137] Memory required for data: 373556400
I0405 19:23:37.616093  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 19:23:37.616153  1665 net.cpp:84] Creating Layer conv1_relu
I0405 19:23:37.616223  1665 net.cpp:406] conv1_relu <- conv1
I0405 19:23:37.616279  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 19:23:37.616344  1665 net.cpp:122] Setting up conv1_relu
I0405 19:23:37.616401  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:23:37.616474  1665 net.cpp:137] Memory required for data: 478414000
I0405 19:23:37.616535  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 19:23:37.616602  1665 net.cpp:84] Creating Layer conv1_pool
I0405 19:23:37.616662  1665 net.cpp:406] conv1_pool <- conv1
I0405 19:23:37.616737  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 19:23:37.616818  1665 net.cpp:122] Setting up conv1_pool
I0405 19:23:37.616880  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:23:37.616940  1665 net.cpp:137] Memory required for data: 504628400
I0405 19:23:37.616997  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 19:23:37.617065  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 19:23:37.617125  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 19:23:37.617189  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 19:23:37.617249  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 19:23:37.617326  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 19:23:37.617395  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:23:37.617465  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:23:37.617522  1665 net.cpp:137] Memory required for data: 557057200
I0405 19:23:37.617578  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 19:23:37.617646  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 19:23:37.617708  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 19:23:37.617772  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 19:23:37.618222  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 19:23:37.618322  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:23:37.618381  1665 net.cpp:137] Memory required for data: 583271600
I0405 19:23:37.618439  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 19:23:37.618516  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 19:23:37.618578  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 19:23:37.618638  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 19:23:37.618820  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 19:23:37.618916  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:23:37.618988  1665 net.cpp:137] Memory required for data: 609486000
I0405 19:23:37.619071  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:23:37.619139  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 19:23:37.619199  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 19:23:37.619256  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 19:23:37.619349  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:23:37.619482  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 19:23:37.619580  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:23:37.619638  1665 net.cpp:137] Memory required for data: 635700400
I0405 19:23:37.619702  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 19:23:37.619786  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 19:23:37.619846  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 19:23:37.619905  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 19:23:37.619964  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 19:23:37.620034  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:23:37.620091  1665 net.cpp:137] Memory required for data: 661914800
I0405 19:23:37.620148  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 19:23:37.620208  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 19:23:37.620273  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 19:23:37.620335  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 19:23:37.620805  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 19:23:37.620913  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:23:37.621013  1665 net.cpp:137] Memory required for data: 688129200
I0405 19:23:37.621083  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 19:23:37.621143  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 19:23:37.621201  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 19:23:37.621258  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 19:23:37.621325  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 19:23:37.621397  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 19:23:37.621476  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:23:37.621536  1665 net.cpp:137] Memory required for data: 714343600
I0405 19:23:37.621600  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 19:23:37.621662  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 19:23:37.621739  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 19:23:37.621812  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 19:23:37.622040  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 19:23:37.622136  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:23:37.622203  1665 net.cpp:137] Memory required for data: 740558000
I0405 19:23:37.622262  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:23:37.622320  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 19:23:37.622376  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 19:23:37.622449  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 19:23:37.622529  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:23:37.622659  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 19:23:37.622756  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:23:37.622815  1665 net.cpp:137] Memory required for data: 766772400
I0405 19:23:37.622875  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 19:23:37.622936  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 19:23:37.622995  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 19:23:37.623054  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 19:23:37.623113  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 19:23:37.623172  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:23:37.623231  1665 net.cpp:137] Memory required for data: 792986800
I0405 19:23:37.623301  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:23:37.623363  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:23:37.623423  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 19:23:37.623487  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:23:37.623546  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:23:37.623628  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:23:37.623697  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:23:37.623772  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:23:37.623839  1665 net.cpp:137] Memory required for data: 845415600
I0405 19:23:37.623898  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 19:23:37.623960  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 19:23:37.624019  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:23:37.624079  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 19:23:37.624846  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 19:23:37.624963  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:23:37.625025  1665 net.cpp:137] Memory required for data: 858522800
I0405 19:23:37.625085  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 19:23:37.625147  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 19:23:37.625207  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 19:23:37.625267  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 19:23:37.625452  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 19:23:37.625515  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:23:37.625573  1665 net.cpp:137] Memory required for data: 871630000
I0405 19:23:37.625634  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:23:37.625703  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 19:23:37.625780  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 19:23:37.625839  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 19:23:37.625919  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:23:37.626041  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 19:23:37.626148  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:23:37.626207  1665 net.cpp:137] Memory required for data: 884737200
I0405 19:23:37.626267  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 19:23:37.626328  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 19:23:37.626387  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 19:23:37.626463  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 19:23:37.626525  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 19:23:37.626592  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:23:37.626652  1665 net.cpp:137] Memory required for data: 897844400
I0405 19:23:37.626709  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 19:23:37.626790  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 19:23:37.626852  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 19:23:37.626909  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 19:23:37.628407  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 19:23:37.628547  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:23:37.628635  1665 net.cpp:137] Memory required for data: 910951600
I0405 19:23:37.628703  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 19:23:37.628830  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 19:23:37.628964  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:23:37.629035  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 19:23:37.629281  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 19:23:37.629362  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:23:37.629424  1665 net.cpp:137] Memory required for data: 924058800
I0405 19:23:37.629490  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 19:23:37.629552  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 19:23:37.629611  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 19:23:37.629669  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 19:23:37.629757  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 19:23:37.629828  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 19:23:37.629887  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:23:37.629946  1665 net.cpp:137] Memory required for data: 937166000
I0405 19:23:37.630015  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 19:23:37.630084  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 19:23:37.630144  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 19:23:37.630208  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 19:23:37.630379  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 19:23:37.630481  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:23:37.630542  1665 net.cpp:137] Memory required for data: 950273200
I0405 19:23:37.630604  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:23:37.630666  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 19:23:37.630750  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 19:23:37.630815  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 19:23:37.630894  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:23:37.631019  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 19:23:37.631079  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:23:37.631144  1665 net.cpp:137] Memory required for data: 963380400
I0405 19:23:37.631201  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 19:23:37.631263  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 19:23:37.631321  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 19:23:37.631377  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 19:23:37.631438  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 19:23:37.631505  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:23:37.631579  1665 net.cpp:137] Memory required for data: 976487600
I0405 19:23:37.631639  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:23:37.631700  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:23:37.631784  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 19:23:37.631850  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:23:37.631917  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:23:37.632006  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:23:37.632068  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:23:37.632127  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:23:37.632184  1665 net.cpp:137] Memory required for data: 1002702000
I0405 19:23:37.632243  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 19:23:37.632306  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 19:23:37.632365  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:23:37.632450  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 19:23:37.636173  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 19:23:37.636305  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:23:37.636370  1665 net.cpp:137] Memory required for data: 1009255600
I0405 19:23:37.636430  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 19:23:37.636545  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 19:23:37.636651  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 19:23:37.636750  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 19:23:37.636951  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 19:23:37.637055  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:23:37.637121  1665 net.cpp:137] Memory required for data: 1015809200
I0405 19:23:37.637187  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:23:37.637254  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 19:23:37.637341  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 19:23:37.637410  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 19:23:37.637501  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:23:37.637683  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 19:23:37.637766  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:23:37.637833  1665 net.cpp:137] Memory required for data: 1022362800
I0405 19:23:37.637933  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 19:23:37.638003  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 19:23:37.638065  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 19:23:37.638125  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 19:23:37.638188  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 19:23:37.638243  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:23:37.638305  1665 net.cpp:137] Memory required for data: 1028916400
I0405 19:23:37.638363  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 19:23:37.638422  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 19:23:37.638491  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 19:23:37.638559  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 19:23:37.645027  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 19:23:37.645177  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:23:37.645247  1665 net.cpp:137] Memory required for data: 1035470000
I0405 19:23:37.645341  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 19:23:37.645409  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 19:23:37.645478  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:23:37.645543  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 19:23:37.646044  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 19:23:37.646154  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:23:37.646219  1665 net.cpp:137] Memory required for data: 1042023600
I0405 19:23:37.646299  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 19:23:37.646375  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 19:23:37.646454  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 19:23:37.646518  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 19:23:37.646581  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 19:23:37.646656  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 19:23:37.646729  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:23:37.646804  1665 net.cpp:137] Memory required for data: 1048577200
I0405 19:23:37.646867  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 19:23:37.646951  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 19:23:37.647017  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 19:23:37.647081  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 19:23:37.647303  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 19:23:37.647423  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:23:37.647500  1665 net.cpp:137] Memory required for data: 1055130800
I0405 19:23:37.647573  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:23:37.647688  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 19:23:37.647774  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 19:23:37.647843  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 19:23:37.647939  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:23:37.648080  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 19:23:37.648188  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:23:37.648255  1665 net.cpp:137] Memory required for data: 1061684400
I0405 19:23:37.648321  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 19:23:37.648396  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 19:23:37.648480  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 19:23:37.648546  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 19:23:37.648613  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 19:23:37.648681  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:23:37.648769  1665 net.cpp:137] Memory required for data: 1068238000
I0405 19:23:37.648849  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:23:37.648931  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:23:37.648998  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 19:23:37.649062  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:23:37.649132  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:23:37.649225  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:23:37.649296  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:23:37.649363  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:23:37.649430  1665 net.cpp:137] Memory required for data: 1081345200
I0405 19:23:37.649500  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 19:23:37.649570  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 19:23:37.649644  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:23:37.649720  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 19:23:37.661614  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 19:23:37.661725  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:23:37.661794  1665 net.cpp:137] Memory required for data: 1084622000
I0405 19:23:37.661859  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 19:23:37.661924  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 19:23:37.661985  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 19:23:37.662045  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 19:23:37.662237  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 19:23:37.662329  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:23:37.662387  1665 net.cpp:137] Memory required for data: 1087898800
I0405 19:23:37.662464  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:23:37.662525  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 19:23:37.662583  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 19:23:37.662739  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 19:23:37.662844  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:23:37.662964  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 19:23:37.663055  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:23:37.663115  1665 net.cpp:137] Memory required for data: 1091175600
I0405 19:23:37.663177  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 19:23:37.663237  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 19:23:37.663296  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 19:23:37.663357  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 19:23:37.663424  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 19:23:37.663487  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:23:37.663545  1665 net.cpp:137] Memory required for data: 1094452400
I0405 19:23:37.663614  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 19:23:37.663673  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 19:23:37.663748  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 19:23:37.663815  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 19:23:37.687122  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 19:23:37.687254  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:23:37.687320  1665 net.cpp:137] Memory required for data: 1097729200
I0405 19:23:37.687407  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 19:23:37.687489  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 19:23:37.687562  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:23:37.687629  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 19:23:37.689337  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 19:23:37.689431  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:23:37.689498  1665 net.cpp:137] Memory required for data: 1101006000
I0405 19:23:37.689596  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 19:23:37.689657  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 19:23:37.689724  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 19:23:37.689785  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 19:23:37.689841  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 19:23:37.689927  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 19:23:37.690023  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:23:37.690080  1665 net.cpp:137] Memory required for data: 1104282800
I0405 19:23:37.690136  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 19:23:37.690209  1665 net.cpp:84] Creating Layer last_bn
I0405 19:23:37.690264  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 19:23:37.690322  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 19:23:37.690544  1665 net.cpp:122] Setting up last_bn
I0405 19:23:37.690623  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:23:37.690680  1665 net.cpp:137] Memory required for data: 1107559600
I0405 19:23:37.690752  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:23:37.690821  1665 net.cpp:84] Creating Layer last_scale
I0405 19:23:37.690877  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 19:23:37.690939  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 19:23:37.691036  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:23:37.691226  1665 net.cpp:122] Setting up last_scale
I0405 19:23:37.691334  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:23:37.691390  1665 net.cpp:137] Memory required for data: 1110836400
I0405 19:23:37.691454  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 19:23:37.691514  1665 net.cpp:84] Creating Layer last_relu
I0405 19:23:37.691570  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 19:23:37.691637  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 19:23:37.691702  1665 net.cpp:122] Setting up last_relu
I0405 19:23:37.691776  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:23:37.691830  1665 net.cpp:137] Memory required for data: 1114113200
I0405 19:23:37.691885  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 19:23:37.691946  1665 net.cpp:84] Creating Layer global_pool
I0405 19:23:37.692003  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 19:23:37.692067  1665 net.cpp:380] global_pool -> global_pool
I0405 19:23:37.692149  1665 net.cpp:122] Setting up global_pool
I0405 19:23:37.692210  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 19:23:37.692265  1665 net.cpp:137] Memory required for data: 1114318000
I0405 19:23:37.692320  1665 layer_factory.hpp:77] Creating layer score
I0405 19:23:37.692405  1665 net.cpp:84] Creating Layer score
I0405 19:23:37.692467  1665 net.cpp:406] score <- global_pool
I0405 19:23:37.692966  1665 net.cpp:380] score -> score
I0405 19:23:37.694396  1665 net.cpp:122] Setting up score
I0405 19:23:37.694586  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:23:37.694676  1665 net.cpp:137] Memory required for data: 1114718000
I0405 19:23:37.694756  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 19:23:37.694823  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 19:23:37.694885  1665 net.cpp:406] score_score_0_split <- score
I0405 19:23:37.694990  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 19:23:37.695055  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 19:23:37.695152  1665 net.cpp:122] Setting up score_score_0_split
I0405 19:23:37.695243  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:23:37.695302  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:23:37.695374  1665 net.cpp:137] Memory required for data: 1115518000
I0405 19:23:37.695430  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:23:37.695492  1665 net.cpp:84] Creating Layer loss
I0405 19:23:37.695554  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 19:23:37.695617  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 19:23:37.695675  1665 net.cpp:380] loss -> loss
I0405 19:23:37.695745  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:23:37.696959  1665 net.cpp:122] Setting up loss
I0405 19:23:37.697036  1665 net.cpp:129] Top shape: (1)
I0405 19:23:37.697093  1665 net.cpp:132]     with loss weight 1
I0405 19:23:37.697175  1665 net.cpp:137] Memory required for data: 1115518004
I0405 19:23:37.697240  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 19:23:37.697299  1665 net.cpp:84] Creating Layer accuracy
I0405 19:23:37.697355  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 19:23:37.697412  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 19:23:37.697474  1665 net.cpp:380] accuracy -> accuracy
I0405 19:23:37.697535  1665 net.cpp:122] Setting up accuracy
I0405 19:23:37.697638  1665 net.cpp:129] Top shape: (1)
I0405 19:23:37.697727  1665 net.cpp:137] Memory required for data: 1115518008
I0405 19:23:37.697783  1665 net.cpp:200] accuracy does not need backward computation.
I0405 19:23:37.697839  1665 net.cpp:198] loss needs backward computation.
I0405 19:23:37.697923  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 19:23:37.697988  1665 net.cpp:198] score needs backward computation.
I0405 19:23:37.698045  1665 net.cpp:198] global_pool needs backward computation.
I0405 19:23:37.698101  1665 net.cpp:198] last_relu needs backward computation.
I0405 19:23:37.698155  1665 net.cpp:198] last_scale needs backward computation.
I0405 19:23:37.698210  1665 net.cpp:198] last_bn needs backward computation.
I0405 19:23:37.698263  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 19:23:37.698319  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 19:23:37.698375  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 19:23:37.698431  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 19:23:37.698505  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 19:23:37.698561  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 19:23:37.698616  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 19:23:37.698673  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 19:23:37.698755  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 19:23:37.698820  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 19:23:37.698879  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 19:23:37.698941  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 19:23:37.699002  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 19:23:37.699062  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 19:23:37.699121  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 19:23:37.699178  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 19:23:37.699235  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 19:23:37.699316  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 19:23:37.699373  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 19:23:37.699430  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 19:23:37.699501  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 19:23:37.699566  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 19:23:37.699625  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 19:23:37.699683  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 19:23:37.699759  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 19:23:37.699817  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 19:23:37.699874  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 19:23:37.699931  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 19:23:37.700006  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 19:23:37.700064  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 19:23:37.700124  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 19:23:37.700191  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 19:23:37.700255  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 19:23:37.700312  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 19:23:37.700371  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 19:23:37.700429  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 19:23:37.700489  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 19:23:37.700546  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 19:23:37.700604  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 19:23:37.700662  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 19:23:37.700733  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 19:23:37.700800  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 19:23:37.700862  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 19:23:37.700920  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 19:23:37.700987  1665 net.cpp:198] conv1 needs backward computation.
I0405 19:23:37.701051  1665 net.cpp:198] data_scale needs backward computation.
I0405 19:23:37.701110  1665 net.cpp:200] data_bn does not need backward computation.
I0405 19:23:37.701170  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 19:23:37.701231  1665 net.cpp:200] data does not need backward computation.
I0405 19:23:37.701287  1665 net.cpp:242] This network produces output accuracy
I0405 19:23:37.701344  1665 net.cpp:242] This network produces output loss
I0405 19:23:37.701431  1665 net.cpp:255] Network initialization done.
I0405 19:23:46.753867  1665 blocking_queue.cpp:49] Waiting for data
I0405 19:24:16.679649  1665 solver.cpp:44] Initializing solver from parameters: 
test_iter: 0
test_interval: 469
base_lr: 0.001
display: 225
max_iter: 1800
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 1800
snapshot_prefix: "data/snapshots/train_batch_03"
solver_mode: GPU
random_seed: 0
net: "confs/sII/mid-caffeNet/inc_train_val.prototxt"
test_initialization: false
snapshot_format: HDF5
I0405 19:24:16.694885  1665 solver.cpp:87] Creating training net from net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:24:16.696005  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:24:16.696131  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 19:24:16.696259  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0405 19:24:16.696338  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0405 19:24:16.696621  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/train_batch_03_filelist.txt"
    batch_size: 256
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I0405 19:24:16.696907  1665 layer_factory.hpp:77] Creating layer data
I0405 19:24:16.696986  1665 net.cpp:84] Creating Layer data
I0405 19:24:16.697041  1665 net.cpp:380] data -> data
I0405 19:24:16.697103  1665 net.cpp:380] data -> label
I0405 19:24:16.697160  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/train_batch_03_filelist.txt
I0405 19:24:16.707934  1665 image_data_layer.cpp:53] Shuffling data
I0405 19:24:16.709836  1665 image_data_layer.cpp:63] A total of 59956 images.
I0405 19:24:16.711992  1665 image_data_layer.cpp:90] output data size: 256,3,128,128
I0405 19:24:16.840112  1665 net.cpp:122] Setting up data
I0405 19:24:16.840397  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 19:24:16.840497  1665 net.cpp:129] Top shape: 256 (256)
I0405 19:24:16.840574  1665 net.cpp:137] Memory required for data: 50332672
I0405 19:24:16.840644  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 19:24:16.840731  1665 net.cpp:84] Creating Layer data_bn
I0405 19:24:16.840809  1665 net.cpp:406] data_bn <- data
I0405 19:24:16.840884  1665 net.cpp:380] data_bn -> data_bn
I0405 19:24:16.841164  1665 net.cpp:122] Setting up data_bn
I0405 19:24:16.841302  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 19:24:16.841380  1665 net.cpp:137] Memory required for data: 100664320
I0405 19:24:16.841468  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:24:16.841562  1665 net.cpp:84] Creating Layer data_scale
I0405 19:24:16.841635  1665 net.cpp:406] data_scale <- data_bn
I0405 19:24:16.841706  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 19:24:16.841800  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:24:16.841984  1665 net.cpp:122] Setting up data_scale
I0405 19:24:16.842082  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 19:24:16.842154  1665 net.cpp:137] Memory required for data: 150995968
I0405 19:24:16.842244  1665 layer_factory.hpp:77] Creating layer conv1
I0405 19:24:16.842329  1665 net.cpp:84] Creating Layer conv1
I0405 19:24:16.842403  1665 net.cpp:406] conv1 <- data_bn
I0405 19:24:16.842478  1665 net.cpp:380] conv1 -> conv1
I0405 19:24:16.847409  1665 net.cpp:122] Setting up conv1
I0405 19:24:16.847617  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 19:24:16.847703  1665 net.cpp:137] Memory required for data: 419431424
I0405 19:24:16.847812  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 19:24:16.847900  1665 net.cpp:84] Creating Layer conv1_bn
I0405 19:24:16.847973  1665 net.cpp:406] conv1_bn <- conv1
I0405 19:24:16.848105  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 19:24:16.848335  1665 net.cpp:122] Setting up conv1_bn
I0405 19:24:16.848425  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 19:24:16.848508  1665 net.cpp:137] Memory required for data: 687866880
I0405 19:24:16.848588  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:24:16.848665  1665 net.cpp:84] Creating Layer conv1_scale
I0405 19:24:16.848774  1665 net.cpp:406] conv1_scale <- conv1
I0405 19:24:16.848850  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 19:24:16.848946  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:24:16.849098  1665 net.cpp:122] Setting up conv1_scale
I0405 19:24:16.849190  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 19:24:16.849292  1665 net.cpp:137] Memory required for data: 956302336
I0405 19:24:16.849362  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 19:24:16.849436  1665 net.cpp:84] Creating Layer conv1_relu
I0405 19:24:16.849505  1665 net.cpp:406] conv1_relu <- conv1
I0405 19:24:16.849593  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 19:24:16.849678  1665 net.cpp:122] Setting up conv1_relu
I0405 19:24:16.849786  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 19:24:16.849860  1665 net.cpp:137] Memory required for data: 1224737792
I0405 19:24:16.849931  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 19:24:16.850005  1665 net.cpp:84] Creating Layer conv1_pool
I0405 19:24:16.850077  1665 net.cpp:406] conv1_pool <- conv1
I0405 19:24:16.850147  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 19:24:16.850244  1665 net.cpp:122] Setting up conv1_pool
I0405 19:24:16.850315  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:24:16.850399  1665 net.cpp:137] Memory required for data: 1291846656
I0405 19:24:16.850467  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 19:24:16.850541  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 19:24:16.850610  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 19:24:16.850700  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 19:24:16.850806  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 19:24:16.850895  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 19:24:16.850970  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:24:16.851047  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:24:16.851115  1665 net.cpp:137] Memory required for data: 1426064384
I0405 19:24:16.851184  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 19:24:16.851258  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 19:24:16.851337  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 19:24:16.851431  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 19:24:16.851931  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 19:24:16.852043  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:24:16.852118  1665 net.cpp:137] Memory required for data: 1493173248
I0405 19:24:16.852190  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 19:24:16.852265  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 19:24:16.852339  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 19:24:16.852409  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 19:24:16.852602  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 19:24:16.852677  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:24:16.852794  1665 net.cpp:137] Memory required for data: 1560282112
I0405 19:24:16.852881  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:24:16.852955  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 19:24:16.853044  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 19:24:16.853121  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 19:24:16.853216  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:24:16.853356  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 19:24:16.853448  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:24:16.853524  1665 net.cpp:137] Memory required for data: 1627390976
I0405 19:24:16.853600  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 19:24:16.853673  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 19:24:16.853777  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 19:24:16.853853  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 19:24:16.853941  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 19:24:16.854033  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:24:16.854116  1665 net.cpp:137] Memory required for data: 1694499840
I0405 19:24:16.854188  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 19:24:16.854266  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 19:24:16.854337  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 19:24:16.854408  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 19:24:16.854907  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 19:24:16.855024  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:24:16.855108  1665 net.cpp:137] Memory required for data: 1761608704
I0405 19:24:16.855185  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 19:24:16.855262  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 19:24:16.855336  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 19:24:16.855406  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 19:24:16.855480  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 19:24:16.855566  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 19:24:16.855639  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:24:16.855710  1665 net.cpp:137] Memory required for data: 1828717568
I0405 19:24:16.855793  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 19:24:16.855890  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 19:24:16.855962  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 19:24:16.856039  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 19:24:16.856231  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 19:24:16.856310  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:24:16.856382  1665 net.cpp:137] Memory required for data: 1895826432
I0405 19:24:16.856456  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:24:16.856532  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 19:24:16.856604  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 19:24:16.856675  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 19:24:16.856793  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:24:16.856935  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 19:24:16.857014  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:24:16.857085  1665 net.cpp:137] Memory required for data: 1962935296
I0405 19:24:16.857154  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 19:24:16.857241  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 19:24:16.857329  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 19:24:16.857405  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 19:24:16.857477  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 19:24:16.857558  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:24:16.857630  1665 net.cpp:137] Memory required for data: 2030044160
I0405 19:24:16.857699  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:24:16.857803  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:24:16.857877  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 19:24:16.857951  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:24:16.858042  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:24:16.858147  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:24:16.858222  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:24:16.858292  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:24:16.858378  1665 net.cpp:137] Memory required for data: 2164261888
I0405 19:24:16.858464  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 19:24:16.858853  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 19:24:16.858964  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:24:16.859057  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 19:24:16.859854  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 19:24:16.859969  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:24:16.860064  1665 net.cpp:137] Memory required for data: 2197816320
I0405 19:24:16.860136  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 19:24:16.860220  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 19:24:16.860293  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 19:24:16.860364  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 19:24:16.860543  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 19:24:16.860630  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:24:16.860703  1665 net.cpp:137] Memory required for data: 2231370752
I0405 19:24:16.860816  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:24:16.860891  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 19:24:16.860965  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 19:24:16.861040  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 19:24:16.861133  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:24:16.861263  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 19:24:16.861356  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:24:16.861423  1665 net.cpp:137] Memory required for data: 2264925184
I0405 19:24:16.861493  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 19:24:16.861572  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 19:24:16.861652  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 19:24:16.861784  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 19:24:16.861861  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 19:24:16.861934  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:24:16.862004  1665 net.cpp:137] Memory required for data: 2298479616
I0405 19:24:16.862069  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 19:24:16.862143  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 19:24:16.862216  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 19:24:16.862287  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 19:24:16.863638  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 19:24:16.863771  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:24:16.863847  1665 net.cpp:137] Memory required for data: 2332034048
I0405 19:24:16.863921  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 19:24:16.863997  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 19:24:16.864071  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:24:16.864145  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 19:24:16.864385  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 19:24:16.864464  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:24:16.864540  1665 net.cpp:137] Memory required for data: 2365588480
I0405 19:24:16.864630  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 19:24:16.864711  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 19:24:16.864815  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 19:24:16.864892  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 19:24:16.864964  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 19:24:16.865057  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 19:24:16.865131  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:24:16.865203  1665 net.cpp:137] Memory required for data: 2399142912
I0405 19:24:16.865275  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 19:24:16.865347  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 19:24:16.865419  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 19:24:16.865487  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 19:24:16.865700  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 19:24:16.865831  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:24:16.865905  1665 net.cpp:137] Memory required for data: 2432697344
I0405 19:24:16.865993  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:24:16.866075  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 19:24:16.866147  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 19:24:16.866235  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 19:24:16.866330  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:24:16.866461  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 19:24:16.866549  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:24:16.866621  1665 net.cpp:137] Memory required for data: 2466251776
I0405 19:24:16.866709  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 19:24:16.866811  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 19:24:16.866881  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 19:24:16.866976  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 19:24:16.867045  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 19:24:16.867128  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:24:16.867202  1665 net.cpp:137] Memory required for data: 2499806208
I0405 19:24:16.867290  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:24:16.867365  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:24:16.867439  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 19:24:16.867509  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:24:16.867584  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:24:16.867674  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:24:16.867760  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:24:16.867831  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:24:16.867914  1665 net.cpp:137] Memory required for data: 2566915072
I0405 19:24:16.867982  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 19:24:16.868062  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 19:24:16.868144  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:24:16.868221  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 19:24:16.871649  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 19:24:16.871788  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:24:16.871853  1665 net.cpp:137] Memory required for data: 2583692288
I0405 19:24:16.871917  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 19:24:16.871978  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 19:24:16.872045  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 19:24:16.872107  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 19:24:16.872313  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 19:24:16.872418  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:24:16.872483  1665 net.cpp:137] Memory required for data: 2600469504
I0405 19:24:16.872568  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:24:16.872632  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 19:24:16.872694  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 19:24:16.872776  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 19:24:16.872864  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:24:16.872985  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 19:24:16.873071  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:24:16.873131  1665 net.cpp:137] Memory required for data: 2617246720
I0405 19:24:16.873191  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 19:24:16.873272  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 19:24:16.873334  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 19:24:16.873395  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 19:24:16.873461  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 19:24:16.873522  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:24:16.873603  1665 net.cpp:137] Memory required for data: 2634023936
I0405 19:24:16.873687  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 19:24:16.873780  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 19:24:16.873842  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 19:24:16.873904  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 19:24:16.879510  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 19:24:16.879627  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:24:16.879710  1665 net.cpp:137] Memory required for data: 2650801152
I0405 19:24:16.879787  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 19:24:16.879858  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 19:24:16.879920  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:24:16.879982  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 19:24:16.880412  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 19:24:16.880494  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:24:16.880584  1665 net.cpp:137] Memory required for data: 2667578368
I0405 19:24:16.880668  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 19:24:16.880758  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 19:24:16.880815  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 19:24:16.880877  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 19:24:16.880937  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 19:24:16.881008  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 19:24:16.881072  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:24:16.881136  1665 net.cpp:137] Memory required for data: 2684355584
I0405 19:24:16.881196  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 19:24:16.881259  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 19:24:16.881315  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 19:24:16.881407  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 19:24:16.881593  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 19:24:16.881675  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:24:16.881781  1665 net.cpp:137] Memory required for data: 2701132800
I0405 19:24:16.881845  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:24:16.881908  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 19:24:16.881966  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 19:24:16.882035  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 19:24:16.882148  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:24:16.882330  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 19:24:16.882422  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:24:16.882505  1665 net.cpp:137] Memory required for data: 2717910016
I0405 19:24:16.882581  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 19:24:16.882647  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 19:24:16.882705  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 19:24:16.882823  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 19:24:16.882911  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 19:24:16.882988  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:24:16.883069  1665 net.cpp:137] Memory required for data: 2734687232
I0405 19:24:16.883141  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:24:16.883215  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:24:16.883288  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 19:24:16.883363  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:24:16.883440  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:24:16.883554  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:24:16.883641  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:24:16.883724  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:24:16.883791  1665 net.cpp:137] Memory required for data: 2768241664
I0405 19:24:16.883859  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 19:24:16.883980  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 19:24:16.884071  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:24:16.884163  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 19:24:16.895462  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 19:24:16.895642  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:24:16.895823  1665 net.cpp:137] Memory required for data: 2776630272
I0405 19:24:16.895938  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 19:24:16.896028  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 19:24:16.896106  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 19:24:16.896195  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 19:24:16.896417  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 19:24:16.896529  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:24:16.896608  1665 net.cpp:137] Memory required for data: 2785018880
I0405 19:24:16.896688  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:24:16.896771  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 19:24:16.896849  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 19:24:16.896929  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 19:24:16.897033  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:24:16.897186  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 19:24:16.897282  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:24:16.897356  1665 net.cpp:137] Memory required for data: 2793407488
I0405 19:24:16.897446  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 19:24:16.897532  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 19:24:16.897612  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 19:24:16.897691  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 19:24:16.897795  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 19:24:16.897879  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:24:16.897958  1665 net.cpp:137] Memory required for data: 2801796096
I0405 19:24:16.898039  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 19:24:16.898123  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 19:24:16.898200  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 19:24:16.898289  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 19:24:16.920110  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 19:24:16.920303  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:24:16.920398  1665 net.cpp:137] Memory required for data: 2810184704
I0405 19:24:16.920476  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 19:24:16.920570  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 19:24:16.920648  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:24:16.920751  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 19:24:16.922049  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 19:24:16.922171  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:24:16.922248  1665 net.cpp:137] Memory required for data: 2818573312
I0405 19:24:16.922327  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 19:24:16.922420  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 19:24:16.922495  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 19:24:16.922570  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 19:24:16.922643  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 19:24:16.922753  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 19:24:16.922840  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:24:16.922919  1665 net.cpp:137] Memory required for data: 2826961920
I0405 19:24:16.922996  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 19:24:16.923079  1665 net.cpp:84] Creating Layer last_bn
I0405 19:24:16.923157  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 19:24:16.923233  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 19:24:16.923432  1665 net.cpp:122] Setting up last_bn
I0405 19:24:16.923534  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:24:16.923614  1665 net.cpp:137] Memory required for data: 2835350528
I0405 19:24:16.923691  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:24:16.923768  1665 net.cpp:84] Creating Layer last_scale
I0405 19:24:16.923851  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 19:24:16.923929  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 19:24:16.924052  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:24:16.924197  1665 net.cpp:122] Setting up last_scale
I0405 19:24:16.924289  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:24:16.924365  1665 net.cpp:137] Memory required for data: 2843739136
I0405 19:24:16.924441  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 19:24:16.924521  1665 net.cpp:84] Creating Layer last_relu
I0405 19:24:16.924600  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 19:24:16.924676  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 19:24:16.924789  1665 net.cpp:122] Setting up last_relu
I0405 19:24:16.924870  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:24:16.924939  1665 net.cpp:137] Memory required for data: 2852127744
I0405 19:24:16.925019  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 19:24:16.925107  1665 net.cpp:84] Creating Layer global_pool
I0405 19:24:16.925189  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 19:24:16.925269  1665 net.cpp:380] global_pool -> global_pool
I0405 19:24:16.925359  1665 net.cpp:122] Setting up global_pool
I0405 19:24:16.925437  1665 net.cpp:129] Top shape: 256 512 1 1 (131072)
I0405 19:24:16.925511  1665 net.cpp:137] Memory required for data: 2852652032
I0405 19:24:16.925587  1665 layer_factory.hpp:77] Creating layer score
I0405 19:24:16.925665  1665 net.cpp:84] Creating Layer score
I0405 19:24:16.925782  1665 net.cpp:406] score <- global_pool
I0405 19:24:16.925882  1665 net.cpp:380] score -> score
I0405 19:24:16.927201  1665 net.cpp:122] Setting up score
I0405 19:24:16.927335  1665 net.cpp:129] Top shape: 256 1000 (256000)
I0405 19:24:16.927403  1665 net.cpp:137] Memory required for data: 2853676032
I0405 19:24:16.927474  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:24:16.927542  1665 net.cpp:84] Creating Layer loss
I0405 19:24:16.927608  1665 net.cpp:406] loss <- score
I0405 19:24:16.927671  1665 net.cpp:406] loss <- label
I0405 19:24:16.927753  1665 net.cpp:380] loss -> loss
I0405 19:24:16.927821  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:24:16.929021  1665 net.cpp:122] Setting up loss
I0405 19:24:16.929116  1665 net.cpp:129] Top shape: (1)
I0405 19:24:16.929183  1665 net.cpp:132]     with loss weight 1
I0405 19:24:16.929255  1665 net.cpp:137] Memory required for data: 2853676036
I0405 19:24:16.929320  1665 net.cpp:198] loss needs backward computation.
I0405 19:24:16.929385  1665 net.cpp:198] score needs backward computation.
I0405 19:24:16.929447  1665 net.cpp:198] global_pool needs backward computation.
I0405 19:24:16.929510  1665 net.cpp:198] last_relu needs backward computation.
I0405 19:24:16.929574  1665 net.cpp:198] last_scale needs backward computation.
I0405 19:24:16.929636  1665 net.cpp:198] last_bn needs backward computation.
I0405 19:24:16.929699  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 19:24:16.929766  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 19:24:16.929829  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 19:24:16.929889  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 19:24:16.929960  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 19:24:16.930020  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 19:24:16.930089  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 19:24:16.930148  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 19:24:16.930215  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 19:24:16.930279  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 19:24:16.930347  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 19:24:16.930413  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 19:24:16.930480  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 19:24:16.930543  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 19:24:16.930606  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 19:24:16.930667  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 19:24:16.930743  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 19:24:16.930812  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 19:24:16.930881  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 19:24:16.930940  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 19:24:16.931001  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 19:24:16.931077  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 19:24:16.931139  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 19:24:16.931200  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 19:24:16.931258  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 19:24:16.931325  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 19:24:16.931390  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 19:24:16.931458  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 19:24:16.931524  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 19:24:16.931587  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 19:24:16.931651  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 19:24:16.931722  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 19:24:16.931789  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 19:24:16.931851  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 19:24:16.931913  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 19:24:16.931974  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 19:24:16.932040  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 19:24:16.932102  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 19:24:16.932163  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 19:24:16.932236  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 19:24:16.932298  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 19:24:16.932358  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 19:24:16.932421  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 19:24:16.932492  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 19:24:16.932557  1665 net.cpp:198] conv1 needs backward computation.
I0405 19:24:16.932623  1665 net.cpp:198] data_scale needs backward computation.
I0405 19:24:16.932687  1665 net.cpp:200] data_bn does not need backward computation.
I0405 19:24:16.932770  1665 net.cpp:200] data does not need backward computation.
I0405 19:24:16.932835  1665 net.cpp:242] This network produces output loss
I0405 19:24:16.932931  1665 net.cpp:255] Network initialization done.
I0405 19:24:16.934316  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:24:16.934468  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 19:24:16.934537  1665 solver.cpp:172] Creating test net (#0) specified by net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:24:16.934665  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 19:24:16.934993  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 19:24:16.946003  1665 layer_factory.hpp:77] Creating layer data
I0405 19:24:16.946107  1665 net.cpp:84] Creating Layer data
I0405 19:24:16.946161  1665 net.cpp:380] data -> data
I0405 19:24:16.946213  1665 net.cpp:380] data -> label
I0405 19:24:16.946267  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 19:24:16.955076  1665 image_data_layer.cpp:53] Shuffling data
I0405 19:24:16.956703  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 19:24:16.957569  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 19:24:17.008752  1665 net.cpp:122] Setting up data
I0405 19:24:17.008931  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:24:17.009012  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:24:17.009071  1665 net.cpp:137] Memory required for data: 19661200
I0405 19:24:17.009131  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 19:24:17.009205  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 19:24:17.009260  1665 net.cpp:406] label_data_1_split <- label
I0405 19:24:17.009323  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 19:24:17.009395  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 19:24:17.009521  1665 net.cpp:122] Setting up label_data_1_split
I0405 19:24:17.009600  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:24:17.009660  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:24:17.009734  1665 net.cpp:137] Memory required for data: 19662000
I0405 19:24:17.009795  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 19:24:17.009857  1665 net.cpp:84] Creating Layer data_bn
I0405 19:24:17.009912  1665 net.cpp:406] data_bn <- data
I0405 19:24:17.009971  1665 net.cpp:380] data_bn -> data_bn
I0405 19:24:17.011956  1665 net.cpp:122] Setting up data_bn
I0405 19:24:17.012084  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:24:17.012163  1665 net.cpp:137] Memory required for data: 39322800
I0405 19:24:17.012248  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:24:17.012312  1665 net.cpp:84] Creating Layer data_scale
I0405 19:24:17.012378  1665 net.cpp:406] data_scale <- data_bn
I0405 19:24:17.012434  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 19:24:17.012550  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:24:17.012778  1665 net.cpp:122] Setting up data_scale
I0405 19:24:17.012850  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:24:17.012899  1665 net.cpp:137] Memory required for data: 58983600
I0405 19:24:17.012959  1665 layer_factory.hpp:77] Creating layer conv1
I0405 19:24:17.013026  1665 net.cpp:84] Creating Layer conv1
I0405 19:24:17.013084  1665 net.cpp:406] conv1 <- data_bn
I0405 19:24:17.013147  1665 net.cpp:380] conv1 -> conv1
I0405 19:24:17.013567  1665 net.cpp:122] Setting up conv1
I0405 19:24:17.013649  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:24:17.013707  1665 net.cpp:137] Memory required for data: 163841200
I0405 19:24:17.013777  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 19:24:17.013844  1665 net.cpp:84] Creating Layer conv1_bn
I0405 19:24:17.013895  1665 net.cpp:406] conv1_bn <- conv1
I0405 19:24:17.013952  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 19:24:17.014202  1665 net.cpp:122] Setting up conv1_bn
I0405 19:24:17.014282  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:24:17.014340  1665 net.cpp:137] Memory required for data: 268698800
I0405 19:24:17.014400  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:24:17.014458  1665 net.cpp:84] Creating Layer conv1_scale
I0405 19:24:17.014516  1665 net.cpp:406] conv1_scale <- conv1
I0405 19:24:17.014577  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 19:24:17.014679  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:24:17.014873  1665 net.cpp:122] Setting up conv1_scale
I0405 19:24:17.014962  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:24:17.015019  1665 net.cpp:137] Memory required for data: 373556400
I0405 19:24:17.015076  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 19:24:17.015136  1665 net.cpp:84] Creating Layer conv1_relu
I0405 19:24:17.015198  1665 net.cpp:406] conv1_relu <- conv1
I0405 19:24:17.015255  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 19:24:17.015314  1665 net.cpp:122] Setting up conv1_relu
I0405 19:24:17.015375  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:24:17.015432  1665 net.cpp:137] Memory required for data: 478414000
I0405 19:24:17.015494  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 19:24:17.015555  1665 net.cpp:84] Creating Layer conv1_pool
I0405 19:24:17.015612  1665 net.cpp:406] conv1_pool <- conv1
I0405 19:24:17.015671  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 19:24:17.015832  1665 net.cpp:122] Setting up conv1_pool
I0405 19:24:17.015897  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:24:17.015954  1665 net.cpp:137] Memory required for data: 504628400
I0405 19:24:17.016012  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 19:24:17.016078  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 19:24:17.016134  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 19:24:17.016191  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 19:24:17.016255  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 19:24:17.016338  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 19:24:17.016400  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:24:17.016459  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:24:17.016520  1665 net.cpp:137] Memory required for data: 557057200
I0405 19:24:17.016587  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 19:24:17.016650  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 19:24:17.016707  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 19:24:17.016775  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 19:24:17.017489  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 19:24:17.017580  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:24:17.017637  1665 net.cpp:137] Memory required for data: 583271600
I0405 19:24:17.017700  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 19:24:17.017781  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 19:24:17.017840  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 19:24:17.017894  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 19:24:17.018141  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 19:24:17.018229  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:24:17.018296  1665 net.cpp:137] Memory required for data: 609486000
I0405 19:24:17.018360  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:24:17.018417  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 19:24:17.018476  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 19:24:17.018540  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 19:24:17.018630  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:24:17.018806  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 19:24:17.018870  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:24:17.018981  1665 net.cpp:137] Memory required for data: 635700400
I0405 19:24:17.019057  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 19:24:17.019111  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 19:24:17.019161  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 19:24:17.019213  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 19:24:17.019275  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 19:24:17.019333  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:24:17.019393  1665 net.cpp:137] Memory required for data: 661914800
I0405 19:24:17.019449  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 19:24:17.019515  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 19:24:17.019573  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 19:24:17.019634  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 19:24:17.020349  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 19:24:17.020439  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:24:17.020498  1665 net.cpp:137] Memory required for data: 688129200
I0405 19:24:17.020561  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 19:24:17.020622  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 19:24:17.020680  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 19:24:17.020753  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 19:24:17.020819  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 19:24:17.020905  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 19:24:17.020969  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:24:17.021029  1665 net.cpp:137] Memory required for data: 714343600
I0405 19:24:17.021087  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 19:24:17.021147  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 19:24:17.021206  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 19:24:17.021270  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 19:24:17.021531  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 19:24:17.021625  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:24:17.021687  1665 net.cpp:137] Memory required for data: 740558000
I0405 19:24:17.021770  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:24:17.021834  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 19:24:17.021895  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 19:24:17.021960  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 19:24:17.022058  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:24:17.022222  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 19:24:17.022292  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:24:17.022346  1665 net.cpp:137] Memory required for data: 766772400
I0405 19:24:17.022408  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 19:24:17.022470  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 19:24:17.022533  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 19:24:17.022599  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 19:24:17.022663  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 19:24:17.022747  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:24:17.022809  1665 net.cpp:137] Memory required for data: 792986800
I0405 19:24:17.022876  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:24:17.022934  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:24:17.022994  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 19:24:17.023058  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:24:17.023121  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:24:17.023212  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:24:17.023278  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:24:17.023334  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:24:17.023391  1665 net.cpp:137] Memory required for data: 845415600
I0405 19:24:17.023452  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 19:24:17.023517  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 19:24:17.023586  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:24:17.023648  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 19:24:17.024860  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 19:24:17.024960  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:24:17.025014  1665 net.cpp:137] Memory required for data: 858522800
I0405 19:24:17.025091  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 19:24:17.025153  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 19:24:17.025213  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 19:24:17.025271  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 19:24:17.025564  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 19:24:17.025646  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:24:17.025707  1665 net.cpp:137] Memory required for data: 871630000
I0405 19:24:17.025780  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:24:17.025840  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 19:24:17.025892  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 19:24:17.025945  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 19:24:17.026037  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:24:17.026182  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 19:24:17.026252  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:24:17.026309  1665 net.cpp:137] Memory required for data: 884737200
I0405 19:24:17.026387  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 19:24:17.026440  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 19:24:17.026495  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 19:24:17.026551  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 19:24:17.026605  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 19:24:17.026659  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:24:17.026710  1665 net.cpp:137] Memory required for data: 897844400
I0405 19:24:17.026782  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 19:24:17.026841  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 19:24:17.026892  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 19:24:17.026947  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 19:24:17.029067  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 19:24:17.029182  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:24:17.029242  1665 net.cpp:137] Memory required for data: 910951600
I0405 19:24:17.029307  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 19:24:17.029377  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 19:24:17.029459  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:24:17.029515  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 19:24:17.029875  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 19:24:17.029973  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:24:17.030033  1665 net.cpp:137] Memory required for data: 924058800
I0405 19:24:17.030108  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 19:24:17.030164  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 19:24:17.030222  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 19:24:17.030342  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 19:24:17.030447  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 19:24:17.030566  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 19:24:17.030656  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:24:17.030731  1665 net.cpp:137] Memory required for data: 937166000
I0405 19:24:17.030798  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 19:24:17.030863  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 19:24:17.030920  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 19:24:17.030979  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 19:24:17.031260  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 19:24:17.031327  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:24:17.031397  1665 net.cpp:137] Memory required for data: 950273200
I0405 19:24:17.031460  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:24:17.031543  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 19:24:17.031605  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 19:24:17.031672  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 19:24:17.031800  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:24:17.031967  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 19:24:17.032058  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:24:17.032114  1665 net.cpp:137] Memory required for data: 963380400
I0405 19:24:17.032172  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 19:24:17.032230  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 19:24:17.032287  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 19:24:17.032343  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 19:24:17.032400  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 19:24:17.032456  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:24:17.032521  1665 net.cpp:137] Memory required for data: 976487600
I0405 19:24:17.032593  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:24:17.032651  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:24:17.032707  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 19:24:17.032775  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:24:17.032845  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:24:17.032932  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:24:17.032994  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:24:17.033068  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:24:17.033124  1665 net.cpp:137] Memory required for data: 1002702000
I0405 19:24:17.033179  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 19:24:17.033243  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 19:24:17.033301  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:24:17.033362  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 19:24:17.038523  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 19:24:17.038628  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:24:17.038702  1665 net.cpp:137] Memory required for data: 1009255600
I0405 19:24:17.038781  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 19:24:17.038857  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 19:24:17.038923  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 19:24:17.038982  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 19:24:17.039237  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 19:24:17.039301  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:24:17.039357  1665 net.cpp:137] Memory required for data: 1015809200
I0405 19:24:17.039418  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:24:17.039477  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 19:24:17.039535  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 19:24:17.039592  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 19:24:17.039691  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:24:17.039889  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 19:24:17.039983  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:24:17.040041  1665 net.cpp:137] Memory required for data: 1022362800
I0405 19:24:17.040107  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 19:24:17.040158  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 19:24:17.040221  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 19:24:17.040275  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 19:24:17.040333  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 19:24:17.040392  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:24:17.040449  1665 net.cpp:137] Memory required for data: 1028916400
I0405 19:24:17.040510  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 19:24:17.040571  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 19:24:17.040627  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 19:24:17.040685  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 19:24:17.049468  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 19:24:17.049629  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:24:17.049707  1665 net.cpp:137] Memory required for data: 1035470000
I0405 19:24:17.049796  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 19:24:17.049872  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 19:24:17.049965  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:24:17.050032  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 19:24:17.050742  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 19:24:17.050840  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:24:17.050896  1665 net.cpp:137] Memory required for data: 1042023600
I0405 19:24:17.050954  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 19:24:17.051035  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 19:24:17.051115  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 19:24:17.051170  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 19:24:17.051228  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 19:24:17.051311  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 19:24:17.051369  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:24:17.051424  1665 net.cpp:137] Memory required for data: 1048577200
I0405 19:24:17.051496  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 19:24:17.051564  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 19:24:17.051625  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 19:24:17.051683  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 19:24:17.051972  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 19:24:17.052052  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:24:17.052112  1665 net.cpp:137] Memory required for data: 1055130800
I0405 19:24:17.052182  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:24:17.052276  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 19:24:17.052346  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 19:24:17.052403  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 19:24:17.052513  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:24:17.052702  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 19:24:17.052788  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:24:17.052852  1665 net.cpp:137] Memory required for data: 1061684400
I0405 19:24:17.052919  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 19:24:17.052991  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 19:24:17.053071  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 19:24:17.053128  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 19:24:17.053194  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 19:24:17.053261  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:24:17.053339  1665 net.cpp:137] Memory required for data: 1068238000
I0405 19:24:17.053411  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:24:17.053474  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:24:17.053540  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 19:24:17.053608  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:24:17.053689  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:24:17.053820  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:24:17.053902  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:24:17.053966  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:24:17.054031  1665 net.cpp:137] Memory required for data: 1081345200
I0405 19:24:17.054100  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 19:24:17.054172  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 19:24:17.054255  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:24:17.054312  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 19:24:17.071374  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 19:24:17.071482  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:24:17.071549  1665 net.cpp:137] Memory required for data: 1084622000
I0405 19:24:17.071614  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 19:24:17.071692  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 19:24:17.071765  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 19:24:17.071835  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 19:24:17.072099  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 19:24:17.072191  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:24:17.072252  1665 net.cpp:137] Memory required for data: 1087898800
I0405 19:24:17.072316  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:24:17.072388  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 19:24:17.072454  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 19:24:17.072522  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 19:24:17.072633  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:24:17.072834  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 19:24:17.072919  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:24:17.072983  1665 net.cpp:137] Memory required for data: 1091175600
I0405 19:24:17.073081  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 19:24:17.073160  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 19:24:17.073230  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 19:24:17.073298  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 19:24:17.073356  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 19:24:17.073422  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:24:17.073485  1665 net.cpp:137] Memory required for data: 1094452400
I0405 19:24:17.073549  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 19:24:17.073616  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 19:24:17.073679  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 19:24:17.073756  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 19:24:17.109201  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 19:24:17.109314  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:24:17.109391  1665 net.cpp:137] Memory required for data: 1097729200
I0405 19:24:17.109457  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 19:24:17.109524  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 19:24:17.109591  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:24:17.109654  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 19:24:17.111577  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 19:24:17.111660  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:24:17.111768  1665 net.cpp:137] Memory required for data: 1101006000
I0405 19:24:17.111840  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 19:24:17.111908  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 19:24:17.111974  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 19:24:17.112036  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 19:24:17.112095  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 19:24:17.112190  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 19:24:17.112270  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:24:17.112331  1665 net.cpp:137] Memory required for data: 1104282800
I0405 19:24:17.112411  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 19:24:17.112483  1665 net.cpp:84] Creating Layer last_bn
I0405 19:24:17.112548  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 19:24:17.112613  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 19:24:17.112884  1665 net.cpp:122] Setting up last_bn
I0405 19:24:17.112963  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:24:17.113029  1665 net.cpp:137] Memory required for data: 1107559600
I0405 19:24:17.113095  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:24:17.113158  1665 net.cpp:84] Creating Layer last_scale
I0405 19:24:17.113238  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 19:24:17.113304  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 19:24:17.113407  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:24:17.113585  1665 net.cpp:122] Setting up last_scale
I0405 19:24:17.113669  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:24:17.113750  1665 net.cpp:137] Memory required for data: 1110836400
I0405 19:24:17.113811  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 19:24:17.113896  1665 net.cpp:84] Creating Layer last_relu
I0405 19:24:17.113955  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 19:24:17.114014  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 19:24:17.114074  1665 net.cpp:122] Setting up last_relu
I0405 19:24:17.114153  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:24:17.114210  1665 net.cpp:137] Memory required for data: 1114113200
I0405 19:24:17.114269  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 19:24:17.114329  1665 net.cpp:84] Creating Layer global_pool
I0405 19:24:17.114387  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 19:24:17.114447  1665 net.cpp:380] global_pool -> global_pool
I0405 19:24:17.114537  1665 net.cpp:122] Setting up global_pool
I0405 19:24:17.114600  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 19:24:17.114684  1665 net.cpp:137] Memory required for data: 1114318000
I0405 19:24:17.114763  1665 layer_factory.hpp:77] Creating layer score
I0405 19:24:17.114835  1665 net.cpp:84] Creating Layer score
I0405 19:24:17.114899  1665 net.cpp:406] score <- global_pool
I0405 19:24:17.114989  1665 net.cpp:380] score -> score
I0405 19:24:17.116739  1665 net.cpp:122] Setting up score
I0405 19:24:17.116842  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:24:17.116914  1665 net.cpp:137] Memory required for data: 1114718000
I0405 19:24:17.116979  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 19:24:17.117053  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 19:24:17.117115  1665 net.cpp:406] score_score_0_split <- score
I0405 19:24:17.117182  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 19:24:17.117242  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 19:24:17.117352  1665 net.cpp:122] Setting up score_score_0_split
I0405 19:24:17.117426  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:24:17.117486  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:24:17.117552  1665 net.cpp:137] Memory required for data: 1115518000
I0405 19:24:17.117612  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:24:17.117676  1665 net.cpp:84] Creating Layer loss
I0405 19:24:17.117755  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 19:24:17.117818  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 19:24:17.117879  1665 net.cpp:380] loss -> loss
I0405 19:24:17.117944  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:24:17.119446  1665 net.cpp:122] Setting up loss
I0405 19:24:17.119544  1665 net.cpp:129] Top shape: (1)
I0405 19:24:17.119645  1665 net.cpp:132]     with loss weight 1
I0405 19:24:17.119758  1665 net.cpp:137] Memory required for data: 1115518004
I0405 19:24:17.119820  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 19:24:17.119885  1665 net.cpp:84] Creating Layer accuracy
I0405 19:24:17.119957  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 19:24:17.120018  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 19:24:17.120080  1665 net.cpp:380] accuracy -> accuracy
I0405 19:24:17.120147  1665 net.cpp:122] Setting up accuracy
I0405 19:24:17.120230  1665 net.cpp:129] Top shape: (1)
I0405 19:24:17.120286  1665 net.cpp:137] Memory required for data: 1115518008
I0405 19:24:17.120349  1665 net.cpp:200] accuracy does not need backward computation.
I0405 19:24:17.120414  1665 net.cpp:198] loss needs backward computation.
I0405 19:24:17.120474  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 19:24:17.120600  1665 net.cpp:198] score needs backward computation.
I0405 19:24:17.120663  1665 net.cpp:198] global_pool needs backward computation.
I0405 19:24:17.120750  1665 net.cpp:198] last_relu needs backward computation.
I0405 19:24:17.120824  1665 net.cpp:198] last_scale needs backward computation.
I0405 19:24:17.120901  1665 net.cpp:198] last_bn needs backward computation.
I0405 19:24:17.120962  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 19:24:17.121055  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 19:24:17.121120  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 19:24:17.121186  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 19:24:17.121249  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 19:24:17.121316  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 19:24:17.121392  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 19:24:17.121453  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 19:24:17.121513  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 19:24:17.121583  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 19:24:17.121639  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 19:24:17.121701  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 19:24:17.121779  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 19:24:17.121840  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 19:24:17.121939  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 19:24:17.122043  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 19:24:17.122129  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 19:24:17.122191  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 19:24:17.122251  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 19:24:17.122313  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 19:24:17.122373  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 19:24:17.122433  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 19:24:17.122493  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 19:24:17.122560  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 19:24:17.122622  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 19:24:17.122680  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 19:24:17.122777  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 19:24:17.122829  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 19:24:17.122887  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 19:24:17.122963  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 19:24:17.123039  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 19:24:17.123093  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 19:24:17.123150  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 19:24:17.123212  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 19:24:17.123275  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 19:24:17.123353  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 19:24:17.123409  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 19:24:17.123464  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 19:24:17.123520  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 19:24:17.123574  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 19:24:17.123631  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 19:24:17.123690  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 19:24:17.123762  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 19:24:17.123821  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 19:24:17.123901  1665 net.cpp:198] conv1 needs backward computation.
I0405 19:24:17.123970  1665 net.cpp:198] data_scale needs backward computation.
I0405 19:24:17.124053  1665 net.cpp:200] data_bn does not need backward computation.
I0405 19:24:17.124131  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 19:24:17.124204  1665 net.cpp:200] data does not need backward computation.
I0405 19:24:17.124262  1665 net.cpp:242] This network produces output accuracy
I0405 19:24:17.124351  1665 net.cpp:242] This network produces output loss
I0405 19:24:17.124469  1665 net.cpp:255] Network initialization done.
I0405 19:24:17.124804  1665 solver.cpp:56] Solver scaffolding done.
I0405 19:24:17.163617  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: data/resnet10_cvgj_iter_320000.caffemodel
I0405 19:24:17.163831  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 19:24:17.632042  1665 solver.cpp:218] Iteration 0 (1.62322e-09 iter/s, 0.463876s/225 iters), loss = 13.1941
I0405 19:24:17.632220  1665 solver.cpp:237]     Train net output #0: loss = 13.1941 (* 1 = 13.1941 loss)
I0405 19:24:17.632822  1665 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I0405 19:25:56.131858  1665 solver.cpp:218] Iteration 225 (2.28423 iter/s, 98.5014s/225 iters), loss = 0.328871
I0405 19:25:56.132112  1665 solver.cpp:237]     Train net output #0: loss = 0.328871 (* 1 = 0.328871 loss)
I0405 19:25:56.132196  1665 sgd_solver.cpp:105] Iteration 225, lr = 0.000875
I0405 19:27:34.629153  1665 solver.cpp:218] Iteration 450 (2.28429 iter/s, 98.4989s/225 iters), loss = 0.12788
I0405 19:27:34.629443  1665 solver.cpp:237]     Train net output #0: loss = 0.12788 (* 1 = 0.12788 loss)
I0405 19:27:34.629523  1665 sgd_solver.cpp:105] Iteration 450, lr = 0.00075
I0405 19:27:42.509816  1665 solver.cpp:330] Iteration 469, Testing net (#0)
I0405 19:29:13.127312  1665 solver.cpp:218] Iteration 675 (2.28427 iter/s, 98.4998s/225 iters), loss = 0.12038
I0405 19:29:13.127576  1665 solver.cpp:237]     Train net output #0: loss = 0.12038 (* 1 = 0.12038 loss)
I0405 19:29:13.127668  1665 sgd_solver.cpp:105] Iteration 675, lr = 0.000625
I0405 19:30:51.624228  1665 solver.cpp:218] Iteration 900 (2.2843 iter/s, 98.4986s/225 iters), loss = 0.104791
I0405 19:30:51.624569  1665 solver.cpp:237]     Train net output #0: loss = 0.104791 (* 1 = 0.104791 loss)
I0405 19:30:51.624665  1665 sgd_solver.cpp:105] Iteration 900, lr = 0.0005
I0405 19:31:07.822495  1665 solver.cpp:330] Iteration 938, Testing net (#0)
I0405 19:32:30.130874  1665 solver.cpp:218] Iteration 1125 (2.28407 iter/s, 98.5083s/225 iters), loss = 0.063061
I0405 19:32:30.131125  1665 solver.cpp:237]     Train net output #0: loss = 0.063061 (* 1 = 0.063061 loss)
I0405 19:32:30.131203  1665 sgd_solver.cpp:105] Iteration 1125, lr = 0.000375
I0405 19:34:08.632017  1665 solver.cpp:218] Iteration 1350 (2.2842 iter/s, 98.5029s/225 iters), loss = 0.0590389
I0405 19:34:08.632294  1665 solver.cpp:237]     Train net output #0: loss = 0.0590389 (* 1 = 0.0590389 loss)
I0405 19:34:08.632382  1665 sgd_solver.cpp:105] Iteration 1350, lr = 0.00025
I0405 19:34:33.149343  1665 solver.cpp:330] Iteration 1407, Testing net (#0)
I0405 19:35:47.131669  1665 solver.cpp:218] Iteration 1575 (2.28423 iter/s, 98.5014s/225 iters), loss = 0.0502549
I0405 19:35:47.132021  1665 solver.cpp:237]     Train net output #0: loss = 0.0502549 (* 1 = 0.0502549 loss)
I0405 19:35:47.132095  1665 sgd_solver.cpp:105] Iteration 1575, lr = 0.000125
I0405 19:37:25.188452  1665 solver.cpp:457] Snapshotting to HDF5 file data/snapshots/train_batch_03_iter_1800.caffemodel.h5
I0405 19:37:25.252650  1665 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file data/snapshots/train_batch_03_iter_1800.solverstate.h5
W0405 19:37:26.930279  1665 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W0405 19:37:26.930533  1665 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W0405 19:37:26.930578  1665 _caffe.cpp:142] Net('confs/sII/mid-caffeNet/inc_train_val.prototxt', 1, weights='data/snapshots/train_batch_03_iter_1800.caffemodel.h5')
I0405 19:37:26.934252  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:37:26.934370  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 19:37:26.934546  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 19:37:26.934901  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 19:37:26.935170  1665 layer_factory.hpp:77] Creating layer data
I0405 19:37:26.935230  1665 net.cpp:84] Creating Layer data
I0405 19:37:26.935274  1665 net.cpp:380] data -> data
I0405 19:37:26.935318  1665 net.cpp:380] data -> label
I0405 19:37:26.935359  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 19:37:26.943564  1665 image_data_layer.cpp:53] Shuffling data
I0405 19:37:26.944594  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 19:37:26.945504  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 19:37:26.991997  1665 net.cpp:122] Setting up data
I0405 19:37:26.992209  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:37:26.992290  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:37:26.992347  1665 net.cpp:137] Memory required for data: 19661200
I0405 19:37:26.992415  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 19:37:26.992486  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 19:37:26.992558  1665 net.cpp:406] label_data_1_split <- label
I0405 19:37:26.992619  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 19:37:26.992683  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 19:37:26.992805  1665 net.cpp:122] Setting up label_data_1_split
I0405 19:37:26.992878  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:37:26.992975  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:37:26.993046  1665 net.cpp:137] Memory required for data: 19662000
I0405 19:37:26.993103  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 19:37:26.993160  1665 net.cpp:84] Creating Layer data_bn
I0405 19:37:26.993214  1665 net.cpp:406] data_bn <- data
I0405 19:37:26.993269  1665 net.cpp:380] data_bn -> data_bn
I0405 19:37:26.993487  1665 net.cpp:122] Setting up data_bn
I0405 19:37:26.993561  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:37:26.993615  1665 net.cpp:137] Memory required for data: 39322800
I0405 19:37:26.993676  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:37:26.993760  1665 net.cpp:84] Creating Layer data_scale
I0405 19:37:26.993842  1665 net.cpp:406] data_scale <- data_bn
I0405 19:37:26.993901  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 19:37:26.996021  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:37:26.996296  1665 net.cpp:122] Setting up data_scale
I0405 19:37:26.996384  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:37:26.996443  1665 net.cpp:137] Memory required for data: 58983600
I0405 19:37:26.996503  1665 layer_factory.hpp:77] Creating layer conv1
I0405 19:37:26.996567  1665 net.cpp:84] Creating Layer conv1
I0405 19:37:26.996626  1665 net.cpp:406] conv1 <- data_bn
I0405 19:37:26.996686  1665 net.cpp:380] conv1 -> conv1
I0405 19:37:26.997018  1665 net.cpp:122] Setting up conv1
I0405 19:37:26.997090  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:37:26.997157  1665 net.cpp:137] Memory required for data: 163841200
I0405 19:37:26.997215  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 19:37:26.997272  1665 net.cpp:84] Creating Layer conv1_bn
I0405 19:37:26.997325  1665 net.cpp:406] conv1_bn <- conv1
I0405 19:37:26.997380  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 19:37:26.997578  1665 net.cpp:122] Setting up conv1_bn
I0405 19:37:26.997659  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:37:26.997756  1665 net.cpp:137] Memory required for data: 268698800
I0405 19:37:26.997822  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:37:26.997880  1665 net.cpp:84] Creating Layer conv1_scale
I0405 19:37:26.997938  1665 net.cpp:406] conv1_scale <- conv1
I0405 19:37:26.998008  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 19:37:26.998100  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:37:26.998234  1665 net.cpp:122] Setting up conv1_scale
I0405 19:37:26.998304  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:37:26.998359  1665 net.cpp:137] Memory required for data: 373556400
I0405 19:37:26.998415  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 19:37:26.998478  1665 net.cpp:84] Creating Layer conv1_relu
I0405 19:37:26.998533  1665 net.cpp:406] conv1_relu <- conv1
I0405 19:37:26.998587  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 19:37:26.998643  1665 net.cpp:122] Setting up conv1_relu
I0405 19:37:26.998697  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:37:26.998771  1665 net.cpp:137] Memory required for data: 478414000
I0405 19:37:26.998832  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 19:37:26.998890  1665 net.cpp:84] Creating Layer conv1_pool
I0405 19:37:26.998944  1665 net.cpp:406] conv1_pool <- conv1
I0405 19:37:26.999001  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 19:37:26.999087  1665 net.cpp:122] Setting up conv1_pool
I0405 19:37:26.999162  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:37:26.999224  1665 net.cpp:137] Memory required for data: 504628400
I0405 19:37:26.999281  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 19:37:26.999338  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 19:37:26.999393  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 19:37:26.999452  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 19:37:26.999509  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 19:37:26.999585  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 19:37:26.999645  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:37:26.999702  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:37:26.999773  1665 net.cpp:137] Memory required for data: 557057200
I0405 19:37:26.999832  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 19:37:26.999900  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 19:37:26.999963  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 19:37:27.000034  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 19:37:27.000495  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 19:37:27.000581  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:37:27.000639  1665 net.cpp:137] Memory required for data: 583271600
I0405 19:37:27.000696  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 19:37:27.000772  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 19:37:27.000830  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 19:37:27.000885  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 19:37:27.001053  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 19:37:27.001125  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:37:27.001186  1665 net.cpp:137] Memory required for data: 609486000
I0405 19:37:27.001242  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:37:27.001298  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 19:37:27.001351  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 19:37:27.001415  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 19:37:27.001494  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:37:27.001610  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 19:37:27.001682  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:37:27.001760  1665 net.cpp:137] Memory required for data: 635700400
I0405 19:37:27.001821  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 19:37:27.001881  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 19:37:27.001935  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 19:37:27.001994  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 19:37:27.002051  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 19:37:27.002106  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:37:27.002161  1665 net.cpp:137] Memory required for data: 661914800
I0405 19:37:27.002218  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 19:37:27.002275  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 19:37:27.002332  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 19:37:27.002388  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 19:37:27.002851  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 19:37:27.002934  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:37:27.003002  1665 net.cpp:137] Memory required for data: 688129200
I0405 19:37:27.003058  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 19:37:27.003115  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 19:37:27.003170  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 19:37:27.003226  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 19:37:27.003280  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 19:37:27.003356  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 19:37:27.003422  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:37:27.003475  1665 net.cpp:137] Memory required for data: 714343600
I0405 19:37:27.003527  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 19:37:27.003584  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 19:37:27.003643  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 19:37:27.003705  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 19:37:27.003883  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 19:37:27.003957  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:37:27.004011  1665 net.cpp:137] Memory required for data: 740558000
I0405 19:37:27.004067  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:37:27.004124  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 19:37:27.004179  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 19:37:27.004235  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 19:37:27.004312  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:37:27.004456  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 19:37:27.004528  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:37:27.004581  1665 net.cpp:137] Memory required for data: 766772400
I0405 19:37:27.004637  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 19:37:27.004698  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 19:37:27.004792  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 19:37:27.004849  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 19:37:27.004904  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 19:37:27.004966  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:37:27.005019  1665 net.cpp:137] Memory required for data: 792986800
I0405 19:37:27.005074  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:37:27.005129  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:37:27.005187  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 19:37:27.005242  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:37:27.005298  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:37:27.005372  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:37:27.005437  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:37:27.005497  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:37:27.005550  1665 net.cpp:137] Memory required for data: 845415600
I0405 19:37:27.005605  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 19:37:27.005663  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 19:37:27.005748  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:37:27.005805  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 19:37:27.006546  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 19:37:27.006644  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:37:27.006700  1665 net.cpp:137] Memory required for data: 858522800
I0405 19:37:27.006778  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 19:37:27.006837  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 19:37:27.006894  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 19:37:27.006950  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 19:37:27.007117  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 19:37:27.007186  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:37:27.007241  1665 net.cpp:137] Memory required for data: 871630000
I0405 19:37:27.007297  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:37:27.007362  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 19:37:27.007419  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 19:37:27.007480  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 19:37:27.007557  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:37:27.007683  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 19:37:27.007773  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:37:27.007827  1665 net.cpp:137] Memory required for data: 884737200
I0405 19:37:27.007881  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 19:37:27.007938  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 19:37:27.007997  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 19:37:27.008066  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 19:37:27.008121  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 19:37:27.008174  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:37:27.008227  1665 net.cpp:137] Memory required for data: 897844400
I0405 19:37:27.008281  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 19:37:27.008339  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 19:37:27.008406  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 19:37:27.008457  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 19:37:27.009824  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 19:37:27.009951  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:37:27.010017  1665 net.cpp:137] Memory required for data: 910951600
I0405 19:37:27.010076  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 19:37:27.010138  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 19:37:27.010193  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:37:27.010251  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 19:37:27.010488  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 19:37:27.010551  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:37:27.010605  1665 net.cpp:137] Memory required for data: 924058800
I0405 19:37:27.010663  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 19:37:27.010720  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 19:37:27.010771  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 19:37:27.010824  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 19:37:27.010879  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 19:37:27.010951  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 19:37:27.011109  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:37:27.011166  1665 net.cpp:137] Memory required for data: 937166000
I0405 19:37:27.011221  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 19:37:27.011297  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 19:37:27.011350  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 19:37:27.011405  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 19:37:27.011576  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 19:37:27.011646  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:37:27.011703  1665 net.cpp:137] Memory required for data: 950273200
I0405 19:37:27.011782  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:37:27.011844  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 19:37:27.011898  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 19:37:27.011965  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 19:37:27.012042  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:37:27.012156  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 19:37:27.012207  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:37:27.012259  1665 net.cpp:137] Memory required for data: 963380400
I0405 19:37:27.012315  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 19:37:27.012368  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 19:37:27.012430  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 19:37:27.012490  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 19:37:27.012547  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 19:37:27.012603  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:37:27.012656  1665 net.cpp:137] Memory required for data: 976487600
I0405 19:37:27.012709  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:37:27.012781  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:37:27.012835  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 19:37:27.012889  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:37:27.012954  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:37:27.013026  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:37:27.013082  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:37:27.013140  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:37:27.013195  1665 net.cpp:137] Memory required for data: 1002702000
I0405 19:37:27.013247  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 19:37:27.013319  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 19:37:27.013382  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:37:27.013437  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 19:37:27.016844  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 19:37:27.016948  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:37:27.017014  1665 net.cpp:137] Memory required for data: 1009255600
I0405 19:37:27.017074  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 19:37:27.017164  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 19:37:27.017244  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 19:37:27.017305  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 19:37:27.017515  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 19:37:27.017590  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:37:27.017644  1665 net.cpp:137] Memory required for data: 1015809200
I0405 19:37:27.017704  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:37:27.017787  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 19:37:27.017853  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 19:37:27.017918  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 19:37:27.018007  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:37:27.018136  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 19:37:27.018218  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:37:27.018275  1665 net.cpp:137] Memory required for data: 1022362800
I0405 19:37:27.018329  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 19:37:27.018391  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 19:37:27.018453  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 19:37:27.018508  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 19:37:27.018563  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 19:37:27.018616  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:37:27.018669  1665 net.cpp:137] Memory required for data: 1028916400
I0405 19:37:27.018748  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 19:37:27.018807  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 19:37:27.018857  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 19:37:27.018909  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 19:37:27.027758  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 19:37:27.027837  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:37:27.027885  1665 net.cpp:137] Memory required for data: 1035470000
I0405 19:37:27.027930  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 19:37:27.027989  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 19:37:27.028035  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:37:27.028082  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 19:37:27.028750  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 19:37:27.028846  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:37:27.028892  1665 net.cpp:137] Memory required for data: 1042023600
I0405 19:37:27.028944  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 19:37:27.028991  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 19:37:27.029053  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 19:37:27.029099  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 19:37:27.029146  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 19:37:27.029211  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 19:37:27.029268  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:37:27.029314  1665 net.cpp:137] Memory required for data: 1048577200
I0405 19:37:27.029356  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 19:37:27.029407  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 19:37:27.029474  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 19:37:27.029515  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 19:37:27.029755  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 19:37:27.029810  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:37:27.029855  1665 net.cpp:137] Memory required for data: 1055130800
I0405 19:37:27.029903  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:37:27.029953  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 19:37:27.029999  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 19:37:27.030045  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 19:37:27.030125  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:37:27.030262  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 19:37:27.030324  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:37:27.030369  1665 net.cpp:137] Memory required for data: 1061684400
I0405 19:37:27.030416  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 19:37:27.030467  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 19:37:27.030511  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 19:37:27.030557  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 19:37:27.030601  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 19:37:27.030642  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:37:27.030686  1665 net.cpp:137] Memory required for data: 1068238000
I0405 19:37:27.030750  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:37:27.030802  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:37:27.030850  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 19:37:27.030900  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:37:27.030956  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:37:27.031045  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:37:27.031097  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:37:27.031145  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:37:27.031194  1665 net.cpp:137] Memory required for data: 1081345200
I0405 19:37:27.031237  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 19:37:27.031291  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 19:37:27.031338  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:37:27.031389  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 19:37:27.045608  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 19:37:27.045751  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:37:27.045805  1665 net.cpp:137] Memory required for data: 1084622000
I0405 19:37:27.045858  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 19:37:27.045917  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 19:37:27.045969  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 19:37:27.046047  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 19:37:27.046228  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 19:37:27.046299  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:37:27.046351  1665 net.cpp:137] Memory required for data: 1087898800
I0405 19:37:27.046404  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:37:27.046479  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 19:37:27.046531  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 19:37:27.046587  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 19:37:27.046684  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:37:27.046864  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 19:37:27.046943  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:37:27.047013  1665 net.cpp:137] Memory required for data: 1091175600
I0405 19:37:27.047078  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 19:37:27.047153  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 19:37:27.047212  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 19:37:27.047272  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 19:37:27.047333  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 19:37:27.047567  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:37:27.048480  1665 net.cpp:137] Memory required for data: 1094452400
I0405 19:37:27.048606  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 19:37:27.049052  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 19:37:27.049163  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 19:37:27.049244  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 19:37:27.072901  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 19:37:27.073010  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:37:27.073081  1665 net.cpp:137] Memory required for data: 1097729200
I0405 19:37:27.073161  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 19:37:27.073225  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 19:37:27.073294  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:37:27.073361  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 19:37:27.074723  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 19:37:27.074813  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:37:27.074870  1665 net.cpp:137] Memory required for data: 1101006000
I0405 19:37:27.074928  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 19:37:27.074986  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 19:37:27.075042  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 19:37:27.075098  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 19:37:27.075155  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 19:37:27.075240  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 19:37:27.075314  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:37:27.075389  1665 net.cpp:137] Memory required for data: 1104282800
I0405 19:37:27.075449  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 19:37:27.075508  1665 net.cpp:84] Creating Layer last_bn
I0405 19:37:27.075563  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 19:37:27.075619  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 19:37:27.075829  1665 net.cpp:122] Setting up last_bn
I0405 19:37:27.075938  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:37:27.076017  1665 net.cpp:137] Memory required for data: 1107559600
I0405 19:37:27.076089  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:37:27.076151  1665 net.cpp:84] Creating Layer last_scale
I0405 19:37:27.076206  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 19:37:27.076263  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 19:37:27.076359  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:37:27.076520  1665 net.cpp:122] Setting up last_scale
I0405 19:37:27.076598  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:37:27.076659  1665 net.cpp:137] Memory required for data: 1110836400
I0405 19:37:27.076736  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 19:37:27.076798  1665 net.cpp:84] Creating Layer last_relu
I0405 19:37:27.076859  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 19:37:27.076917  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 19:37:27.076977  1665 net.cpp:122] Setting up last_relu
I0405 19:37:27.077033  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:37:27.077086  1665 net.cpp:137] Memory required for data: 1114113200
I0405 19:37:27.077139  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 19:37:27.077208  1665 net.cpp:84] Creating Layer global_pool
I0405 19:37:27.077262  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 19:37:27.077318  1665 net.cpp:380] global_pool -> global_pool
I0405 19:37:27.077399  1665 net.cpp:122] Setting up global_pool
I0405 19:37:27.077467  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 19:37:27.077522  1665 net.cpp:137] Memory required for data: 1114318000
I0405 19:37:27.077584  1665 layer_factory.hpp:77] Creating layer score
I0405 19:37:27.077646  1665 net.cpp:84] Creating Layer score
I0405 19:37:27.077702  1665 net.cpp:406] score <- global_pool
I0405 19:37:27.077778  1665 net.cpp:380] score -> score
I0405 19:37:27.079102  1665 net.cpp:122] Setting up score
I0405 19:37:27.079216  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:37:27.079269  1665 net.cpp:137] Memory required for data: 1114718000
I0405 19:37:27.079331  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 19:37:27.079406  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 19:37:27.079460  1665 net.cpp:406] score_score_0_split <- score
I0405 19:37:27.079514  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 19:37:27.079571  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 19:37:27.079658  1665 net.cpp:122] Setting up score_score_0_split
I0405 19:37:27.079747  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:37:27.079815  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:37:27.079866  1665 net.cpp:137] Memory required for data: 1115518000
I0405 19:37:27.079929  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:37:27.079985  1665 net.cpp:84] Creating Layer loss
I0405 19:37:27.080042  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 19:37:27.080099  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 19:37:27.080153  1665 net.cpp:380] loss -> loss
I0405 19:37:27.080211  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:37:27.081388  1665 net.cpp:122] Setting up loss
I0405 19:37:27.081477  1665 net.cpp:129] Top shape: (1)
I0405 19:37:27.081544  1665 net.cpp:132]     with loss weight 1
I0405 19:37:27.081629  1665 net.cpp:137] Memory required for data: 1115518004
I0405 19:37:27.081686  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 19:37:27.081761  1665 net.cpp:84] Creating Layer accuracy
I0405 19:37:27.081815  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 19:37:27.081869  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 19:37:27.081923  1665 net.cpp:380] accuracy -> accuracy
I0405 19:37:27.081977  1665 net.cpp:122] Setting up accuracy
I0405 19:37:27.082031  1665 net.cpp:129] Top shape: (1)
I0405 19:37:27.082082  1665 net.cpp:137] Memory required for data: 1115518008
I0405 19:37:27.082134  1665 net.cpp:200] accuracy does not need backward computation.
I0405 19:37:27.082196  1665 net.cpp:198] loss needs backward computation.
I0405 19:37:27.082249  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 19:37:27.082301  1665 net.cpp:198] score needs backward computation.
I0405 19:37:27.082361  1665 net.cpp:198] global_pool needs backward computation.
I0405 19:37:27.082418  1665 net.cpp:198] last_relu needs backward computation.
I0405 19:37:27.082476  1665 net.cpp:198] last_scale needs backward computation.
I0405 19:37:27.082530  1665 net.cpp:198] last_bn needs backward computation.
I0405 19:37:27.082582  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 19:37:27.082635  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 19:37:27.082687  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 19:37:27.082752  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 19:37:27.082805  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 19:37:27.082856  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 19:37:27.082927  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 19:37:27.082983  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 19:37:27.083035  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 19:37:27.083088  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 19:37:27.083146  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 19:37:27.083204  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 19:37:27.083256  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 19:37:27.083309  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 19:37:27.083361  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 19:37:27.083413  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 19:37:27.083465  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 19:37:27.083518  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 19:37:27.083572  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 19:37:27.083626  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 19:37:27.083688  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 19:37:27.083755  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 19:37:27.083813  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 19:37:27.083868  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 19:37:27.083967  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 19:37:27.084038  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 19:37:27.084093  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 19:37:27.084148  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 19:37:27.084209  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 19:37:27.084265  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 19:37:27.084321  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 19:37:27.084376  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 19:37:27.084431  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 19:37:27.084496  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 19:37:27.084551  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 19:37:27.084607  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 19:37:27.084664  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 19:37:27.084736  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 19:37:27.084794  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 19:37:27.084849  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 19:37:27.084905  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 19:37:27.084966  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 19:37:27.085021  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 19:37:27.085078  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 19:37:27.085134  1665 net.cpp:198] conv1 needs backward computation.
I0405 19:37:27.085189  1665 net.cpp:198] data_scale needs backward computation.
I0405 19:37:27.085245  1665 net.cpp:200] data_bn does not need backward computation.
I0405 19:37:27.085301  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 19:37:27.085357  1665 net.cpp:200] data does not need backward computation.
I0405 19:37:27.085420  1665 net.cpp:242] This network produces output accuracy
I0405 19:37:27.085479  1665 net.cpp:242] This network produces output loss
I0405 19:37:27.085566  1665 net.cpp:255] Network initialization done.
I0405 19:38:06.070788  1665 solver.cpp:44] Initializing solver from parameters: 
test_iter: 0
test_interval: 469
base_lr: 0.001
display: 225
max_iter: 1800
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 1800
snapshot_prefix: "data/snapshots/train_batch_04"
solver_mode: GPU
random_seed: 0
net: "confs/sII/mid-caffeNet/inc_train_val.prototxt"
test_initialization: false
snapshot_format: HDF5
I0405 19:38:06.073778  1665 solver.cpp:87] Creating training net from net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:38:06.074877  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:38:06.074987  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 19:38:06.075130  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0405 19:38:06.075212  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0405 19:38:06.075449  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/train_batch_04_filelist.txt"
    batch_size: 256
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I0405 19:38:06.075701  1665 layer_factory.hpp:77] Creating layer data
I0405 19:38:06.075785  1665 net.cpp:84] Creating Layer data
I0405 19:38:06.075860  1665 net.cpp:380] data -> data
I0405 19:38:06.075911  1665 net.cpp:380] data -> label
I0405 19:38:06.075963  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/train_batch_04_filelist.txt
I0405 19:38:06.087774  1665 image_data_layer.cpp:53] Shuffling data
I0405 19:38:06.089309  1665 image_data_layer.cpp:63] A total of 71945 images.
I0405 19:38:06.091441  1665 image_data_layer.cpp:90] output data size: 256,3,128,128
I0405 19:38:06.215818  1665 net.cpp:122] Setting up data
I0405 19:38:06.216079  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 19:38:06.216176  1665 net.cpp:129] Top shape: 256 (256)
I0405 19:38:06.216248  1665 net.cpp:137] Memory required for data: 50332672
I0405 19:38:06.216323  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 19:38:06.216408  1665 net.cpp:84] Creating Layer data_bn
I0405 19:38:06.216531  1665 net.cpp:406] data_bn <- data
I0405 19:38:06.216635  1665 net.cpp:380] data_bn -> data_bn
I0405 19:38:06.216946  1665 net.cpp:122] Setting up data_bn
I0405 19:38:06.217064  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 19:38:06.217151  1665 net.cpp:137] Memory required for data: 100664320
I0405 19:38:06.217234  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:38:06.217326  1665 net.cpp:84] Creating Layer data_scale
I0405 19:38:06.217408  1665 net.cpp:406] data_scale <- data_bn
I0405 19:38:06.217485  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 19:38:06.222276  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:38:06.222522  1665 net.cpp:122] Setting up data_scale
I0405 19:38:06.222649  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 19:38:06.222771  1665 net.cpp:137] Memory required for data: 150995968
I0405 19:38:06.222858  1665 layer_factory.hpp:77] Creating layer conv1
I0405 19:38:06.222939  1665 net.cpp:84] Creating Layer conv1
I0405 19:38:06.223012  1665 net.cpp:406] conv1 <- data_bn
I0405 19:38:06.223088  1665 net.cpp:380] conv1 -> conv1
I0405 19:38:06.223510  1665 net.cpp:122] Setting up conv1
I0405 19:38:06.223620  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 19:38:06.223704  1665 net.cpp:137] Memory required for data: 419431424
I0405 19:38:06.223785  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 19:38:06.223884  1665 net.cpp:84] Creating Layer conv1_bn
I0405 19:38:06.223953  1665 net.cpp:406] conv1_bn <- conv1
I0405 19:38:06.224022  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 19:38:06.224272  1665 net.cpp:122] Setting up conv1_bn
I0405 19:38:06.224359  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 19:38:06.224668  1665 net.cpp:137] Memory required for data: 687866880
I0405 19:38:06.224858  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:38:06.224964  1665 net.cpp:84] Creating Layer conv1_scale
I0405 19:38:06.225028  1665 net.cpp:406] conv1_scale <- conv1
I0405 19:38:06.225147  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 19:38:06.225252  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:38:06.225414  1665 net.cpp:122] Setting up conv1_scale
I0405 19:38:06.225497  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 19:38:06.225565  1665 net.cpp:137] Memory required for data: 956302336
I0405 19:38:06.225638  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 19:38:06.225703  1665 net.cpp:84] Creating Layer conv1_relu
I0405 19:38:06.225788  1665 net.cpp:406] conv1_relu <- conv1
I0405 19:38:06.225858  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 19:38:06.225929  1665 net.cpp:122] Setting up conv1_relu
I0405 19:38:06.225992  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 19:38:06.226054  1665 net.cpp:137] Memory required for data: 1224737792
I0405 19:38:06.226117  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 19:38:06.226181  1665 net.cpp:84] Creating Layer conv1_pool
I0405 19:38:06.226244  1665 net.cpp:406] conv1_pool <- conv1
I0405 19:38:06.226307  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 19:38:06.226389  1665 net.cpp:122] Setting up conv1_pool
I0405 19:38:06.226469  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:38:06.226531  1665 net.cpp:137] Memory required for data: 1291846656
I0405 19:38:06.226591  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 19:38:06.226658  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 19:38:06.226765  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 19:38:06.226830  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 19:38:06.226905  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 19:38:06.226994  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 19:38:06.227061  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:38:06.227126  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:38:06.227188  1665 net.cpp:137] Memory required for data: 1426064384
I0405 19:38:06.227252  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 19:38:06.227319  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 19:38:06.227380  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 19:38:06.227443  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 19:38:06.227977  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 19:38:06.228061  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:38:06.228125  1665 net.cpp:137] Memory required for data: 1493173248
I0405 19:38:06.228189  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 19:38:06.228256  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 19:38:06.228318  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 19:38:06.228381  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 19:38:06.228574  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 19:38:06.228652  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:38:06.228726  1665 net.cpp:137] Memory required for data: 1560282112
I0405 19:38:06.228798  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:38:06.228868  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 19:38:06.228976  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 19:38:06.229045  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 19:38:06.229140  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:38:06.229300  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 19:38:06.229378  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:38:06.229435  1665 net.cpp:137] Memory required for data: 1627390976
I0405 19:38:06.229498  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 19:38:06.229560  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 19:38:06.229619  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 19:38:06.229677  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 19:38:06.229756  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 19:38:06.229815  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:38:06.229878  1665 net.cpp:137] Memory required for data: 1694499840
I0405 19:38:06.229944  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 19:38:06.230005  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 19:38:06.230064  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 19:38:06.230134  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 19:38:06.230599  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 19:38:06.230679  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:38:06.230751  1665 net.cpp:137] Memory required for data: 1761608704
I0405 19:38:06.230805  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 19:38:06.230865  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 19:38:06.230919  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 19:38:06.230976  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 19:38:06.231034  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 19:38:06.231101  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 19:38:06.231165  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:38:06.231218  1665 net.cpp:137] Memory required for data: 1828717568
I0405 19:38:06.231273  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 19:38:06.231329  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 19:38:06.231384  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 19:38:06.231446  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 19:38:06.231639  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 19:38:06.231727  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:38:06.231787  1665 net.cpp:137] Memory required for data: 1895826432
I0405 19:38:06.231848  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:38:06.231910  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 19:38:06.231967  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 19:38:06.232024  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 19:38:06.232096  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:38:06.232215  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 19:38:06.232271  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:38:06.232326  1665 net.cpp:137] Memory required for data: 1962935296
I0405 19:38:06.232383  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 19:38:06.232441  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 19:38:06.232513  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 19:38:06.232568  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 19:38:06.232627  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 19:38:06.232683  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:38:06.232761  1665 net.cpp:137] Memory required for data: 2030044160
I0405 19:38:06.232821  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:38:06.232898  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:38:06.232957  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 19:38:06.233016  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:38:06.233090  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:38:06.233166  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:38:06.233224  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:38:06.233283  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:38:06.233341  1665 net.cpp:137] Memory required for data: 2164261888
I0405 19:38:06.233397  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 19:38:06.233456  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 19:38:06.233511  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:38:06.233569  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 19:38:06.234309  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 19:38:06.234390  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:38:06.234452  1665 net.cpp:137] Memory required for data: 2197816320
I0405 19:38:06.234516  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 19:38:06.234573  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 19:38:06.234632  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 19:38:06.234686  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 19:38:06.234869  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 19:38:06.234941  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:38:06.234995  1665 net.cpp:137] Memory required for data: 2231370752
I0405 19:38:06.235054  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:38:06.235111  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 19:38:06.235173  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 19:38:06.235229  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 19:38:06.235299  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:38:06.235409  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 19:38:06.235464  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:38:06.235523  1665 net.cpp:137] Memory required for data: 2264925184
I0405 19:38:06.235579  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 19:38:06.235637  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 19:38:06.235694  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 19:38:06.235759  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 19:38:06.235817  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 19:38:06.235877  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:38:06.235930  1665 net.cpp:137] Memory required for data: 2298479616
I0405 19:38:06.235982  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 19:38:06.236039  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 19:38:06.236093  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 19:38:06.236146  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 19:38:06.238190  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 19:38:06.238302  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:38:06.238366  1665 net.cpp:137] Memory required for data: 2332034048
I0405 19:38:06.238430  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 19:38:06.238497  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 19:38:06.238557  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:38:06.238620  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 19:38:06.238976  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 19:38:06.239073  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:38:06.239143  1665 net.cpp:137] Memory required for data: 2365588480
I0405 19:38:06.239210  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 19:38:06.239274  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 19:38:06.239336  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 19:38:06.239400  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 19:38:06.239465  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 19:38:06.239552  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 19:38:06.239625  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:38:06.239686  1665 net.cpp:137] Memory required for data: 2399142912
I0405 19:38:06.239761  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 19:38:06.239825  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 19:38:06.239895  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 19:38:06.239957  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 19:38:06.240191  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 19:38:06.240270  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:38:06.240337  1665 net.cpp:137] Memory required for data: 2432697344
I0405 19:38:06.240423  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:38:06.240489  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 19:38:06.240548  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 19:38:06.240610  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 19:38:06.240705  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:38:06.241107  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 19:38:06.241216  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:38:06.241278  1665 net.cpp:137] Memory required for data: 2466251776
I0405 19:38:06.241336  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 19:38:06.241395  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 19:38:06.241449  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 19:38:06.241528  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 19:38:06.241590  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 19:38:06.241647  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:38:06.241700  1665 net.cpp:137] Memory required for data: 2499806208
I0405 19:38:06.241772  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:38:06.241829  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:38:06.241894  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 19:38:06.241947  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:38:06.242002  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:38:06.242087  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:38:06.242157  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:38:06.242213  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:38:06.242269  1665 net.cpp:137] Memory required for data: 2566915072
I0405 19:38:06.242342  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 19:38:06.242403  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 19:38:06.242458  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:38:06.242537  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 19:38:06.247697  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 19:38:06.247800  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:38:06.247854  1665 net.cpp:137] Memory required for data: 2583692288
I0405 19:38:06.247900  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 19:38:06.247961  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 19:38:06.248049  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 19:38:06.248091  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 19:38:06.248306  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 19:38:06.248361  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:38:06.248405  1665 net.cpp:137] Memory required for data: 2600469504
I0405 19:38:06.248453  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:38:06.248502  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 19:38:06.248544  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 19:38:06.248589  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 19:38:06.248661  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:38:06.248821  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 19:38:06.248883  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:38:06.248944  1665 net.cpp:137] Memory required for data: 2617246720
I0405 19:38:06.248991  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 19:38:06.249034  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 19:38:06.249090  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 19:38:06.249135  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 19:38:06.249178  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 19:38:06.249222  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:38:06.249265  1665 net.cpp:137] Memory required for data: 2634023936
I0405 19:38:06.249310  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 19:38:06.249356  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 19:38:06.249414  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 19:38:06.249461  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 19:38:06.258186  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 19:38:06.258287  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:38:06.258363  1665 net.cpp:137] Memory required for data: 2650801152
I0405 19:38:06.258424  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 19:38:06.258489  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 19:38:06.258559  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:38:06.258615  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 19:38:06.259330  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 19:38:06.259423  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:38:06.259495  1665 net.cpp:137] Memory required for data: 2667578368
I0405 19:38:06.259554  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 19:38:06.259624  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 19:38:06.259681  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 19:38:06.259757  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 19:38:06.259820  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 19:38:06.259909  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 19:38:06.259981  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:38:06.260040  1665 net.cpp:137] Memory required for data: 2684355584
I0405 19:38:06.260097  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 19:38:06.260159  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 19:38:06.260218  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 19:38:06.260277  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 19:38:06.260530  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 19:38:06.260596  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:38:06.260653  1665 net.cpp:137] Memory required for data: 2701132800
I0405 19:38:06.260725  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:38:06.260802  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 19:38:06.260861  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 19:38:06.260922  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 19:38:06.261015  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:38:06.261170  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 19:38:06.261245  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:38:06.261303  1665 net.cpp:137] Memory required for data: 2717910016
I0405 19:38:06.261368  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 19:38:06.261428  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 19:38:06.261490  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 19:38:06.261550  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 19:38:06.261605  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 19:38:06.261664  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:38:06.261723  1665 net.cpp:137] Memory required for data: 2734687232
I0405 19:38:06.261780  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:38:06.261857  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:38:06.261916  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 19:38:06.261971  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:38:06.262032  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:38:06.262125  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:38:06.262184  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:38:06.262244  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:38:06.262302  1665 net.cpp:137] Memory required for data: 2768241664
I0405 19:38:06.262362  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 19:38:06.262426  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 19:38:06.262485  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:38:06.262545  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 19:38:06.279690  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 19:38:06.279806  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:38:06.279884  1665 net.cpp:137] Memory required for data: 2776630272
I0405 19:38:06.279945  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 19:38:06.280007  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 19:38:06.280066  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 19:38:06.280122  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 19:38:06.280361  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 19:38:06.280475  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:38:06.280535  1665 net.cpp:137] Memory required for data: 2785018880
I0405 19:38:06.280597  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:38:06.280701  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 19:38:06.280773  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 19:38:06.280834  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 19:38:06.280930  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:38:06.281080  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 19:38:06.281152  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:38:06.281206  1665 net.cpp:137] Memory required for data: 2793407488
I0405 19:38:06.281268  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 19:38:06.281333  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 19:38:06.281406  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 19:38:06.281481  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 19:38:06.281553  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 19:38:06.281633  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:38:06.281705  1665 net.cpp:137] Memory required for data: 2801796096
I0405 19:38:06.281781  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 19:38:06.281855  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 19:38:06.281919  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 19:38:06.281983  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 19:38:06.315896  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 19:38:06.315994  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:38:06.316051  1665 net.cpp:137] Memory required for data: 2810184704
I0405 19:38:06.316112  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 19:38:06.316179  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 19:38:06.316251  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:38:06.316313  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 19:38:06.318226  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 19:38:06.318320  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:38:06.318370  1665 net.cpp:137] Memory required for data: 2818573312
I0405 19:38:06.318425  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 19:38:06.318500  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 19:38:06.318559  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 19:38:06.318620  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 19:38:06.318681  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 19:38:06.318783  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 19:38:06.318864  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:38:06.318934  1665 net.cpp:137] Memory required for data: 2826961920
I0405 19:38:06.319048  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 19:38:06.319114  1665 net.cpp:84] Creating Layer last_bn
I0405 19:38:06.319192  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 19:38:06.319254  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 19:38:06.319486  1665 net.cpp:122] Setting up last_bn
I0405 19:38:06.319552  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:38:06.319610  1665 net.cpp:137] Memory required for data: 2835350528
I0405 19:38:06.319674  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:38:06.319754  1665 net.cpp:84] Creating Layer last_scale
I0405 19:38:06.319816  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 19:38:06.319885  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 19:38:06.319975  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:38:06.320129  1665 net.cpp:122] Setting up last_scale
I0405 19:38:06.320202  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:38:06.320261  1665 net.cpp:137] Memory required for data: 2843739136
I0405 19:38:06.320320  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 19:38:06.320381  1665 net.cpp:84] Creating Layer last_relu
I0405 19:38:06.320443  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 19:38:06.320497  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 19:38:06.320559  1665 net.cpp:122] Setting up last_relu
I0405 19:38:06.320618  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:38:06.320677  1665 net.cpp:137] Memory required for data: 2852127744
I0405 19:38:06.320746  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 19:38:06.320808  1665 net.cpp:84] Creating Layer global_pool
I0405 19:38:06.320868  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 19:38:06.320927  1665 net.cpp:380] global_pool -> global_pool
I0405 19:38:06.321009  1665 net.cpp:122] Setting up global_pool
I0405 19:38:06.321069  1665 net.cpp:129] Top shape: 256 512 1 1 (131072)
I0405 19:38:06.321126  1665 net.cpp:137] Memory required for data: 2852652032
I0405 19:38:06.321184  1665 layer_factory.hpp:77] Creating layer score
I0405 19:38:06.321241  1665 net.cpp:84] Creating Layer score
I0405 19:38:06.321300  1665 net.cpp:406] score <- global_pool
I0405 19:38:06.321362  1665 net.cpp:380] score -> score
I0405 19:38:06.322942  1665 net.cpp:122] Setting up score
I0405 19:38:06.323035  1665 net.cpp:129] Top shape: 256 1000 (256000)
I0405 19:38:06.323092  1665 net.cpp:137] Memory required for data: 2853676032
I0405 19:38:06.323150  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:38:06.323212  1665 net.cpp:84] Creating Layer loss
I0405 19:38:06.323262  1665 net.cpp:406] loss <- score
I0405 19:38:06.323313  1665 net.cpp:406] loss <- label
I0405 19:38:06.323372  1665 net.cpp:380] loss -> loss
I0405 19:38:06.323428  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:38:06.324915  1665 net.cpp:122] Setting up loss
I0405 19:38:06.325006  1665 net.cpp:129] Top shape: (1)
I0405 19:38:06.325058  1665 net.cpp:132]     with loss weight 1
I0405 19:38:06.325117  1665 net.cpp:137] Memory required for data: 2853676036
I0405 19:38:06.325167  1665 net.cpp:198] loss needs backward computation.
I0405 19:38:06.325222  1665 net.cpp:198] score needs backward computation.
I0405 19:38:06.325271  1665 net.cpp:198] global_pool needs backward computation.
I0405 19:38:06.325321  1665 net.cpp:198] last_relu needs backward computation.
I0405 19:38:06.325371  1665 net.cpp:198] last_scale needs backward computation.
I0405 19:38:06.325424  1665 net.cpp:198] last_bn needs backward computation.
I0405 19:38:06.325474  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 19:38:06.325525  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 19:38:06.325578  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 19:38:06.325629  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 19:38:06.325678  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 19:38:06.325743  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 19:38:06.325798  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 19:38:06.325862  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 19:38:06.325914  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 19:38:06.325968  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 19:38:06.326015  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 19:38:06.326069  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 19:38:06.326119  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 19:38:06.326170  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 19:38:06.326220  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 19:38:06.326274  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 19:38:06.326324  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 19:38:06.326375  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 19:38:06.326427  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 19:38:06.326478  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 19:38:06.326527  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 19:38:06.326579  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 19:38:06.326634  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 19:38:06.326685  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 19:38:06.326766  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 19:38:06.326818  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 19:38:06.326879  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 19:38:06.326926  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 19:38:06.326979  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 19:38:06.327030  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 19:38:06.327080  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 19:38:06.327131  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 19:38:06.327181  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 19:38:06.327237  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 19:38:06.327288  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 19:38:06.327339  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 19:38:06.327390  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 19:38:06.327440  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 19:38:06.327489  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 19:38:06.327540  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 19:38:06.327590  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 19:38:06.327646  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 19:38:06.327695  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 19:38:06.327762  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 19:38:06.327813  1665 net.cpp:198] conv1 needs backward computation.
I0405 19:38:06.327867  1665 net.cpp:198] data_scale needs backward computation.
I0405 19:38:06.327925  1665 net.cpp:200] data_bn does not need backward computation.
I0405 19:38:06.327973  1665 net.cpp:200] data does not need backward computation.
I0405 19:38:06.328024  1665 net.cpp:242] This network produces output loss
I0405 19:38:06.328106  1665 net.cpp:255] Network initialization done.
I0405 19:38:06.329792  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:38:06.329970  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 19:38:06.330058  1665 solver.cpp:172] Creating test net (#0) specified by net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:38:06.330194  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 19:38:06.330629  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 19:38:06.330965  1665 layer_factory.hpp:77] Creating layer data
I0405 19:38:06.331046  1665 net.cpp:84] Creating Layer data
I0405 19:38:06.331110  1665 net.cpp:380] data -> data
I0405 19:38:06.331166  1665 net.cpp:380] data -> label
I0405 19:38:06.331218  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 19:38:06.339677  1665 image_data_layer.cpp:53] Shuffling data
I0405 19:38:06.341323  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 19:38:06.342208  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 19:38:06.393105  1665 net.cpp:122] Setting up data
I0405 19:38:06.393272  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:38:06.393358  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:38:06.393422  1665 net.cpp:137] Memory required for data: 19661200
I0405 19:38:06.393535  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 19:38:06.393610  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 19:38:06.393673  1665 net.cpp:406] label_data_1_split <- label
I0405 19:38:06.393786  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 19:38:06.393860  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 19:38:06.393995  1665 net.cpp:122] Setting up label_data_1_split
I0405 19:38:06.394080  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:38:06.394150  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:38:06.394204  1665 net.cpp:137] Memory required for data: 19662000
I0405 19:38:06.394258  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 19:38:06.394330  1665 net.cpp:84] Creating Layer data_bn
I0405 19:38:06.394397  1665 net.cpp:406] data_bn <- data
I0405 19:38:06.394464  1665 net.cpp:380] data_bn -> data_bn
I0405 19:38:06.396347  1665 net.cpp:122] Setting up data_bn
I0405 19:38:06.396462  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:38:06.396535  1665 net.cpp:137] Memory required for data: 39322800
I0405 19:38:06.396641  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:38:06.396711  1665 net.cpp:84] Creating Layer data_scale
I0405 19:38:06.396790  1665 net.cpp:406] data_scale <- data_bn
I0405 19:38:06.396895  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 19:38:06.397019  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:38:06.397255  1665 net.cpp:122] Setting up data_scale
I0405 19:38:06.397336  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:38:06.397403  1665 net.cpp:137] Memory required for data: 58983600
I0405 19:38:06.397466  1665 layer_factory.hpp:77] Creating layer conv1
I0405 19:38:06.397563  1665 net.cpp:84] Creating Layer conv1
I0405 19:38:06.397634  1665 net.cpp:406] conv1 <- data_bn
I0405 19:38:06.397703  1665 net.cpp:380] conv1 -> conv1
I0405 19:38:06.398169  1665 net.cpp:122] Setting up conv1
I0405 19:38:06.398263  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:38:06.398324  1665 net.cpp:137] Memory required for data: 163841200
I0405 19:38:06.398396  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 19:38:06.398459  1665 net.cpp:84] Creating Layer conv1_bn
I0405 19:38:06.398519  1665 net.cpp:406] conv1_bn <- conv1
I0405 19:38:06.398579  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 19:38:06.398862  1665 net.cpp:122] Setting up conv1_bn
I0405 19:38:06.398962  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:38:06.399025  1665 net.cpp:137] Memory required for data: 268698800
I0405 19:38:06.399086  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:38:06.399204  1665 net.cpp:84] Creating Layer conv1_scale
I0405 19:38:06.399277  1665 net.cpp:406] conv1_scale <- conv1
I0405 19:38:06.399338  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 19:38:06.399464  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:38:06.399673  1665 net.cpp:122] Setting up conv1_scale
I0405 19:38:06.399775  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:38:06.399855  1665 net.cpp:137] Memory required for data: 373556400
I0405 19:38:06.399952  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 19:38:06.400022  1665 net.cpp:84] Creating Layer conv1_relu
I0405 19:38:06.400081  1665 net.cpp:406] conv1_relu <- conv1
I0405 19:38:06.400154  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 19:38:06.400215  1665 net.cpp:122] Setting up conv1_relu
I0405 19:38:06.400274  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:38:06.400333  1665 net.cpp:137] Memory required for data: 478414000
I0405 19:38:06.400396  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 19:38:06.400460  1665 net.cpp:84] Creating Layer conv1_pool
I0405 19:38:06.400519  1665 net.cpp:406] conv1_pool <- conv1
I0405 19:38:06.400583  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 19:38:06.400741  1665 net.cpp:122] Setting up conv1_pool
I0405 19:38:06.400822  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:38:06.400887  1665 net.cpp:137] Memory required for data: 504628400
I0405 19:38:06.400955  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 19:38:06.401021  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 19:38:06.401085  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 19:38:06.401142  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 19:38:06.401217  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 19:38:06.401338  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 19:38:06.401417  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:38:06.401475  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:38:06.401535  1665 net.cpp:137] Memory required for data: 557057200
I0405 19:38:06.401597  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 19:38:06.401664  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 19:38:06.401749  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 19:38:06.401826  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 19:38:06.402549  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 19:38:06.402657  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:38:06.402755  1665 net.cpp:137] Memory required for data: 583271600
I0405 19:38:06.402822  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 19:38:06.402894  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 19:38:06.402954  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 19:38:06.403015  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 19:38:06.403331  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 19:38:06.403455  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:38:06.403540  1665 net.cpp:137] Memory required for data: 609486000
I0405 19:38:06.403609  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:38:06.403673  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 19:38:06.403786  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 19:38:06.403853  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 19:38:06.403965  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:38:06.404140  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 19:38:06.404211  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:38:06.404299  1665 net.cpp:137] Memory required for data: 635700400
I0405 19:38:06.404376  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 19:38:06.404431  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 19:38:06.404484  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 19:38:06.404538  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 19:38:06.404637  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 19:38:06.404752  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:38:06.404815  1665 net.cpp:137] Memory required for data: 661914800
I0405 19:38:06.404886  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 19:38:06.404951  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 19:38:06.405017  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 19:38:06.405078  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 19:38:06.405824  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 19:38:06.405921  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:38:06.406015  1665 net.cpp:137] Memory required for data: 688129200
I0405 19:38:06.406083  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 19:38:06.406142  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 19:38:06.406198  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 19:38:06.406255  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 19:38:06.406311  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 19:38:06.406392  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 19:38:06.406452  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:38:06.406507  1665 net.cpp:137] Memory required for data: 714343600
I0405 19:38:06.406560  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 19:38:06.406620  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 19:38:06.406755  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 19:38:06.406814  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 19:38:06.407135  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 19:38:06.407215  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:38:06.407270  1665 net.cpp:137] Memory required for data: 740558000
I0405 19:38:06.407330  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:38:06.407392  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 19:38:06.407457  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 19:38:06.407513  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 19:38:06.407604  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:38:06.407776  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 19:38:06.407850  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:38:06.407938  1665 net.cpp:137] Memory required for data: 766772400
I0405 19:38:06.408007  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 19:38:06.408069  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 19:38:06.408129  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 19:38:06.408191  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 19:38:06.408255  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 19:38:06.408316  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:38:06.408380  1665 net.cpp:137] Memory required for data: 792986800
I0405 19:38:06.408440  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:38:06.408532  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:38:06.408587  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 19:38:06.408645  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:38:06.408699  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:38:06.408815  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:38:06.408874  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:38:06.408936  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:38:06.408993  1665 net.cpp:137] Memory required for data: 845415600
I0405 19:38:06.409057  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 19:38:06.409124  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 19:38:06.409191  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:38:06.409255  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 19:38:06.410473  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 19:38:06.410554  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:38:06.410610  1665 net.cpp:137] Memory required for data: 858522800
I0405 19:38:06.410666  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 19:38:06.410758  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 19:38:06.410811  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 19:38:06.410877  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 19:38:06.411108  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 19:38:06.411180  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:38:06.411234  1665 net.cpp:137] Memory required for data: 871630000
I0405 19:38:06.411293  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:38:06.411358  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 19:38:06.411428  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 19:38:06.411491  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 19:38:06.411597  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:38:06.411773  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 19:38:06.411854  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:38:06.411912  1665 net.cpp:137] Memory required for data: 884737200
I0405 19:38:06.411972  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 19:38:06.412034  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 19:38:06.412092  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 19:38:06.412155  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 19:38:06.412216  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 19:38:06.412277  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:38:06.412361  1665 net.cpp:137] Memory required for data: 897844400
I0405 19:38:06.412425  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 19:38:06.412494  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 19:38:06.412549  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 19:38:06.412608  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 19:38:06.414788  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 19:38:06.414899  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:38:06.414961  1665 net.cpp:137] Memory required for data: 910951600
I0405 19:38:06.415025  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 19:38:06.415096  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 19:38:06.415156  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:38:06.415225  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 19:38:06.415593  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 19:38:06.415669  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:38:06.415753  1665 net.cpp:137] Memory required for data: 924058800
I0405 19:38:06.415819  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 19:38:06.415879  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 19:38:06.415935  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 19:38:06.415990  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 19:38:06.416054  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 19:38:06.416136  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 19:38:06.416189  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:38:06.416244  1665 net.cpp:137] Memory required for data: 937166000
I0405 19:38:06.416297  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 19:38:06.416360  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 19:38:06.416414  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 19:38:06.416469  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 19:38:06.416800  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 19:38:06.416896  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:38:06.416956  1665 net.cpp:137] Memory required for data: 950273200
I0405 19:38:06.417022  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:38:06.417083  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 19:38:06.417145  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 19:38:06.417208  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 19:38:06.417330  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:38:06.417498  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 19:38:06.417613  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:38:06.417673  1665 net.cpp:137] Memory required for data: 963380400
I0405 19:38:06.417764  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 19:38:06.417837  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 19:38:06.417897  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 19:38:06.417963  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 19:38:06.418023  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 19:38:06.418081  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:38:06.418138  1665 net.cpp:137] Memory required for data: 976487600
I0405 19:38:06.418213  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:38:06.418277  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:38:06.418335  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 19:38:06.418406  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:38:06.418512  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:38:06.418627  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:38:06.418686  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:38:06.418769  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:38:06.418828  1665 net.cpp:137] Memory required for data: 1002702000
I0405 19:38:06.419083  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 19:38:06.419180  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 19:38:06.419242  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:38:06.419311  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 19:38:06.424544  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 19:38:06.424665  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:38:06.424785  1665 net.cpp:137] Memory required for data: 1009255600
I0405 19:38:06.424844  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 19:38:06.424958  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 19:38:06.425048  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 19:38:06.425112  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 19:38:06.425395  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 19:38:06.425460  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:38:06.425534  1665 net.cpp:137] Memory required for data: 1015809200
I0405 19:38:06.425602  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:38:06.425668  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 19:38:06.425787  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 19:38:06.425858  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 19:38:06.425967  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:38:06.426156  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 19:38:06.426226  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:38:06.426283  1665 net.cpp:137] Memory required for data: 1022362800
I0405 19:38:06.426360  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 19:38:06.426461  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 19:38:06.426586  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 19:38:06.426657  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 19:38:06.426748  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 19:38:06.426808  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:38:06.426865  1665 net.cpp:137] Memory required for data: 1028916400
I0405 19:38:06.426930  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 19:38:06.427055  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 19:38:06.427119  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 19:38:06.427184  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 19:38:06.436079  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 19:38:06.436183  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:38:06.436262  1665 net.cpp:137] Memory required for data: 1035470000
I0405 19:38:06.436337  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 19:38:06.436410  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 19:38:06.436467  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:38:06.436547  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 19:38:06.437278  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 19:38:06.437364  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:38:06.437451  1665 net.cpp:137] Memory required for data: 1042023600
I0405 19:38:06.437521  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 19:38:06.437602  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 19:38:06.437664  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 19:38:06.437752  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 19:38:06.437809  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 19:38:06.437903  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 19:38:06.437983  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:38:06.438038  1665 net.cpp:137] Memory required for data: 1048577200
I0405 19:38:06.438093  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 19:38:06.438155  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 19:38:06.438210  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 19:38:06.438267  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 19:38:06.438580  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 19:38:06.438671  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:38:06.438750  1665 net.cpp:137] Memory required for data: 1055130800
I0405 19:38:06.438835  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:38:06.438904  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 19:38:06.439007  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 19:38:06.439080  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 19:38:06.439188  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:38:06.439360  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 19:38:06.439455  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:38:06.440162  1665 net.cpp:137] Memory required for data: 1061684400
I0405 19:38:06.440452  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 19:38:06.440511  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 19:38:06.440558  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 19:38:06.440615  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 19:38:06.440687  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 19:38:06.440785  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:38:06.440861  1665 net.cpp:137] Memory required for data: 1068238000
I0405 19:38:06.440917  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:38:06.440975  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:38:06.441040  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 19:38:06.441103  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:38:06.441162  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:38:06.441270  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:38:06.441354  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:38:06.441418  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:38:06.441473  1665 net.cpp:137] Memory required for data: 1081345200
I0405 19:38:06.441527  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 19:38:06.441608  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 19:38:06.441676  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:38:06.441753  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 19:38:06.459007  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 19:38:06.459107  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:38:06.459195  1665 net.cpp:137] Memory required for data: 1084622000
I0405 19:38:06.459259  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 19:38:06.459321  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 19:38:06.459390  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 19:38:06.459456  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 19:38:06.459739  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 19:38:06.459817  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:38:06.459879  1665 net.cpp:137] Memory required for data: 1087898800
I0405 19:38:06.459950  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:38:06.460012  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 19:38:06.460075  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 19:38:06.460139  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 19:38:06.460250  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:38:06.460423  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 19:38:06.460526  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:38:06.460584  1665 net.cpp:137] Memory required for data: 1091175600
I0405 19:38:06.460652  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 19:38:06.460731  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 19:38:06.460798  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 19:38:06.460858  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 19:38:06.460922  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 19:38:06.460994  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:38:06.461051  1665 net.cpp:137] Memory required for data: 1094452400
I0405 19:38:06.461112  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 19:38:06.461179  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 19:38:06.461244  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 19:38:06.461314  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 19:38:06.495827  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 19:38:06.495975  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:38:06.496076  1665 net.cpp:137] Memory required for data: 1097729200
I0405 19:38:06.496141  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 19:38:06.496215  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 19:38:06.496277  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:38:06.496348  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 19:38:06.498306  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 19:38:06.498450  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:38:06.498525  1665 net.cpp:137] Memory required for data: 1101006000
I0405 19:38:06.498590  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 19:38:06.498656  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 19:38:06.498750  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 19:38:06.498818  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 19:38:06.498878  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 19:38:06.498975  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 19:38:06.499048  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:38:06.499111  1665 net.cpp:137] Memory required for data: 1104282800
I0405 19:38:06.499171  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 19:38:06.499235  1665 net.cpp:84] Creating Layer last_bn
I0405 19:38:06.499296  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 19:38:06.499361  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 19:38:06.499614  1665 net.cpp:122] Setting up last_bn
I0405 19:38:06.499699  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:38:06.499794  1665 net.cpp:137] Memory required for data: 1107559600
I0405 19:38:06.499853  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:38:06.499929  1665 net.cpp:84] Creating Layer last_scale
I0405 19:38:06.499991  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 19:38:06.500054  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 19:38:06.500164  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:38:06.500336  1665 net.cpp:122] Setting up last_scale
I0405 19:38:06.500427  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:38:06.500483  1665 net.cpp:137] Memory required for data: 1110836400
I0405 19:38:06.500560  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 19:38:06.500623  1665 net.cpp:84] Creating Layer last_relu
I0405 19:38:06.500685  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 19:38:06.500756  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 19:38:06.500821  1665 net.cpp:122] Setting up last_relu
I0405 19:38:06.500885  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:38:06.500946  1665 net.cpp:137] Memory required for data: 1114113200
I0405 19:38:06.501008  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 19:38:06.501071  1665 net.cpp:84] Creating Layer global_pool
I0405 19:38:06.501133  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 19:38:06.501197  1665 net.cpp:380] global_pool -> global_pool
I0405 19:38:06.501298  1665 net.cpp:122] Setting up global_pool
I0405 19:38:06.501363  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 19:38:06.501446  1665 net.cpp:137] Memory required for data: 1114318000
I0405 19:38:06.501504  1665 layer_factory.hpp:77] Creating layer score
I0405 19:38:06.501581  1665 net.cpp:84] Creating Layer score
I0405 19:38:06.501646  1665 net.cpp:406] score <- global_pool
I0405 19:38:06.501703  1665 net.cpp:380] score -> score
I0405 19:38:06.503430  1665 net.cpp:122] Setting up score
I0405 19:38:06.503538  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:38:06.503602  1665 net.cpp:137] Memory required for data: 1114718000
I0405 19:38:06.503671  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 19:38:06.503762  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 19:38:06.503827  1665 net.cpp:406] score_score_0_split <- score
I0405 19:38:06.503890  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 19:38:06.503948  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 19:38:06.504051  1665 net.cpp:122] Setting up score_score_0_split
I0405 19:38:06.504122  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:38:06.504186  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:38:06.504245  1665 net.cpp:137] Memory required for data: 1115518000
I0405 19:38:06.504302  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:38:06.504359  1665 net.cpp:84] Creating Layer loss
I0405 19:38:06.504415  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 19:38:06.504472  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 19:38:06.504534  1665 net.cpp:380] loss -> loss
I0405 19:38:06.504604  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:38:06.506198  1665 net.cpp:122] Setting up loss
I0405 19:38:06.506299  1665 net.cpp:129] Top shape: (1)
I0405 19:38:06.506366  1665 net.cpp:132]     with loss weight 1
I0405 19:38:06.506440  1665 net.cpp:137] Memory required for data: 1115518004
I0405 19:38:06.506517  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 19:38:06.506592  1665 net.cpp:84] Creating Layer accuracy
I0405 19:38:06.506647  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 19:38:06.506705  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 19:38:06.506778  1665 net.cpp:380] accuracy -> accuracy
I0405 19:38:06.506839  1665 net.cpp:122] Setting up accuracy
I0405 19:38:06.506894  1665 net.cpp:129] Top shape: (1)
I0405 19:38:06.506968  1665 net.cpp:137] Memory required for data: 1115518008
I0405 19:38:06.507031  1665 net.cpp:200] accuracy does not need backward computation.
I0405 19:38:06.507086  1665 net.cpp:198] loss needs backward computation.
I0405 19:38:06.507141  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 19:38:06.507205  1665 net.cpp:198] score needs backward computation.
I0405 19:38:06.507266  1665 net.cpp:198] global_pool needs backward computation.
I0405 19:38:06.507355  1665 net.cpp:198] last_relu needs backward computation.
I0405 19:38:06.507422  1665 net.cpp:198] last_scale needs backward computation.
I0405 19:38:06.507479  1665 net.cpp:198] last_bn needs backward computation.
I0405 19:38:06.507535  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 19:38:06.507591  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 19:38:06.507650  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 19:38:06.507706  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 19:38:06.507784  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 19:38:06.507840  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 19:38:06.507896  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 19:38:06.507953  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 19:38:06.508008  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 19:38:06.508072  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 19:38:06.508137  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 19:38:06.508189  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 19:38:06.508246  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 19:38:06.508311  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 19:38:06.508374  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 19:38:06.508466  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 19:38:06.508527  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 19:38:06.508602  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 19:38:06.508668  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 19:38:06.508776  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 19:38:06.508846  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 19:38:06.508916  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 19:38:06.508988  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 19:38:06.509058  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 19:38:06.509126  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 19:38:06.509193  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 19:38:06.509260  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 19:38:06.509358  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 19:38:06.509435  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 19:38:06.509503  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 19:38:06.509569  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 19:38:06.509639  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 19:38:06.509770  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 19:38:06.509848  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 19:38:06.509912  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 19:38:06.509972  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 19:38:06.510031  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 19:38:06.510092  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 19:38:06.510151  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 19:38:06.510211  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 19:38:06.510272  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 19:38:06.510331  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 19:38:06.510396  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 19:38:06.510457  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 19:38:06.510521  1665 net.cpp:198] conv1 needs backward computation.
I0405 19:38:06.510583  1665 net.cpp:198] data_scale needs backward computation.
I0405 19:38:06.510640  1665 net.cpp:200] data_bn does not need backward computation.
I0405 19:38:06.510702  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 19:38:06.510787  1665 net.cpp:200] data does not need backward computation.
I0405 19:38:06.510848  1665 net.cpp:242] This network produces output accuracy
I0405 19:38:06.510911  1665 net.cpp:242] This network produces output loss
I0405 19:38:06.511008  1665 net.cpp:255] Network initialization done.
I0405 19:38:06.511348  1665 solver.cpp:56] Solver scaffolding done.
I0405 19:38:06.553707  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: data/resnet10_cvgj_iter_320000.caffemodel
I0405 19:38:06.553946  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 19:38:07.026566  1665 solver.cpp:218] Iteration 0 (1.61119e-09 iter/s, 0.467658s/225 iters), loss = 13.1914
I0405 19:38:07.026777  1665 solver.cpp:237]     Train net output #0: loss = 13.1914 (* 1 = 13.1914 loss)
I0405 19:38:07.026917  1665 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I0405 19:39:45.544941  1665 solver.cpp:218] Iteration 225 (2.28379 iter/s, 98.5203s/225 iters), loss = 0.439788
I0405 19:39:45.545244  1665 solver.cpp:237]     Train net output #0: loss = 0.439788 (* 1 = 0.439788 loss)
I0405 19:39:45.545323  1665 sgd_solver.cpp:105] Iteration 225, lr = 0.000875
I0405 19:41:24.062826  1665 solver.cpp:218] Iteration 450 (2.28392 iter/s, 98.515s/225 iters), loss = 0.206058
I0405 19:41:24.063079  1665 solver.cpp:237]     Train net output #0: loss = 0.206058 (* 1 = 0.206058 loss)
I0405 19:41:24.063158  1665 sgd_solver.cpp:105] Iteration 450, lr = 0.00075
I0405 19:41:31.945382  1665 solver.cpp:330] Iteration 469, Testing net (#0)
I0405 19:43:02.576619  1665 solver.cpp:218] Iteration 675 (2.28403 iter/s, 98.5102s/225 iters), loss = 0.149586
I0405 19:43:02.576951  1665 solver.cpp:237]     Train net output #0: loss = 0.149586 (* 1 = 0.149586 loss)
I0405 19:43:02.577016  1665 sgd_solver.cpp:105] Iteration 675, lr = 0.000625
I0405 19:44:41.090837  1665 solver.cpp:218] Iteration 900 (2.284 iter/s, 98.5114s/225 iters), loss = 0.158543
I0405 19:44:41.091179  1665 solver.cpp:237]     Train net output #0: loss = 0.158543 (* 1 = 0.158543 loss)
I0405 19:44:41.091255  1665 sgd_solver.cpp:105] Iteration 900, lr = 0.0005
I0405 19:44:57.292934  1665 solver.cpp:330] Iteration 938, Testing net (#0)
I0405 19:46:19.600634  1665 solver.cpp:218] Iteration 1125 (2.28409 iter/s, 98.5076s/225 iters), loss = 0.08933
I0405 19:46:19.600888  1665 solver.cpp:237]     Train net output #0: loss = 0.08933 (* 1 = 0.08933 loss)
I0405 19:46:19.600981  1665 sgd_solver.cpp:105] Iteration 1125, lr = 0.000375
I0405 19:47:58.109082  1665 solver.cpp:218] Iteration 1350 (2.2841 iter/s, 98.507s/225 iters), loss = 0.085959
I0405 19:47:58.109375  1665 solver.cpp:237]     Train net output #0: loss = 0.085959 (* 1 = 0.085959 loss)
I0405 19:47:58.109452  1665 sgd_solver.cpp:105] Iteration 1350, lr = 0.00025
I0405 19:48:22.628051  1665 solver.cpp:330] Iteration 1407, Testing net (#0)
I0405 19:49:36.625609  1665 solver.cpp:218] Iteration 1575 (2.28391 iter/s, 98.5155s/225 iters), loss = 0.0549051
I0405 19:49:36.626018  1665 solver.cpp:237]     Train net output #0: loss = 0.0549051 (* 1 = 0.0549051 loss)
I0405 19:49:36.626134  1665 sgd_solver.cpp:105] Iteration 1575, lr = 0.000125
I0405 19:51:14.698164  1665 solver.cpp:457] Snapshotting to HDF5 file data/snapshots/train_batch_04_iter_1800.caffemodel.h5
I0405 19:51:14.754380  1665 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file data/snapshots/train_batch_04_iter_1800.solverstate.h5
W0405 19:51:16.674782  1665 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W0405 19:51:16.674999  1665 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W0405 19:51:16.675061  1665 _caffe.cpp:142] Net('confs/sII/mid-caffeNet/inc_train_val.prototxt', 1, weights='data/snapshots/train_batch_04_iter_1800.caffemodel.h5')
I0405 19:51:16.678989  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:51:16.679147  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 19:51:16.679278  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 19:51:16.679601  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 19:51:16.680037  1665 layer_factory.hpp:77] Creating layer data
I0405 19:51:16.680284  1665 net.cpp:84] Creating Layer data
I0405 19:51:16.680364  1665 net.cpp:380] data -> data
I0405 19:51:16.680418  1665 net.cpp:380] data -> label
I0405 19:51:16.680469  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 19:51:16.688954  1665 image_data_layer.cpp:53] Shuffling data
I0405 19:51:16.690377  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 19:51:16.691519  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 19:51:16.744247  1665 net.cpp:122] Setting up data
I0405 19:51:16.744493  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:51:16.744607  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:51:16.744683  1665 net.cpp:137] Memory required for data: 19661200
I0405 19:51:16.744777  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 19:51:16.744860  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 19:51:16.744992  1665 net.cpp:406] label_data_1_split <- label
I0405 19:51:16.745085  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 19:51:16.745165  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 19:51:16.745293  1665 net.cpp:122] Setting up label_data_1_split
I0405 19:51:16.745394  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:51:16.745470  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:51:16.745568  1665 net.cpp:137] Memory required for data: 19662000
I0405 19:51:16.745642  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 19:51:16.745741  1665 net.cpp:84] Creating Layer data_bn
I0405 19:51:16.745822  1665 net.cpp:406] data_bn <- data
I0405 19:51:16.745891  1665 net.cpp:380] data_bn -> data_bn
I0405 19:51:16.748193  1665 net.cpp:122] Setting up data_bn
I0405 19:51:16.748327  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:51:16.748425  1665 net.cpp:137] Memory required for data: 39322800
I0405 19:51:16.748507  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:51:16.748590  1665 net.cpp:84] Creating Layer data_scale
I0405 19:51:16.748663  1665 net.cpp:406] data_scale <- data_bn
I0405 19:51:16.748764  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 19:51:16.748894  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:51:16.749269  1665 net.cpp:122] Setting up data_scale
I0405 19:51:16.749413  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:51:16.749497  1665 net.cpp:137] Memory required for data: 58983600
I0405 19:51:16.749595  1665 layer_factory.hpp:77] Creating layer conv1
I0405 19:51:16.749689  1665 net.cpp:84] Creating Layer conv1
I0405 19:51:16.749814  1665 net.cpp:406] conv1 <- data_bn
I0405 19:51:16.749917  1665 net.cpp:380] conv1 -> conv1
I0405 19:51:16.750362  1665 net.cpp:122] Setting up conv1
I0405 19:51:16.750499  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:51:16.750600  1665 net.cpp:137] Memory required for data: 163841200
I0405 19:51:16.750705  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 19:51:16.750811  1665 net.cpp:84] Creating Layer conv1_bn
I0405 19:51:16.750895  1665 net.cpp:406] conv1_bn <- conv1
I0405 19:51:16.750991  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 19:51:16.751256  1665 net.cpp:122] Setting up conv1_bn
I0405 19:51:16.751366  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:51:16.751466  1665 net.cpp:137] Memory required for data: 268698800
I0405 19:51:16.751552  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:51:16.751639  1665 net.cpp:84] Creating Layer conv1_scale
I0405 19:51:16.751762  1665 net.cpp:406] conv1_scale <- conv1
I0405 19:51:16.751859  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 19:51:16.751997  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:51:16.752226  1665 net.cpp:122] Setting up conv1_scale
I0405 19:51:16.752337  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:51:16.752429  1665 net.cpp:137] Memory required for data: 373556400
I0405 19:51:16.752521  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 19:51:16.752614  1665 net.cpp:84] Creating Layer conv1_relu
I0405 19:51:16.752696  1665 net.cpp:406] conv1_relu <- conv1
I0405 19:51:16.752820  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 19:51:16.752907  1665 net.cpp:122] Setting up conv1_relu
I0405 19:51:16.753021  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:51:16.753103  1665 net.cpp:137] Memory required for data: 478414000
I0405 19:51:16.753196  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 19:51:16.753293  1665 net.cpp:84] Creating Layer conv1_pool
I0405 19:51:16.753365  1665 net.cpp:406] conv1_pool <- conv1
I0405 19:51:16.753448  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 19:51:16.753593  1665 net.cpp:122] Setting up conv1_pool
I0405 19:51:16.753698  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:16.753803  1665 net.cpp:137] Memory required for data: 504628400
I0405 19:51:16.753885  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 19:51:16.754011  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 19:51:16.754096  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 19:51:16.754180  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 19:51:16.754402  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 19:51:16.754683  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 19:51:16.754914  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:16.755043  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:16.755159  1665 net.cpp:137] Memory required for data: 557057200
I0405 19:51:16.755291  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 19:51:16.755409  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 19:51:16.755494  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 19:51:16.755621  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 19:51:16.756533  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 19:51:16.756654  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:16.756798  1665 net.cpp:137] Memory required for data: 583271600
I0405 19:51:16.756906  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 19:51:16.756996  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 19:51:16.757086  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 19:51:16.757225  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 19:51:16.757501  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 19:51:16.757616  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:16.757699  1665 net.cpp:137] Memory required for data: 609486000
I0405 19:51:16.757810  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:51:16.757916  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 19:51:16.757990  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 19:51:16.758074  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 19:51:16.758235  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:51:16.758424  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 19:51:16.758528  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:16.758605  1665 net.cpp:137] Memory required for data: 635700400
I0405 19:51:16.758692  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 19:51:16.758805  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 19:51:16.758916  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 19:51:16.759001  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 19:51:16.759099  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 19:51:16.759187  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:16.759265  1665 net.cpp:137] Memory required for data: 661914800
I0405 19:51:16.759346  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 19:51:16.759433  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 19:51:16.759513  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 19:51:16.759603  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 19:51:16.760298  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 19:51:16.760430  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:16.760525  1665 net.cpp:137] Memory required for data: 688129200
I0405 19:51:16.760617  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 19:51:16.760740  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 19:51:16.760823  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 19:51:16.760905  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 19:51:16.761013  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 19:51:16.761132  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 19:51:16.761240  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:16.761319  1665 net.cpp:137] Memory required for data: 714343600
I0405 19:51:16.761399  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 19:51:16.761508  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 19:51:16.761593  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 19:51:16.761665  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 19:51:16.761958  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 19:51:16.762050  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:16.762125  1665 net.cpp:137] Memory required for data: 740558000
I0405 19:51:16.762197  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:51:16.762270  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 19:51:16.762339  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 19:51:16.762409  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 19:51:16.762543  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:51:16.762733  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 19:51:16.762810  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:16.762878  1665 net.cpp:137] Memory required for data: 766772400
I0405 19:51:16.762948  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 19:51:16.763025  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 19:51:16.763093  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 19:51:16.763164  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 19:51:16.763236  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 19:51:16.763312  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:16.763379  1665 net.cpp:137] Memory required for data: 792986800
I0405 19:51:16.763461  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:51:16.763540  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:51:16.763603  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 19:51:16.763674  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:51:16.763764  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:51:16.763864  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:51:16.763939  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:16.764009  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:16.764088  1665 net.cpp:137] Memory required for data: 845415600
I0405 19:51:16.764164  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 19:51:16.764238  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 19:51:16.764307  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:51:16.764377  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 19:51:16.765288  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 19:51:16.765404  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:16.765497  1665 net.cpp:137] Memory required for data: 858522800
I0405 19:51:16.765657  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 19:51:16.765756  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 19:51:16.765828  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 19:51:16.765900  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 19:51:16.766135  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 19:51:16.766216  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:16.766306  1665 net.cpp:137] Memory required for data: 871630000
I0405 19:51:16.766387  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:51:16.766463  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 19:51:16.766531  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 19:51:16.766607  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 19:51:16.766729  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:51:16.766932  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 19:51:16.767040  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:16.767115  1665 net.cpp:137] Memory required for data: 884737200
I0405 19:51:16.767192  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 19:51:16.767264  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 19:51:16.767333  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 19:51:16.767422  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 19:51:16.767494  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 19:51:16.767582  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:16.767660  1665 net.cpp:137] Memory required for data: 897844400
I0405 19:51:16.767750  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 19:51:16.767833  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 19:51:16.767915  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 19:51:16.767985  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 19:51:16.769570  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 19:51:16.769693  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:16.769780  1665 net.cpp:137] Memory required for data: 910951600
I0405 19:51:16.769868  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 19:51:16.769944  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 19:51:16.770025  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:51:16.770105  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 19:51:16.770365  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 19:51:16.770462  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:16.770542  1665 net.cpp:137] Memory required for data: 924058800
I0405 19:51:16.770620  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 19:51:16.770706  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 19:51:16.770797  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 19:51:16.770879  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 19:51:16.770957  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 19:51:16.771049  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 19:51:16.771140  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:16.771209  1665 net.cpp:137] Memory required for data: 937166000
I0405 19:51:16.771277  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 19:51:16.771349  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 19:51:16.771418  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 19:51:16.771502  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 19:51:16.771770  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 19:51:16.771867  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:16.771937  1665 net.cpp:137] Memory required for data: 950273200
I0405 19:51:16.772013  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:51:16.772086  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 19:51:16.772156  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 19:51:16.772228  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 19:51:16.772347  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:51:16.772508  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 19:51:16.772594  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:16.772665  1665 net.cpp:137] Memory required for data: 963380400
I0405 19:51:16.772764  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 19:51:16.772855  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 19:51:16.772924  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 19:51:16.772994  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 19:51:16.773077  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 19:51:16.773165  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:16.773249  1665 net.cpp:137] Memory required for data: 976487600
I0405 19:51:16.773330  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:51:16.773406  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:51:16.773478  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 19:51:16.773568  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:51:16.773641  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:51:16.773763  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:51:16.773842  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:16.773926  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:16.773993  1665 net.cpp:137] Memory required for data: 1002702000
I0405 19:51:16.774073  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 19:51:16.774168  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 19:51:16.774237  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:51:16.774312  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 19:51:16.779399  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 19:51:16.779475  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:16.779526  1665 net.cpp:137] Memory required for data: 1009255600
I0405 19:51:16.779618  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 19:51:16.779675  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 19:51:16.779736  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 19:51:16.779789  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 19:51:16.780020  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 19:51:16.780095  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:16.780144  1665 net.cpp:137] Memory required for data: 1015809200
I0405 19:51:16.780200  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:51:16.780256  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 19:51:16.780305  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 19:51:16.780364  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 19:51:16.780457  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:51:16.780616  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 19:51:16.780683  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:16.780741  1665 net.cpp:137] Memory required for data: 1022362800
I0405 19:51:16.780795  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 19:51:16.780851  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 19:51:16.780905  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 19:51:16.780958  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 19:51:16.781010  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 19:51:16.781075  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:16.781127  1665 net.cpp:137] Memory required for data: 1028916400
I0405 19:51:16.781178  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 19:51:16.781234  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 19:51:16.781283  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 19:51:16.781342  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 19:51:16.790060  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 19:51:16.790155  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:16.790213  1665 net.cpp:137] Memory required for data: 1035470000
I0405 19:51:16.790268  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 19:51:16.790328  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 19:51:16.790381  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:51:16.790436  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 19:51:16.791110  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 19:51:16.791193  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:16.791252  1665 net.cpp:137] Memory required for data: 1042023600
I0405 19:51:16.791313  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 19:51:16.791376  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 19:51:16.791436  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 19:51:16.791497  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 19:51:16.791558  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 19:51:16.791644  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 19:51:16.791736  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:16.791805  1665 net.cpp:137] Memory required for data: 1048577200
I0405 19:51:16.791859  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 19:51:16.791921  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 19:51:16.791981  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 19:51:16.792042  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 19:51:16.792284  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 19:51:16.792364  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:16.792423  1665 net.cpp:137] Memory required for data: 1055130800
I0405 19:51:16.792487  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:51:16.792551  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 19:51:16.792613  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 19:51:16.792675  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 19:51:16.792788  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:51:16.792958  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 19:51:16.793035  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:16.793098  1665 net.cpp:137] Memory required for data: 1061684400
I0405 19:51:16.793155  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 19:51:16.793218  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 19:51:16.793278  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 19:51:16.793339  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 19:51:16.793403  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 19:51:16.793464  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:16.793524  1665 net.cpp:137] Memory required for data: 1068238000
I0405 19:51:16.793589  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:51:16.793651  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:51:16.793710  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 19:51:16.793788  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:51:16.793853  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:51:16.793951  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:51:16.794016  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:16.794080  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:16.794138  1665 net.cpp:137] Memory required for data: 1081345200
I0405 19:51:16.794198  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 19:51:16.794270  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 19:51:16.794332  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:51:16.794397  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 19:51:16.811704  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 19:51:16.811825  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:16.811888  1665 net.cpp:137] Memory required for data: 1084622000
I0405 19:51:16.811950  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 19:51:16.812016  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 19:51:16.812192  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 19:51:16.812248  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 19:51:16.812484  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 19:51:16.812536  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:16.812603  1665 net.cpp:137] Memory required for data: 1087898800
I0405 19:51:16.812661  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:51:16.812736  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 19:51:16.812790  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 19:51:16.812856  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 19:51:16.812950  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:51:16.813125  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 19:51:16.813190  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:16.813243  1665 net.cpp:137] Memory required for data: 1091175600
I0405 19:51:16.813298  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 19:51:16.813355  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 19:51:16.813408  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 19:51:16.813462  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 19:51:16.813518  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 19:51:16.813570  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:16.813618  1665 net.cpp:137] Memory required for data: 1094452400
I0405 19:51:16.813673  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 19:51:16.813756  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 19:51:16.813817  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 19:51:16.813872  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 19:51:16.843760  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 19:51:16.843926  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:16.843997  1665 net.cpp:137] Memory required for data: 1097729200
I0405 19:51:16.844058  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 19:51:16.844138  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 19:51:16.844205  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:51:16.844264  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 19:51:16.845513  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 19:51:16.845620  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:16.845692  1665 net.cpp:137] Memory required for data: 1101006000
I0405 19:51:16.845755  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 19:51:16.845818  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 19:51:16.845875  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 19:51:16.845935  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 19:51:16.845993  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 19:51:16.846079  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 19:51:16.846158  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:16.846215  1665 net.cpp:137] Memory required for data: 1104282800
I0405 19:51:16.846272  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 19:51:16.846331  1665 net.cpp:84] Creating Layer last_bn
I0405 19:51:16.846390  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 19:51:16.846448  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 19:51:16.846657  1665 net.cpp:122] Setting up last_bn
I0405 19:51:16.846765  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:16.846824  1665 net.cpp:137] Memory required for data: 1107559600
I0405 19:51:16.846896  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:51:16.846961  1665 net.cpp:84] Creating Layer last_scale
I0405 19:51:16.847018  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 19:51:16.847077  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 19:51:16.847188  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:51:16.847370  1665 net.cpp:122] Setting up last_scale
I0405 19:51:16.847451  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:16.847509  1665 net.cpp:137] Memory required for data: 1110836400
I0405 19:51:16.847570  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 19:51:16.847637  1665 net.cpp:84] Creating Layer last_relu
I0405 19:51:16.847697  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 19:51:16.847770  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 19:51:16.847841  1665 net.cpp:122] Setting up last_relu
I0405 19:51:16.847903  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:16.847960  1665 net.cpp:137] Memory required for data: 1114113200
I0405 19:51:16.848019  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 19:51:16.848083  1665 net.cpp:84] Creating Layer global_pool
I0405 19:51:16.848148  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 19:51:16.848209  1665 net.cpp:380] global_pool -> global_pool
I0405 19:51:16.849807  1665 net.cpp:122] Setting up global_pool
I0405 19:51:16.849915  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 19:51:16.849975  1665 net.cpp:137] Memory required for data: 1114318000
I0405 19:51:16.850045  1665 layer_factory.hpp:77] Creating layer score
I0405 19:51:16.850112  1665 net.cpp:84] Creating Layer score
I0405 19:51:16.850170  1665 net.cpp:406] score <- global_pool
I0405 19:51:16.850230  1665 net.cpp:380] score -> score
I0405 19:51:16.851634  1665 net.cpp:122] Setting up score
I0405 19:51:16.851758  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:51:16.851816  1665 net.cpp:137] Memory required for data: 1114718000
I0405 19:51:16.851879  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 19:51:16.851938  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 19:51:16.852020  1665 net.cpp:406] score_score_0_split <- score
I0405 19:51:16.852077  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 19:51:16.852147  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 19:51:16.852246  1665 net.cpp:122] Setting up score_score_0_split
I0405 19:51:16.852308  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:51:16.852365  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:51:16.852418  1665 net.cpp:137] Memory required for data: 1115518000
I0405 19:51:16.852473  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:51:16.852530  1665 net.cpp:84] Creating Layer loss
I0405 19:51:16.852584  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 19:51:16.852641  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 19:51:16.852697  1665 net.cpp:380] loss -> loss
I0405 19:51:16.852777  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:51:16.853976  1665 net.cpp:122] Setting up loss
I0405 19:51:16.854079  1665 net.cpp:129] Top shape: (1)
I0405 19:51:16.854152  1665 net.cpp:132]     with loss weight 1
I0405 19:51:16.854229  1665 net.cpp:137] Memory required for data: 1115518004
I0405 19:51:16.854295  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 19:51:16.854362  1665 net.cpp:84] Creating Layer accuracy
I0405 19:51:16.854411  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 19:51:16.854467  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 19:51:16.854526  1665 net.cpp:380] accuracy -> accuracy
I0405 19:51:16.854588  1665 net.cpp:122] Setting up accuracy
I0405 19:51:16.854660  1665 net.cpp:129] Top shape: (1)
I0405 19:51:16.854732  1665 net.cpp:137] Memory required for data: 1115518008
I0405 19:51:16.854792  1665 net.cpp:200] accuracy does not need backward computation.
I0405 19:51:16.854848  1665 net.cpp:198] loss needs backward computation.
I0405 19:51:16.854915  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 19:51:16.854969  1665 net.cpp:198] score needs backward computation.
I0405 19:51:16.855024  1665 net.cpp:198] global_pool needs backward computation.
I0405 19:51:16.855079  1665 net.cpp:198] last_relu needs backward computation.
I0405 19:51:16.855146  1665 net.cpp:198] last_scale needs backward computation.
I0405 19:51:16.855206  1665 net.cpp:198] last_bn needs backward computation.
I0405 19:51:16.855260  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 19:51:16.855316  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 19:51:16.855370  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 19:51:16.855463  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 19:51:16.855568  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 19:51:16.855640  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 19:51:16.855738  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 19:51:16.855803  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 19:51:16.855895  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 19:51:16.855959  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 19:51:16.856024  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 19:51:16.856096  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 19:51:16.856173  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 19:51:16.856238  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 19:51:16.856303  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 19:51:16.856367  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 19:51:16.856431  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 19:51:16.856494  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 19:51:16.856559  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 19:51:16.856639  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 19:51:16.856701  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 19:51:16.856801  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 19:51:16.856869  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 19:51:16.856928  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 19:51:16.856986  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 19:51:16.857064  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 19:51:16.857141  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 19:51:16.857198  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 19:51:16.857252  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 19:51:16.857307  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 19:51:16.857362  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 19:51:16.857416  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 19:51:16.857470  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 19:51:16.857524  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 19:51:16.857589  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 19:51:16.858110  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 19:51:16.858201  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 19:51:16.858271  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 19:51:16.858328  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 19:51:16.858388  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 19:51:16.858443  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 19:51:16.858498  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 19:51:16.858554  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 19:51:16.858609  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 19:51:16.858665  1665 net.cpp:198] conv1 needs backward computation.
I0405 19:51:16.858752  1665 net.cpp:198] data_scale needs backward computation.
I0405 19:51:16.858809  1665 net.cpp:200] data_bn does not need backward computation.
I0405 19:51:16.858865  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 19:51:16.858920  1665 net.cpp:200] data does not need backward computation.
I0405 19:51:16.858980  1665 net.cpp:242] This network produces output accuracy
I0405 19:51:16.859041  1665 net.cpp:242] This network produces output loss
I0405 19:51:16.859131  1665 net.cpp:255] Network initialization done.
I0405 19:51:34.038789  1665 blocking_queue.cpp:49] Waiting for data
I0405 19:51:56.380712  1665 solver.cpp:44] Initializing solver from parameters: 
test_iter: 0
test_interval: 469
base_lr: 0.001
display: 225
max_iter: 1800
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 1800
snapshot_prefix: "data/snapshots/train_batch_05"
solver_mode: GPU
random_seed: 0
net: "confs/sII/mid-caffeNet/inc_train_val.prototxt"
test_initialization: false
snapshot_format: HDF5
I0405 19:51:56.383308  1665 solver.cpp:87] Creating training net from net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:51:56.384404  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:51:56.384544  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 19:51:56.384742  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0405 19:51:56.384853  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0405 19:51:56.385136  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/train_batch_05_filelist.txt"
    batch_size: 256
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I0405 19:51:56.385458  1665 layer_factory.hpp:77] Creating layer data
I0405 19:51:56.385555  1665 net.cpp:84] Creating Layer data
I0405 19:51:56.385625  1665 net.cpp:380] data -> data
I0405 19:51:56.385689  1665 net.cpp:380] data -> label
I0405 19:51:56.385771  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/train_batch_05_filelist.txt
I0405 19:51:56.399971  1665 image_data_layer.cpp:53] Shuffling data
I0405 19:51:56.401865  1665 image_data_layer.cpp:63] A total of 83924 images.
I0405 19:51:56.403997  1665 image_data_layer.cpp:90] output data size: 256,3,128,128
I0405 19:51:56.535207  1665 net.cpp:122] Setting up data
I0405 19:51:56.535445  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 19:51:56.535528  1665 net.cpp:129] Top shape: 256 (256)
I0405 19:51:56.535588  1665 net.cpp:137] Memory required for data: 50332672
I0405 19:51:56.535650  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 19:51:56.535737  1665 net.cpp:84] Creating Layer data_bn
I0405 19:51:56.535897  1665 net.cpp:406] data_bn <- data
I0405 19:51:56.535964  1665 net.cpp:380] data_bn -> data_bn
I0405 19:51:56.536190  1665 net.cpp:122] Setting up data_bn
I0405 19:51:56.536265  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 19:51:56.536321  1665 net.cpp:137] Memory required for data: 100664320
I0405 19:51:56.536382  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:51:56.536444  1665 net.cpp:84] Creating Layer data_scale
I0405 19:51:56.536496  1665 net.cpp:406] data_scale <- data_bn
I0405 19:51:56.536554  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 19:51:56.536630  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:51:56.541752  1665 net.cpp:122] Setting up data_scale
I0405 19:51:56.541857  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 19:51:56.541978  1665 net.cpp:137] Memory required for data: 150995968
I0405 19:51:56.542039  1665 layer_factory.hpp:77] Creating layer conv1
I0405 19:51:56.542100  1665 net.cpp:84] Creating Layer conv1
I0405 19:51:56.542156  1665 net.cpp:406] conv1 <- data_bn
I0405 19:51:56.542222  1665 net.cpp:380] conv1 -> conv1
I0405 19:51:56.542515  1665 net.cpp:122] Setting up conv1
I0405 19:51:56.542587  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 19:51:56.542661  1665 net.cpp:137] Memory required for data: 419431424
I0405 19:51:56.542718  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 19:51:56.542788  1665 net.cpp:84] Creating Layer conv1_bn
I0405 19:51:56.542845  1665 net.cpp:406] conv1_bn <- conv1
I0405 19:51:56.542913  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 19:51:56.543102  1665 net.cpp:122] Setting up conv1_bn
I0405 19:51:56.543175  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 19:51:56.543231  1665 net.cpp:137] Memory required for data: 687866880
I0405 19:51:56.543290  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:51:56.543349  1665 net.cpp:84] Creating Layer conv1_scale
I0405 19:51:56.543403  1665 net.cpp:406] conv1_scale <- conv1
I0405 19:51:56.543463  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 19:51:56.543537  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:51:56.543663  1665 net.cpp:122] Setting up conv1_scale
I0405 19:51:56.543756  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 19:51:56.543812  1665 net.cpp:137] Memory required for data: 956302336
I0405 19:51:56.543869  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 19:51:56.543943  1665 net.cpp:84] Creating Layer conv1_relu
I0405 19:51:56.543998  1665 net.cpp:406] conv1_relu <- conv1
I0405 19:51:56.544059  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 19:51:56.544114  1665 net.cpp:122] Setting up conv1_relu
I0405 19:51:56.544170  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 19:51:56.544225  1665 net.cpp:137] Memory required for data: 1224737792
I0405 19:51:56.544279  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 19:51:56.544337  1665 net.cpp:84] Creating Layer conv1_pool
I0405 19:51:56.544391  1665 net.cpp:406] conv1_pool <- conv1
I0405 19:51:56.544458  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 19:51:56.544534  1665 net.cpp:122] Setting up conv1_pool
I0405 19:51:56.544606  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:51:56.544661  1665 net.cpp:137] Memory required for data: 1291846656
I0405 19:51:56.544744  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 19:51:56.544826  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 19:51:56.544878  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 19:51:56.544932  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 19:51:56.544987  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 19:51:56.545061  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 19:51:56.545135  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:51:56.545197  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:51:56.545250  1665 net.cpp:137] Memory required for data: 1426064384
I0405 19:51:56.545302  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 19:51:56.545363  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 19:51:56.545418  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 19:51:56.545473  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 19:51:56.545954  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 19:51:56.546042  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:51:56.546108  1665 net.cpp:137] Memory required for data: 1493173248
I0405 19:51:56.546173  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 19:51:56.546233  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 19:51:56.546289  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 19:51:56.546345  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 19:51:56.546542  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 19:51:56.546615  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:51:56.546671  1665 net.cpp:137] Memory required for data: 1560282112
I0405 19:51:56.546758  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:51:56.546841  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 19:51:56.546895  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 19:51:56.546949  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 19:51:56.547024  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:51:56.547178  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 19:51:56.547230  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:51:56.547283  1665 net.cpp:137] Memory required for data: 1627390976
I0405 19:51:56.547341  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 19:51:56.547400  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 19:51:56.547461  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 19:51:56.547516  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 19:51:56.547574  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 19:51:56.547629  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:51:56.547685  1665 net.cpp:137] Memory required for data: 1694499840
I0405 19:51:56.547760  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 19:51:56.547817  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 19:51:56.547879  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 19:51:56.547933  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 19:51:56.548377  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 19:51:56.548473  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:51:56.548530  1665 net.cpp:137] Memory required for data: 1761608704
I0405 19:51:56.548585  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 19:51:56.548645  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 19:51:56.548700  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 19:51:56.548775  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 19:51:56.548841  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 19:51:56.548910  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 19:51:56.548979  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:51:56.549033  1665 net.cpp:137] Memory required for data: 1828717568
I0405 19:51:56.549088  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 19:51:56.549173  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 19:51:56.549234  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 19:51:56.549291  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 19:51:56.549479  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 19:51:56.549552  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:51:56.549608  1665 net.cpp:137] Memory required for data: 1895826432
I0405 19:51:56.549665  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:51:56.549747  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 19:51:56.549809  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 19:51:56.549891  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 19:51:56.549968  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:51:56.550092  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 19:51:56.550179  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:51:56.550238  1665 net.cpp:137] Memory required for data: 1962935296
I0405 19:51:56.550293  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 19:51:56.550351  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 19:51:56.550406  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 19:51:56.550472  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 19:51:56.550529  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 19:51:56.550585  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:51:56.550640  1665 net.cpp:137] Memory required for data: 2030044160
I0405 19:51:56.550700  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:51:56.550782  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:51:56.550837  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 19:51:56.550892  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:51:56.550957  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:51:56.551043  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:51:56.551100  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:51:56.551153  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 19:51:56.551219  1665 net.cpp:137] Memory required for data: 2164261888
I0405 19:51:56.551281  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 19:51:56.551339  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 19:51:56.551394  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:51:56.551460  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 19:51:56.552227  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 19:51:56.552320  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:51:56.552376  1665 net.cpp:137] Memory required for data: 2197816320
I0405 19:51:56.552441  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 19:51:56.552497  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 19:51:56.552554  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 19:51:56.552613  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 19:51:56.552808  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 19:51:56.552867  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:51:56.552922  1665 net.cpp:137] Memory required for data: 2231370752
I0405 19:51:56.552978  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:51:56.553035  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 19:51:56.553088  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 19:51:56.553167  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 19:51:56.553248  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:51:56.553364  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 19:51:56.553434  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:51:56.553493  1665 net.cpp:137] Memory required for data: 2264925184
I0405 19:51:56.553550  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 19:51:56.553607  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 19:51:56.553663  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 19:51:56.553723  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 19:51:56.553776  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 19:51:56.553831  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:51:56.553896  1665 net.cpp:137] Memory required for data: 2298479616
I0405 19:51:56.553951  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 19:51:56.554009  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 19:51:56.554062  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 19:51:56.554117  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 19:51:56.555516  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 19:51:56.555599  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:51:56.555671  1665 net.cpp:137] Memory required for data: 2332034048
I0405 19:51:56.555757  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 19:51:56.555840  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 19:51:56.555898  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:51:56.555963  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 19:51:56.556200  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 19:51:56.556273  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:51:56.556329  1665 net.cpp:137] Memory required for data: 2365588480
I0405 19:51:56.556385  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 19:51:56.556447  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 19:51:56.556504  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 19:51:56.556571  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 19:51:56.556625  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 19:51:56.556691  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 19:51:56.556761  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:51:56.556824  1665 net.cpp:137] Memory required for data: 2399142912
I0405 19:51:56.556882  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 19:51:56.556946  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 19:51:56.557004  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 19:51:56.557061  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 19:51:56.557233  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 19:51:56.557303  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:51:56.557359  1665 net.cpp:137] Memory required for data: 2432697344
I0405 19:51:56.557422  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:51:56.557485  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 19:51:56.557543  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 19:51:56.557598  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 19:51:56.557680  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:51:56.557812  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 19:51:56.557885  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:51:56.558007  1665 net.cpp:137] Memory required for data: 2466251776
I0405 19:51:56.558137  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 19:51:56.558224  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 19:51:56.558296  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 19:51:56.558363  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 19:51:56.558439  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 19:51:56.558506  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:51:56.558573  1665 net.cpp:137] Memory required for data: 2499806208
I0405 19:51:56.558640  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:51:56.558706  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:51:56.558779  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 19:51:56.558846  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:51:56.558931  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:51:56.559010  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:51:56.559077  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:51:56.559139  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 19:51:56.559219  1665 net.cpp:137] Memory required for data: 2566915072
I0405 19:51:56.559298  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 19:51:56.559370  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 19:51:56.559461  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:51:56.559531  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 19:51:56.562903  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 19:51:56.563015  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:51:56.563072  1665 net.cpp:137] Memory required for data: 2583692288
I0405 19:51:56.563131  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 19:51:56.563199  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 19:51:56.563269  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 19:51:56.563349  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 19:51:56.563540  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 19:51:56.563643  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:51:56.563740  1665 net.cpp:137] Memory required for data: 2600469504
I0405 19:51:56.563802  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:51:56.563861  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 19:51:56.563920  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 19:51:56.563975  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 19:51:56.564050  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:51:56.564165  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 19:51:56.564239  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:51:56.564293  1665 net.cpp:137] Memory required for data: 2617246720
I0405 19:51:56.564370  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 19:51:56.564437  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 19:51:56.564491  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 19:51:56.564544  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 19:51:56.564599  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 19:51:56.564690  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:51:56.564790  1665 net.cpp:137] Memory required for data: 2634023936
I0405 19:51:56.564848  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 19:51:56.564908  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 19:51:56.564965  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 19:51:56.565022  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 19:51:56.570696  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 19:51:56.570809  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:51:56.570891  1665 net.cpp:137] Memory required for data: 2650801152
I0405 19:51:56.570953  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 19:51:56.571020  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 19:51:56.571089  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:51:56.571171  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 19:51:56.571621  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 19:51:56.571698  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:51:56.571784  1665 net.cpp:137] Memory required for data: 2667578368
I0405 19:51:56.571867  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 19:51:56.571923  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 19:51:56.571976  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 19:51:56.572031  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 19:51:56.572085  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 19:51:56.572180  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 19:51:56.572279  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:51:56.572335  1665 net.cpp:137] Memory required for data: 2684355584
I0405 19:51:56.572391  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 19:51:56.572468  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 19:51:56.572536  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 19:51:56.572593  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 19:51:56.572814  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 19:51:56.572913  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:51:56.572974  1665 net.cpp:137] Memory required for data: 2701132800
I0405 19:51:56.573033  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:51:56.573088  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 19:51:56.573140  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 19:51:56.573227  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 19:51:56.573305  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:51:56.573433  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 19:51:56.573526  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:51:56.573582  1665 net.cpp:137] Memory required for data: 2717910016
I0405 19:51:56.573642  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 19:51:56.573696  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 19:51:56.573773  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 19:51:56.573832  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 19:51:56.573886  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 19:51:56.573942  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:51:56.573997  1665 net.cpp:137] Memory required for data: 2734687232
I0405 19:51:56.574081  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:51:56.574139  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:51:56.574193  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 19:51:56.574247  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:51:56.574331  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:51:56.574409  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:51:56.574479  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:51:56.574535  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 19:51:56.574592  1665 net.cpp:137] Memory required for data: 2768241664
I0405 19:51:56.574664  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 19:51:56.574750  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 19:51:56.574821  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:51:56.574888  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 19:51:56.590335  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 19:51:56.590447  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:51:56.590509  1665 net.cpp:137] Memory required for data: 2776630272
I0405 19:51:56.590567  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 19:51:56.590631  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 19:51:56.590689  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 19:51:56.590788  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 19:51:56.591033  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 19:51:56.591130  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:51:56.591187  1665 net.cpp:137] Memory required for data: 2785018880
I0405 19:51:56.591248  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:51:56.591311  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 19:51:56.591372  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 19:51:56.591436  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 19:51:56.591531  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:51:56.591686  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 19:51:56.591794  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:51:56.591851  1665 net.cpp:137] Memory required for data: 2793407488
I0405 19:51:56.591912  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 19:51:56.591972  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 19:51:56.592038  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 19:51:56.592123  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 19:51:56.592190  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 19:51:56.592252  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:51:56.592499  1665 net.cpp:137] Memory required for data: 2801796096
I0405 19:51:56.592561  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 19:51:56.592629  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 19:51:56.592687  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 19:51:56.592756  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 19:51:56.620605  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 19:51:56.620730  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:51:56.620837  1665 net.cpp:137] Memory required for data: 2810184704
I0405 19:51:56.620923  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 19:51:56.621001  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 19:51:56.621067  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:51:56.621134  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 19:51:56.622545  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 19:51:56.622649  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:51:56.622730  1665 net.cpp:137] Memory required for data: 2818573312
I0405 19:51:56.622798  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 19:51:56.622866  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 19:51:56.622946  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 19:51:56.623016  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 19:51:56.623082  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 19:51:56.623173  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 19:51:56.623244  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:51:56.623306  1665 net.cpp:137] Memory required for data: 2826961920
I0405 19:51:56.623368  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 19:51:56.623435  1665 net.cpp:84] Creating Layer last_bn
I0405 19:51:56.623503  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 19:51:56.623565  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 19:51:56.623816  1665 net.cpp:122] Setting up last_bn
I0405 19:51:56.623914  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:51:56.623978  1665 net.cpp:137] Memory required for data: 2835350528
I0405 19:51:56.624040  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:51:56.624107  1665 net.cpp:84] Creating Layer last_scale
I0405 19:51:56.624171  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 19:51:56.624235  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 19:51:56.624339  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:51:56.624503  1665 net.cpp:122] Setting up last_scale
I0405 19:51:56.624586  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:51:56.624650  1665 net.cpp:137] Memory required for data: 2843739136
I0405 19:51:56.624738  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 19:51:56.624814  1665 net.cpp:84] Creating Layer last_relu
I0405 19:51:56.624878  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 19:51:56.624941  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 19:51:56.625012  1665 net.cpp:122] Setting up last_relu
I0405 19:51:56.625077  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 19:51:56.625139  1665 net.cpp:137] Memory required for data: 2852127744
I0405 19:51:56.625201  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 19:51:56.625274  1665 net.cpp:84] Creating Layer global_pool
I0405 19:51:56.625329  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 19:51:56.625392  1665 net.cpp:380] global_pool -> global_pool
I0405 19:51:56.625488  1665 net.cpp:122] Setting up global_pool
I0405 19:51:56.625566  1665 net.cpp:129] Top shape: 256 512 1 1 (131072)
I0405 19:51:56.625629  1665 net.cpp:137] Memory required for data: 2852652032
I0405 19:51:56.625691  1665 layer_factory.hpp:77] Creating layer score
I0405 19:51:56.625777  1665 net.cpp:84] Creating Layer score
I0405 19:51:56.625839  1665 net.cpp:406] score <- global_pool
I0405 19:51:56.625910  1665 net.cpp:380] score -> score
I0405 19:51:56.627369  1665 net.cpp:122] Setting up score
I0405 19:51:56.627501  1665 net.cpp:129] Top shape: 256 1000 (256000)
I0405 19:51:56.627571  1665 net.cpp:137] Memory required for data: 2853676032
I0405 19:51:56.627650  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:51:56.627743  1665 net.cpp:84] Creating Layer loss
I0405 19:51:56.627815  1665 net.cpp:406] loss <- score
I0405 19:51:56.627887  1665 net.cpp:406] loss <- label
I0405 19:51:56.627951  1665 net.cpp:380] loss -> loss
I0405 19:51:56.628012  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:51:56.629281  1665 net.cpp:122] Setting up loss
I0405 19:51:56.629381  1665 net.cpp:129] Top shape: (1)
I0405 19:51:56.629447  1665 net.cpp:132]     with loss weight 1
I0405 19:51:56.629516  1665 net.cpp:137] Memory required for data: 2853676036
I0405 19:51:56.629573  1665 net.cpp:198] loss needs backward computation.
I0405 19:51:56.629631  1665 net.cpp:198] score needs backward computation.
I0405 19:51:56.629689  1665 net.cpp:198] global_pool needs backward computation.
I0405 19:51:56.629748  1665 net.cpp:198] last_relu needs backward computation.
I0405 19:51:56.629804  1665 net.cpp:198] last_scale needs backward computation.
I0405 19:51:56.629860  1665 net.cpp:198] last_bn needs backward computation.
I0405 19:51:56.629915  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 19:51:56.629982  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 19:51:56.630036  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 19:51:56.630092  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 19:51:56.630182  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 19:51:56.630244  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 19:51:56.630298  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 19:51:56.630355  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 19:51:56.630411  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 19:51:56.630472  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 19:51:56.630527  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 19:51:56.630584  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 19:51:56.630640  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 19:51:56.630697  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 19:51:56.630774  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 19:51:56.630828  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 19:51:56.630885  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 19:51:56.630944  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 19:51:56.631008  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 19:51:56.631068  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 19:51:56.631124  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 19:51:56.631179  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 19:51:56.631233  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 19:51:56.631289  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 19:51:56.631345  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 19:51:56.631402  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 19:51:56.631461  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 19:51:56.631525  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 19:51:56.631580  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 19:51:56.631637  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 19:51:56.631700  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 19:51:56.631779  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 19:51:56.631836  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 19:51:56.631893  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 19:51:56.631954  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 19:51:56.632010  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 19:51:56.632077  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 19:51:56.632133  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 19:51:56.632189  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 19:51:56.632244  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 19:51:56.632310  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 19:51:56.632367  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 19:51:56.632423  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 19:51:56.632493  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 19:51:56.632553  1665 net.cpp:198] conv1 needs backward computation.
I0405 19:51:56.632609  1665 net.cpp:198] data_scale needs backward computation.
I0405 19:51:56.632665  1665 net.cpp:200] data_bn does not need backward computation.
I0405 19:51:56.632740  1665 net.cpp:200] data does not need backward computation.
I0405 19:51:56.632798  1665 net.cpp:242] This network produces output loss
I0405 19:51:56.632885  1665 net.cpp:255] Network initialization done.
I0405 19:51:56.634430  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:51:56.634604  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 19:51:56.634681  1665 solver.cpp:172] Creating test net (#0) specified by net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 19:51:56.634874  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 19:51:56.635278  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 19:51:56.635594  1665 layer_factory.hpp:77] Creating layer data
I0405 19:51:56.635684  1665 net.cpp:84] Creating Layer data
I0405 19:51:56.635776  1665 net.cpp:380] data -> data
I0405 19:51:56.635860  1665 net.cpp:380] data -> label
I0405 19:51:56.635944  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 19:51:56.643257  1665 image_data_layer.cpp:53] Shuffling data
I0405 19:51:56.644558  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 19:51:56.645457  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 19:51:56.692569  1665 net.cpp:122] Setting up data
I0405 19:51:56.692767  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:51:56.692855  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:51:56.692930  1665 net.cpp:137] Memory required for data: 19661200
I0405 19:51:56.693002  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 19:51:56.693114  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 19:51:56.693214  1665 net.cpp:406] label_data_1_split <- label
I0405 19:51:56.693301  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 19:51:56.693387  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 19:51:56.693531  1665 net.cpp:122] Setting up label_data_1_split
I0405 19:51:56.693622  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:51:56.693693  1665 net.cpp:129] Top shape: 100 (100)
I0405 19:51:56.693785  1665 net.cpp:137] Memory required for data: 19662000
I0405 19:51:56.693856  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 19:51:56.694003  1665 net.cpp:84] Creating Layer data_bn
I0405 19:51:56.694077  1665 net.cpp:406] data_bn <- data
I0405 19:51:56.694152  1665 net.cpp:380] data_bn -> data_bn
I0405 19:51:56.695884  1665 net.cpp:122] Setting up data_bn
I0405 19:51:56.696028  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:51:56.696105  1665 net.cpp:137] Memory required for data: 39322800
I0405 19:51:56.696185  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:51:56.696300  1665 net.cpp:84] Creating Layer data_scale
I0405 19:51:56.696386  1665 net.cpp:406] data_scale <- data_bn
I0405 19:51:56.696466  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 19:51:56.696594  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 19:51:56.696861  1665 net.cpp:122] Setting up data_scale
I0405 19:51:56.696985  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 19:51:56.697057  1665 net.cpp:137] Memory required for data: 58983600
I0405 19:51:56.697130  1665 layer_factory.hpp:77] Creating layer conv1
I0405 19:51:56.697209  1665 net.cpp:84] Creating Layer conv1
I0405 19:51:56.697302  1665 net.cpp:406] conv1 <- data_bn
I0405 19:51:56.697376  1665 net.cpp:380] conv1 -> conv1
I0405 19:51:56.697844  1665 net.cpp:122] Setting up conv1
I0405 19:51:56.697955  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:51:56.698027  1665 net.cpp:137] Memory required for data: 163841200
I0405 19:51:56.698099  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 19:51:56.698173  1665 net.cpp:84] Creating Layer conv1_bn
I0405 19:51:56.698241  1665 net.cpp:406] conv1_bn <- conv1
I0405 19:51:56.698312  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 19:51:56.698590  1665 net.cpp:122] Setting up conv1_bn
I0405 19:51:56.698676  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:51:56.698781  1665 net.cpp:137] Memory required for data: 268698800
I0405 19:51:56.698894  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:51:56.698985  1665 net.cpp:84] Creating Layer conv1_scale
I0405 19:51:56.699051  1665 net.cpp:406] conv1_scale <- conv1
I0405 19:51:56.699123  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 19:51:56.699247  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 19:51:56.699457  1665 net.cpp:122] Setting up conv1_scale
I0405 19:51:56.699579  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:51:56.699651  1665 net.cpp:137] Memory required for data: 373556400
I0405 19:51:56.699764  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 19:51:56.699836  1665 net.cpp:84] Creating Layer conv1_relu
I0405 19:51:56.699911  1665 net.cpp:406] conv1_relu <- conv1
I0405 19:51:56.700002  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 19:51:56.700098  1665 net.cpp:122] Setting up conv1_relu
I0405 19:51:56.700175  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 19:51:56.700246  1665 net.cpp:137] Memory required for data: 478414000
I0405 19:51:56.700316  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 19:51:56.700392  1665 net.cpp:84] Creating Layer conv1_pool
I0405 19:51:56.700594  1665 net.cpp:406] conv1_pool <- conv1
I0405 19:51:56.700700  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 19:51:56.700863  1665 net.cpp:122] Setting up conv1_pool
I0405 19:51:56.700943  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:56.701009  1665 net.cpp:137] Memory required for data: 504628400
I0405 19:51:56.701077  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 19:51:56.701159  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 19:51:56.701228  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 19:51:56.701289  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 19:51:56.701357  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 19:51:56.701457  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 19:51:56.701530  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:56.701598  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:56.701663  1665 net.cpp:137] Memory required for data: 557057200
I0405 19:51:56.701745  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 19:51:56.701818  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 19:51:56.701882  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 19:51:56.701968  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 19:51:56.702567  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 19:51:56.702669  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:56.702756  1665 net.cpp:137] Memory required for data: 583271600
I0405 19:51:56.702847  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 19:51:56.702926  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 19:51:56.702992  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 19:51:56.703053  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 19:51:56.703326  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 19:51:56.703409  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:56.703476  1665 net.cpp:137] Memory required for data: 609486000
I0405 19:51:56.703549  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:51:56.703608  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 19:51:56.703667  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 19:51:56.703748  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 19:51:56.703862  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 19:51:56.704066  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 19:51:56.704140  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:56.704205  1665 net.cpp:137] Memory required for data: 635700400
I0405 19:51:56.704272  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 19:51:56.704352  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 19:51:56.704447  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 19:51:56.704514  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 19:51:56.704579  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 19:51:56.704645  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:56.704725  1665 net.cpp:137] Memory required for data: 661914800
I0405 19:51:56.704810  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 19:51:56.704875  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 19:51:56.704941  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 19:51:56.705009  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 19:51:56.705596  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 19:51:56.705696  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:56.705781  1665 net.cpp:137] Memory required for data: 688129200
I0405 19:51:56.705864  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 19:51:56.705922  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 19:51:56.706022  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 19:51:56.706092  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 19:51:56.706162  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 19:51:56.706259  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 19:51:56.706323  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:56.706393  1665 net.cpp:137] Memory required for data: 714343600
I0405 19:51:56.706471  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 19:51:56.706571  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 19:51:56.706655  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 19:51:56.706750  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 19:51:56.707023  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 19:51:56.707121  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:56.707201  1665 net.cpp:137] Memory required for data: 740558000
I0405 19:51:56.707283  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:51:56.707355  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 19:51:56.707424  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 19:51:56.707504  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 19:51:56.707617  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 19:51:56.707859  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 19:51:56.707944  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:56.708000  1665 net.cpp:137] Memory required for data: 766772400
I0405 19:51:56.708070  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 19:51:56.708137  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 19:51:56.708201  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 19:51:56.708266  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 19:51:56.708338  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 19:51:56.708412  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:56.708467  1665 net.cpp:137] Memory required for data: 792986800
I0405 19:51:56.708530  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:51:56.708596  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:51:56.708678  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 19:51:56.708763  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:51:56.708832  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:51:56.708927  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 19:51:56.709024  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:56.709084  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 19:51:56.709147  1665 net.cpp:137] Memory required for data: 845415600
I0405 19:51:56.709229  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 19:51:56.709298  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 19:51:56.709362  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 19:51:56.709442  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 19:51:56.710394  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 19:51:56.710494  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:56.710559  1665 net.cpp:137] Memory required for data: 858522800
I0405 19:51:56.710628  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 19:51:56.710696  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 19:51:56.710777  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 19:51:56.710844  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 19:51:56.711057  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 19:51:56.711163  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:56.711222  1665 net.cpp:137] Memory required for data: 871630000
I0405 19:51:56.711287  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:51:56.711352  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 19:51:56.711412  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 19:51:56.711483  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 19:51:56.711583  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 19:51:56.711757  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 19:51:56.711844  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:56.711923  1665 net.cpp:137] Memory required for data: 884737200
I0405 19:51:56.711992  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 19:51:56.712054  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 19:51:56.712112  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 19:51:56.712184  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 19:51:56.712257  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 19:51:56.712313  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:56.712373  1665 net.cpp:137] Memory required for data: 897844400
I0405 19:51:56.712430  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 19:51:56.712500  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 19:51:56.712554  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 19:51:56.712616  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 19:51:56.714211  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 19:51:56.714313  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:56.714377  1665 net.cpp:137] Memory required for data: 910951600
I0405 19:51:56.714449  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 19:51:56.714519  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 19:51:56.714582  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 19:51:56.714648  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 19:51:56.714987  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 19:51:56.715085  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:56.715147  1665 net.cpp:137] Memory required for data: 924058800
I0405 19:51:56.715214  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 19:51:56.715279  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 19:51:56.715340  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 19:51:56.715399  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 19:51:56.715466  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 19:51:56.715548  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 19:51:56.715612  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:56.715672  1665 net.cpp:137] Memory required for data: 937166000
I0405 19:51:56.715751  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 19:51:56.715829  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 19:51:56.715895  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 19:51:56.715983  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 19:51:56.716248  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 19:51:56.716331  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:56.716395  1665 net.cpp:137] Memory required for data: 950273200
I0405 19:51:56.716472  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:51:56.716542  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 19:51:56.716763  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 19:51:56.717360  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 19:51:56.717747  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 19:51:56.717952  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 19:51:56.718051  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:56.718107  1665 net.cpp:137] Memory required for data: 963380400
I0405 19:51:56.718163  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 19:51:56.718220  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 19:51:56.718276  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 19:51:56.718329  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 19:51:56.718423  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 19:51:56.720614  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:56.720930  1665 net.cpp:137] Memory required for data: 976487600
I0405 19:51:56.721011  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:51:56.721822  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:51:56.722085  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 19:51:56.722178  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:51:56.722846  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:51:56.722990  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 19:51:56.723071  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:56.723130  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 19:51:56.723187  1665 net.cpp:137] Memory required for data: 1002702000
I0405 19:51:56.723244  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 19:51:56.723312  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 19:51:56.723387  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 19:51:56.723459  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 19:51:56.728551  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 19:51:56.729622  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:56.729692  1665 net.cpp:137] Memory required for data: 1009255600
I0405 19:51:56.730474  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 19:51:56.730953  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 19:51:56.731698  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 19:51:56.732007  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 19:51:56.732313  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 19:51:56.732403  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:56.732470  1665 net.cpp:137] Memory required for data: 1015809200
I0405 19:51:56.732532  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:51:56.732591  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 19:51:56.732656  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 19:51:56.732728  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 19:51:56.732828  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 19:51:56.733803  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 19:51:56.733886  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:56.733934  1665 net.cpp:137] Memory required for data: 1022362800
I0405 19:51:56.733991  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 19:51:56.734205  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 19:51:56.734308  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 19:51:56.734894  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 19:51:56.735349  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 19:51:56.735450  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:56.735507  1665 net.cpp:137] Memory required for data: 1028916400
I0405 19:51:56.735574  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 19:51:56.735641  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 19:51:56.735698  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 19:51:56.735780  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 19:51:56.744307  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 19:51:56.744406  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:56.744477  1665 net.cpp:137] Memory required for data: 1035470000
I0405 19:51:56.744544  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 19:51:56.744623  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 19:51:56.744695  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 19:51:56.744783  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 19:51:56.745448  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 19:51:56.745550  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:56.745616  1665 net.cpp:137] Memory required for data: 1042023600
I0405 19:51:56.745682  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 19:51:56.745762  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 19:51:56.745833  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 19:51:56.745903  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 19:51:56.745980  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 19:51:56.746089  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 19:51:56.746160  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:56.746228  1665 net.cpp:137] Memory required for data: 1048577200
I0405 19:51:56.746299  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 19:51:56.746381  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 19:51:56.746462  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 19:51:56.746538  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 19:51:56.746819  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 19:51:56.746898  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:56.746958  1665 net.cpp:137] Memory required for data: 1055130800
I0405 19:51:56.747033  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:51:56.747107  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 19:51:56.747179  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 19:51:56.747254  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 19:51:56.747354  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 19:51:56.747525  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 19:51:56.747601  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:56.747676  1665 net.cpp:137] Memory required for data: 1061684400
I0405 19:51:56.747802  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 19:51:56.747877  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 19:51:56.747938  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 19:51:56.748009  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 19:51:56.748080  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 19:51:56.748142  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:56.748208  1665 net.cpp:137] Memory required for data: 1068238000
I0405 19:51:56.748271  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:51:56.748351  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:51:56.748427  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 19:51:56.748492  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:51:56.748564  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:51:56.748677  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 19:51:56.748765  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:56.748833  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 19:51:56.748901  1665 net.cpp:137] Memory required for data: 1081345200
I0405 19:51:56.748968  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 19:51:56.749043  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 19:51:56.749109  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 19:51:56.749186  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 19:51:56.766073  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 19:51:56.766192  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:56.766263  1665 net.cpp:137] Memory required for data: 1084622000
I0405 19:51:56.766333  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 19:51:56.766402  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 19:51:56.766476  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 19:51:56.766544  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 19:51:56.766813  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 19:51:56.766906  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:56.766989  1665 net.cpp:137] Memory required for data: 1087898800
I0405 19:51:56.767057  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:51:56.767127  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 19:51:56.767195  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 19:51:56.767266  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 19:51:56.767369  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 19:51:56.767560  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 19:51:56.767647  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:56.767730  1665 net.cpp:137] Memory required for data: 1091175600
I0405 19:51:56.767832  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 19:51:56.767906  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 19:51:56.767982  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 19:51:56.768049  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 19:51:56.768112  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 19:51:56.768175  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:56.768242  1665 net.cpp:137] Memory required for data: 1094452400
I0405 19:51:56.768308  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 19:51:56.768379  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 19:51:56.768452  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 19:51:56.768528  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 19:51:56.802356  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 19:51:56.802502  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:56.802582  1665 net.cpp:137] Memory required for data: 1097729200
I0405 19:51:56.802649  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 19:51:56.802740  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 19:51:56.802834  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 19:51:56.802901  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 19:51:56.804778  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 19:51:56.804886  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:56.804961  1665 net.cpp:137] Memory required for data: 1101006000
I0405 19:51:56.805037  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 19:51:56.805112  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 19:51:56.805184  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 19:51:56.805256  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 19:51:56.805331  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 19:51:56.809691  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 19:51:56.809849  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:56.809933  1665 net.cpp:137] Memory required for data: 1104282800
I0405 19:51:56.810010  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 19:51:56.810089  1665 net.cpp:84] Creating Layer last_bn
I0405 19:51:56.810166  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 19:51:56.810242  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 19:51:56.810528  1665 net.cpp:122] Setting up last_bn
I0405 19:51:56.810621  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:56.810688  1665 net.cpp:137] Memory required for data: 1107559600
I0405 19:51:56.810830  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:51:56.810904  1665 net.cpp:84] Creating Layer last_scale
I0405 19:51:56.810987  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 19:51:56.811077  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 19:51:56.811200  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 19:51:56.811393  1665 net.cpp:122] Setting up last_scale
I0405 19:51:56.811482  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:56.811549  1665 net.cpp:137] Memory required for data: 1110836400
I0405 19:51:56.811619  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 19:51:56.811687  1665 net.cpp:84] Creating Layer last_relu
I0405 19:51:56.811782  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 19:51:56.811851  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 19:51:56.811942  1665 net.cpp:122] Setting up last_relu
I0405 19:51:56.812016  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 19:51:56.812098  1665 net.cpp:137] Memory required for data: 1114113200
I0405 19:51:56.812165  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 19:51:56.812255  1665 net.cpp:84] Creating Layer global_pool
I0405 19:51:56.812336  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 19:51:56.812407  1665 net.cpp:380] global_pool -> global_pool
I0405 19:51:56.812510  1665 net.cpp:122] Setting up global_pool
I0405 19:51:56.812587  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 19:51:56.812654  1665 net.cpp:137] Memory required for data: 1114318000
I0405 19:51:56.812723  1665 layer_factory.hpp:77] Creating layer score
I0405 19:51:56.812794  1665 net.cpp:84] Creating Layer score
I0405 19:51:56.812858  1665 net.cpp:406] score <- global_pool
I0405 19:51:56.812924  1665 net.cpp:380] score -> score
I0405 19:51:56.814851  1665 net.cpp:122] Setting up score
I0405 19:51:56.814998  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:51:56.815083  1665 net.cpp:137] Memory required for data: 1114718000
I0405 19:51:56.815165  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 19:51:56.815254  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 19:51:56.815333  1665 net.cpp:406] score_score_0_split <- score
I0405 19:51:56.815403  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 19:51:56.815477  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 19:51:56.815596  1665 net.cpp:122] Setting up score_score_0_split
I0405 19:51:56.815685  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:51:56.815760  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 19:51:56.815830  1665 net.cpp:137] Memory required for data: 1115518000
I0405 19:51:56.815901  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:51:56.816076  1665 net.cpp:84] Creating Layer loss
I0405 19:51:56.816203  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 19:51:56.816948  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 19:51:56.817090  1665 net.cpp:380] loss -> loss
I0405 19:51:56.817210  1665 layer_factory.hpp:77] Creating layer loss
I0405 19:51:56.818893  1665 net.cpp:122] Setting up loss
I0405 19:51:56.819072  1665 net.cpp:129] Top shape: (1)
I0405 19:51:56.819154  1665 net.cpp:132]     with loss weight 1
I0405 19:51:56.819243  1665 net.cpp:137] Memory required for data: 1115518004
I0405 19:51:56.819331  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 19:51:56.819422  1665 net.cpp:84] Creating Layer accuracy
I0405 19:51:56.819533  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 19:51:56.819615  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 19:51:56.819697  1665 net.cpp:380] accuracy -> accuracy
I0405 19:51:56.819823  1665 net.cpp:122] Setting up accuracy
I0405 19:51:56.819917  1665 net.cpp:129] Top shape: (1)
I0405 19:51:56.819996  1665 net.cpp:137] Memory required for data: 1115518008
I0405 19:51:56.820073  1665 net.cpp:200] accuracy does not need backward computation.
I0405 19:51:56.820152  1665 net.cpp:198] loss needs backward computation.
I0405 19:51:56.820231  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 19:51:56.820312  1665 net.cpp:198] score needs backward computation.
I0405 19:51:56.820403  1665 net.cpp:198] global_pool needs backward computation.
I0405 19:51:56.820482  1665 net.cpp:198] last_relu needs backward computation.
I0405 19:51:56.820557  1665 net.cpp:198] last_scale needs backward computation.
I0405 19:51:56.820637  1665 net.cpp:198] last_bn needs backward computation.
I0405 19:51:56.820763  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 19:51:56.820843  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 19:51:56.820931  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 19:51:56.821017  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 19:51:56.821090  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 19:51:56.821166  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 19:51:56.821246  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 19:51:56.821326  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 19:51:56.821411  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 19:51:56.821491  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 19:51:56.821570  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 19:51:56.821662  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 19:51:56.821755  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 19:51:56.821836  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 19:51:56.821923  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 19:51:56.822016  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 19:51:56.822090  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 19:51:56.822170  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 19:51:56.822264  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 19:51:56.822338  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 19:51:56.822418  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 19:51:56.822499  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 19:51:56.822577  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 19:51:56.822657  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 19:51:56.822760  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 19:51:56.822840  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 19:51:56.822916  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 19:51:56.822989  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 19:51:56.823067  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 19:51:56.823160  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 19:51:56.823235  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 19:51:56.823314  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 19:51:56.823391  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 19:51:56.823477  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 19:51:56.823550  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 19:51:56.823627  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 19:51:56.823705  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 19:51:56.823807  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 19:51:56.823894  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 19:51:56.823983  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 19:51:56.824071  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 19:51:56.824158  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 19:51:56.824247  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 19:51:56.824327  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 19:51:56.824430  1665 net.cpp:198] conv1 needs backward computation.
I0405 19:51:56.824509  1665 net.cpp:198] data_scale needs backward computation.
I0405 19:51:56.824599  1665 net.cpp:200] data_bn does not need backward computation.
I0405 19:51:56.824687  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 19:51:56.824798  1665 net.cpp:200] data does not need backward computation.
I0405 19:51:56.824887  1665 net.cpp:242] This network produces output accuracy
I0405 19:51:56.824970  1665 net.cpp:242] This network produces output loss
I0405 19:51:56.825112  1665 net.cpp:255] Network initialization done.
I0405 19:51:56.825520  1665 solver.cpp:56] Solver scaffolding done.
I0405 19:51:56.865694  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: data/resnet10_cvgj_iter_320000.caffemodel
I0405 19:51:56.865957  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 19:51:57.338831  1665 solver.cpp:218] Iteration 0 (1.61368e-09 iter/s, 0.467977s/225 iters), loss = 13.2266
I0405 19:51:57.339085  1665 solver.cpp:237]     Train net output #0: loss = 13.2266 (* 1 = 13.2266 loss)
I0405 19:51:57.339198  1665 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I0405 19:53:35.864933  1665 solver.cpp:218] Iteration 225 (2.28366 iter/s, 98.5259s/225 iters), loss = 0.528313
I0405 19:53:35.865324  1665 solver.cpp:237]     Train net output #0: loss = 0.528313 (* 1 = 0.528313 loss)
I0405 19:53:35.865407  1665 sgd_solver.cpp:105] Iteration 225, lr = 0.000875
I0405 19:55:14.386520  1665 solver.cpp:218] Iteration 450 (2.28377 iter/s, 98.5215s/225 iters), loss = 0.28105
I0405 19:55:14.386909  1665 solver.cpp:237]     Train net output #0: loss = 0.28105 (* 1 = 0.28105 loss)
I0405 19:55:14.387002  1665 sgd_solver.cpp:105] Iteration 450, lr = 0.00075
I0405 19:55:22.270144  1665 solver.cpp:330] Iteration 469, Testing net (#0)
I0405 19:56:52.908007  1665 solver.cpp:218] Iteration 675 (2.28376 iter/s, 98.5216s/225 iters), loss = 0.222298
I0405 19:56:52.908366  1665 solver.cpp:237]     Train net output #0: loss = 0.222298 (* 1 = 0.222298 loss)
I0405 19:56:52.908449  1665 sgd_solver.cpp:105] Iteration 675, lr = 0.000625
I0405 19:58:31.429350  1665 solver.cpp:218] Iteration 900 (2.28376 iter/s, 98.5217s/225 iters), loss = 0.219864
I0405 19:58:31.429612  1665 solver.cpp:237]     Train net output #0: loss = 0.219864 (* 1 = 0.219864 loss)
I0405 19:58:31.429684  1665 sgd_solver.cpp:105] Iteration 900, lr = 0.0005
I0405 19:58:47.632284  1665 solver.cpp:330] Iteration 938, Testing net (#0)
I0405 20:00:09.953037  1665 solver.cpp:218] Iteration 1125 (2.2837 iter/s, 98.5242s/225 iters), loss = 0.185011
I0405 20:00:09.953351  1665 solver.cpp:237]     Train net output #0: loss = 0.185011 (* 1 = 0.185011 loss)
I0405 20:00:09.953428  1665 sgd_solver.cpp:105] Iteration 1125, lr = 0.000375
I0405 20:01:48.486140  1665 solver.cpp:218] Iteration 1350 (2.28348 iter/s, 98.5337s/225 iters), loss = 0.140884
I0405 20:01:48.486459  1665 solver.cpp:237]     Train net output #0: loss = 0.140884 (* 1 = 0.140884 loss)
I0405 20:01:48.486541  1665 sgd_solver.cpp:105] Iteration 1350, lr = 0.00025
I0405 20:02:13.014457  1665 solver.cpp:330] Iteration 1407, Testing net (#0)
I0405 20:03:27.023615  1665 solver.cpp:218] Iteration 1575 (2.28338 iter/s, 98.5382s/225 iters), loss = 0.0807946
I0405 20:03:27.023921  1665 solver.cpp:237]     Train net output #0: loss = 0.0807946 (* 1 = 0.0807946 loss)
I0405 20:03:27.024019  1665 sgd_solver.cpp:105] Iteration 1575, lr = 0.000125
I0405 20:05:05.108803  1665 solver.cpp:457] Snapshotting to HDF5 file data/snapshots/train_batch_05_iter_1800.caffemodel.h5
I0405 20:05:05.182876  1665 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file data/snapshots/train_batch_05_iter_1800.solverstate.h5
W0405 20:05:07.497633  1665 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W0405 20:05:07.497961  1665 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W0405 20:05:07.498062  1665 _caffe.cpp:142] Net('confs/sII/mid-caffeNet/inc_train_val.prototxt', 1, weights='data/snapshots/train_batch_05_iter_1800.caffemodel.h5')
I0405 20:05:07.501744  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 20:05:07.501888  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 20:05:07.502017  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 20:05:07.502333  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 20:05:07.502635  1665 layer_factory.hpp:77] Creating layer data
I0405 20:05:07.502745  1665 net.cpp:84] Creating Layer data
I0405 20:05:07.502846  1665 net.cpp:380] data -> data
I0405 20:05:07.502893  1665 net.cpp:380] data -> label
I0405 20:05:07.502939  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 20:05:07.510649  1665 image_data_layer.cpp:53] Shuffling data
I0405 20:05:07.511835  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 20:05:07.512859  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 20:05:07.559701  1665 net.cpp:122] Setting up data
I0405 20:05:07.560035  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:05:07.560102  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:05:07.560158  1665 net.cpp:137] Memory required for data: 19661200
I0405 20:05:07.560223  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 20:05:07.560288  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 20:05:07.560348  1665 net.cpp:406] label_data_1_split <- label
I0405 20:05:07.560408  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 20:05:07.560472  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 20:05:07.560568  1665 net.cpp:122] Setting up label_data_1_split
I0405 20:05:07.560662  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:05:07.560788  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:05:07.560847  1665 net.cpp:137] Memory required for data: 19662000
I0405 20:05:07.560930  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 20:05:07.560988  1665 net.cpp:84] Creating Layer data_bn
I0405 20:05:07.561046  1665 net.cpp:406] data_bn <- data
I0405 20:05:07.561105  1665 net.cpp:380] data_bn -> data_bn
I0405 20:05:07.561327  1665 net.cpp:122] Setting up data_bn
I0405 20:05:07.561431  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:05:07.561491  1665 net.cpp:137] Memory required for data: 39322800
I0405 20:05:07.561555  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:05:07.561637  1665 net.cpp:84] Creating Layer data_scale
I0405 20:05:07.561709  1665 net.cpp:406] data_scale <- data_bn
I0405 20:05:07.561789  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 20:05:07.563877  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:05:07.564165  1665 net.cpp:122] Setting up data_scale
I0405 20:05:07.564288  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:05:07.564348  1665 net.cpp:137] Memory required for data: 58983600
I0405 20:05:07.564410  1665 layer_factory.hpp:77] Creating layer conv1
I0405 20:05:07.564473  1665 net.cpp:84] Creating Layer conv1
I0405 20:05:07.564534  1665 net.cpp:406] conv1 <- data_bn
I0405 20:05:07.564594  1665 net.cpp:380] conv1 -> conv1
I0405 20:05:07.564922  1665 net.cpp:122] Setting up conv1
I0405 20:05:07.565027  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:05:07.565088  1665 net.cpp:137] Memory required for data: 163841200
I0405 20:05:07.565155  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 20:05:07.565218  1665 net.cpp:84] Creating Layer conv1_bn
I0405 20:05:07.565277  1665 net.cpp:406] conv1_bn <- conv1
I0405 20:05:07.565335  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 20:05:07.565524  1665 net.cpp:122] Setting up conv1_bn
I0405 20:05:07.565687  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:05:07.565793  1665 net.cpp:137] Memory required for data: 268698800
I0405 20:05:07.565860  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:05:07.565919  1665 net.cpp:84] Creating Layer conv1_scale
I0405 20:05:07.565975  1665 net.cpp:406] conv1_scale <- conv1
I0405 20:05:07.566032  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 20:05:07.566134  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:05:07.566273  1665 net.cpp:122] Setting up conv1_scale
I0405 20:05:07.566370  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:05:07.566427  1665 net.cpp:137] Memory required for data: 373556400
I0405 20:05:07.566488  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 20:05:07.566548  1665 net.cpp:84] Creating Layer conv1_relu
I0405 20:05:07.566607  1665 net.cpp:406] conv1_relu <- conv1
I0405 20:05:07.566665  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 20:05:07.566735  1665 net.cpp:122] Setting up conv1_relu
I0405 20:05:07.566799  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:05:07.566855  1665 net.cpp:137] Memory required for data: 478414000
I0405 20:05:07.566926  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 20:05:07.566994  1665 net.cpp:84] Creating Layer conv1_pool
I0405 20:05:07.567049  1665 net.cpp:406] conv1_pool <- conv1
I0405 20:05:07.567107  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 20:05:07.567206  1665 net.cpp:122] Setting up conv1_pool
I0405 20:05:07.567273  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:07.567330  1665 net.cpp:137] Memory required for data: 504628400
I0405 20:05:07.567387  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 20:05:07.567447  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 20:05:07.567505  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 20:05:07.567564  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 20:05:07.567622  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 20:05:07.567706  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 20:05:07.567790  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:07.567847  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:07.567903  1665 net.cpp:137] Memory required for data: 557057200
I0405 20:05:07.567957  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 20:05:07.568032  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 20:05:07.568092  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 20:05:07.568152  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 20:05:07.568606  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 20:05:07.568722  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:07.568810  1665 net.cpp:137] Memory required for data: 583271600
I0405 20:05:07.568873  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 20:05:07.568935  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 20:05:07.568994  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 20:05:07.569051  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 20:05:07.569236  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 20:05:07.569337  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:07.569402  1665 net.cpp:137] Memory required for data: 609486000
I0405 20:05:07.569463  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:05:07.569521  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 20:05:07.569578  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 20:05:07.569643  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 20:05:07.569751  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:05:07.569896  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 20:05:07.569994  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:07.570052  1665 net.cpp:137] Memory required for data: 635700400
I0405 20:05:07.570113  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 20:05:07.570222  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 20:05:07.570283  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 20:05:07.570343  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 20:05:07.570402  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 20:05:07.570461  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:07.570528  1665 net.cpp:137] Memory required for data: 661914800
I0405 20:05:07.570587  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 20:05:07.570649  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 20:05:07.570705  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 20:05:07.570788  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 20:05:07.571251  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 20:05:07.571355  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:07.571456  1665 net.cpp:137] Memory required for data: 688129200
I0405 20:05:07.571527  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 20:05:07.571586  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 20:05:07.571647  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 20:05:07.571704  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 20:05:07.571796  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 20:05:07.571864  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 20:05:07.571934  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:07.572002  1665 net.cpp:137] Memory required for data: 714343600
I0405 20:05:07.572109  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 20:05:07.572170  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 20:05:07.572228  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 20:05:07.572288  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 20:05:07.572489  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 20:05:07.572590  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:07.572649  1665 net.cpp:137] Memory required for data: 740558000
I0405 20:05:07.572710  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:05:07.572804  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 20:05:07.572860  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 20:05:07.572928  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 20:05:07.573012  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:05:07.573137  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 20:05:07.573225  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:07.573283  1665 net.cpp:137] Memory required for data: 766772400
I0405 20:05:07.573341  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 20:05:07.573401  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 20:05:07.573482  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 20:05:07.573565  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 20:05:07.573639  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 20:05:07.573706  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:07.573812  1665 net.cpp:137] Memory required for data: 792986800
I0405 20:05:07.573879  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:05:07.573946  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:05:07.574012  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 20:05:07.574090  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:05:07.574159  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:05:07.574260  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:05:07.574331  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:07.574399  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:07.574467  1665 net.cpp:137] Memory required for data: 845415600
I0405 20:05:07.574539  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 20:05:07.574607  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 20:05:07.574676  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:05:07.574775  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 20:05:07.575557  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 20:05:07.575672  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:07.575753  1665 net.cpp:137] Memory required for data: 858522800
I0405 20:05:07.575827  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 20:05:07.575888  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 20:05:07.575947  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 20:05:07.576026  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 20:05:07.576206  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 20:05:07.576280  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:07.576357  1665 net.cpp:137] Memory required for data: 871630000
I0405 20:05:07.576416  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:05:07.576476  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 20:05:07.576542  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 20:05:07.576601  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 20:05:07.576685  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:05:07.576829  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 20:05:07.576930  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:07.576988  1665 net.cpp:137] Memory required for data: 884737200
I0405 20:05:07.577047  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 20:05:07.577108  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 20:05:07.577167  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 20:05:07.577224  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 20:05:07.577284  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 20:05:07.577342  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:07.577420  1665 net.cpp:137] Memory required for data: 897844400
I0405 20:05:07.577481  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 20:05:07.577540  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 20:05:07.577596  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 20:05:07.577664  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 20:05:07.579001  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 20:05:07.579121  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:07.579232  1665 net.cpp:137] Memory required for data: 910951600
I0405 20:05:07.579295  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 20:05:07.579357  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 20:05:07.579414  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:05:07.579473  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 20:05:07.579731  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 20:05:07.579847  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:07.579907  1665 net.cpp:137] Memory required for data: 924058800
I0405 20:05:07.579967  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 20:05:07.580026  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 20:05:07.580085  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 20:05:07.580143  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 20:05:07.580209  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 20:05:07.580296  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 20:05:07.580355  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:07.580412  1665 net.cpp:137] Memory required for data: 937166000
I0405 20:05:07.580467  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 20:05:07.580538  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 20:05:07.580600  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 20:05:07.580658  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 20:05:07.580860  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 20:05:07.580965  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:07.581037  1665 net.cpp:137] Memory required for data: 950273200
I0405 20:05:07.581096  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:05:07.581156  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 20:05:07.581212  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 20:05:07.581279  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 20:05:07.581360  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:05:07.581477  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 20:05:07.581569  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:07.581632  1665 net.cpp:137] Memory required for data: 963380400
I0405 20:05:07.581692  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 20:05:07.581777  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 20:05:07.581835  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 20:05:07.581894  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 20:05:07.581964  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 20:05:07.582023  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:07.582079  1665 net.cpp:137] Memory required for data: 976487600
I0405 20:05:07.582135  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:05:07.582195  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:05:07.582259  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 20:05:07.582326  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:05:07.582384  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:05:07.582459  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:05:07.582518  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:07.582577  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:07.582634  1665 net.cpp:137] Memory required for data: 1002702000
I0405 20:05:07.582691  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 20:05:07.582787  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 20:05:07.582846  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:05:07.582916  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 20:05:07.586279  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 20:05:07.586362  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:07.586421  1665 net.cpp:137] Memory required for data: 1009255600
I0405 20:05:07.586477  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 20:05:07.586539  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 20:05:07.586598  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 20:05:07.586657  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 20:05:07.586855  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 20:05:07.586949  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:07.587018  1665 net.cpp:137] Memory required for data: 1015809200
I0405 20:05:07.587080  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:05:07.587138  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 20:05:07.587193  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 20:05:07.587246  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 20:05:07.587349  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:05:07.587471  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 20:05:07.587560  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:07.587620  1665 net.cpp:137] Memory required for data: 1022362800
I0405 20:05:07.587675  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 20:05:07.587747  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 20:05:07.587805  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 20:05:07.587863  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 20:05:07.587921  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 20:05:07.587977  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:07.588032  1665 net.cpp:137] Memory required for data: 1028916400
I0405 20:05:07.588100  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 20:05:07.588157  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 20:05:07.588212  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 20:05:07.588265  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 20:05:07.594063  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 20:05:07.594195  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:07.594311  1665 net.cpp:137] Memory required for data: 1035470000
I0405 20:05:07.594377  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 20:05:07.594449  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 20:05:07.594521  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:05:07.594586  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 20:05:07.595116  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 20:05:07.595228  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:07.595290  1665 net.cpp:137] Memory required for data: 1042023600
I0405 20:05:07.595353  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 20:05:07.595466  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 20:05:07.595530  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 20:05:07.595592  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 20:05:07.595669  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 20:05:07.595892  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 20:05:07.596069  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:07.596139  1665 net.cpp:137] Memory required for data: 1048577200
I0405 20:05:07.596192  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 20:05:07.596252  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 20:05:07.596308  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 20:05:07.596365  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 20:05:07.596645  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 20:05:07.596774  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:07.596828  1665 net.cpp:137] Memory required for data: 1055130800
I0405 20:05:07.596885  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:05:07.596972  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 20:05:07.597028  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 20:05:07.597082  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 20:05:07.597175  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:05:07.597344  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 20:05:07.597432  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:07.597486  1665 net.cpp:137] Memory required for data: 1061684400
I0405 20:05:07.597543  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 20:05:07.597597  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 20:05:07.597649  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 20:05:07.597728  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 20:05:07.597856  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 20:05:07.597913  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:07.598062  1665 net.cpp:137] Memory required for data: 1068238000
I0405 20:05:07.598160  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:05:07.598209  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:05:07.598273  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 20:05:07.598330  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:05:07.598387  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:05:07.598486  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:05:07.598578  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:07.598634  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:07.598688  1665 net.cpp:137] Memory required for data: 1081345200
I0405 20:05:07.598759  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 20:05:07.598824  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 20:05:07.598873  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:05:07.598927  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 20:05:07.616153  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 20:05:07.616274  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:07.616330  1665 net.cpp:137] Memory required for data: 1084622000
I0405 20:05:07.616385  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 20:05:07.616441  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 20:05:07.616494  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 20:05:07.616549  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 20:05:07.616820  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 20:05:07.616883  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:07.616936  1665 net.cpp:137] Memory required for data: 1087898800
I0405 20:05:07.616991  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:05:07.617048  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 20:05:07.617100  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 20:05:07.617156  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 20:05:07.617251  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:05:07.617449  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 20:05:07.617527  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:07.617580  1665 net.cpp:137] Memory required for data: 1091175600
I0405 20:05:07.617635  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 20:05:07.617691  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 20:05:07.617765  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 20:05:07.617831  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 20:05:07.617887  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 20:05:07.617940  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:07.617991  1665 net.cpp:137] Memory required for data: 1094452400
I0405 20:05:07.618043  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 20:05:07.618098  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 20:05:07.618161  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 20:05:07.618217  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 20:05:07.652330  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 20:05:07.652422  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:07.652513  1665 net.cpp:137] Memory required for data: 1097729200
I0405 20:05:07.652570  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 20:05:07.652660  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 20:05:07.652731  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:05:07.652812  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 20:05:07.654950  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 20:05:07.655042  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:07.655135  1665 net.cpp:137] Memory required for data: 1101006000
I0405 20:05:07.655191  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 20:05:07.655253  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 20:05:07.655330  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 20:05:07.655385  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 20:05:07.655439  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 20:05:07.655517  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 20:05:07.655591  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:07.655644  1665 net.cpp:137] Memory required for data: 1104282800
I0405 20:05:07.655697  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 20:05:07.655758  1665 net.cpp:84] Creating Layer last_bn
I0405 20:05:07.655817  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 20:05:07.655867  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 20:05:07.656100  1665 net.cpp:122] Setting up last_bn
I0405 20:05:07.656157  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:07.656657  1665 net.cpp:137] Memory required for data: 1107559600
I0405 20:05:07.656806  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:05:07.656867  1665 net.cpp:84] Creating Layer last_scale
I0405 20:05:07.656920  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 20:05:07.657016  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 20:05:07.657122  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:05:07.657275  1665 net.cpp:122] Setting up last_scale
I0405 20:05:07.657354  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:07.657407  1665 net.cpp:137] Memory required for data: 1110836400
I0405 20:05:07.657462  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 20:05:07.657517  1665 net.cpp:84] Creating Layer last_relu
I0405 20:05:07.657569  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 20:05:07.657624  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 20:05:07.657677  1665 net.cpp:122] Setting up last_relu
I0405 20:05:07.657754  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:07.657816  1665 net.cpp:137] Memory required for data: 1114113200
I0405 20:05:07.657868  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 20:05:07.657936  1665 net.cpp:84] Creating Layer global_pool
I0405 20:05:07.658000  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 20:05:07.658054  1665 net.cpp:380] global_pool -> global_pool
I0405 20:05:07.658134  1665 net.cpp:122] Setting up global_pool
I0405 20:05:07.658190  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 20:05:07.658241  1665 net.cpp:137] Memory required for data: 1114318000
I0405 20:05:07.658294  1665 layer_factory.hpp:77] Creating layer score
I0405 20:05:07.658349  1665 net.cpp:84] Creating Layer score
I0405 20:05:07.658403  1665 net.cpp:406] score <- global_pool
I0405 20:05:07.658457  1665 net.cpp:380] score -> score
I0405 20:05:07.660069  1665 net.cpp:122] Setting up score
I0405 20:05:07.660151  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:05:07.660207  1665 net.cpp:137] Memory required for data: 1114718000
I0405 20:05:07.660267  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 20:05:07.660349  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 20:05:07.660399  1665 net.cpp:406] score_score_0_split <- score
I0405 20:05:07.660449  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 20:05:07.660501  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 20:05:07.660584  1665 net.cpp:122] Setting up score_score_0_split
I0405 20:05:07.660655  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:05:07.660703  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:05:07.660786  1665 net.cpp:137] Memory required for data: 1115518000
I0405 20:05:07.660837  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:05:07.660889  1665 net.cpp:84] Creating Layer loss
I0405 20:05:07.660938  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 20:05:07.660989  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 20:05:07.661048  1665 net.cpp:380] loss -> loss
I0405 20:05:07.661109  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:05:07.662495  1665 net.cpp:122] Setting up loss
I0405 20:05:07.662585  1665 net.cpp:129] Top shape: (1)
I0405 20:05:07.662633  1665 net.cpp:132]     with loss weight 1
I0405 20:05:07.662693  1665 net.cpp:137] Memory required for data: 1115518004
I0405 20:05:07.662760  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 20:05:07.662820  1665 net.cpp:84] Creating Layer accuracy
I0405 20:05:07.662870  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 20:05:07.663009  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 20:05:07.663110  1665 net.cpp:380] accuracy -> accuracy
I0405 20:05:07.663175  1665 net.cpp:122] Setting up accuracy
I0405 20:05:07.663233  1665 net.cpp:129] Top shape: (1)
I0405 20:05:07.663282  1665 net.cpp:137] Memory required for data: 1115518008
I0405 20:05:07.663331  1665 net.cpp:200] accuracy does not need backward computation.
I0405 20:05:07.663381  1665 net.cpp:198] loss needs backward computation.
I0405 20:05:07.663435  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 20:05:07.663480  1665 net.cpp:198] score needs backward computation.
I0405 20:05:07.663525  1665 net.cpp:198] global_pool needs backward computation.
I0405 20:05:07.663576  1665 net.cpp:198] last_relu needs backward computation.
I0405 20:05:07.663626  1665 net.cpp:198] last_scale needs backward computation.
I0405 20:05:07.663674  1665 net.cpp:198] last_bn needs backward computation.
I0405 20:05:07.663735  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 20:05:07.663802  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 20:05:07.663852  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 20:05:07.663902  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 20:05:07.663949  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 20:05:07.663998  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 20:05:07.664047  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 20:05:07.664096  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 20:05:07.664149  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 20:05:07.664199  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 20:05:07.664253  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 20:05:07.664304  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 20:05:07.664355  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 20:05:07.664404  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 20:05:07.664450  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 20:05:07.664503  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 20:05:07.664553  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 20:05:07.664602  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 20:05:07.664654  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 20:05:07.664703  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 20:05:07.664783  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 20:05:07.664830  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 20:05:07.664876  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 20:05:07.664923  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 20:05:07.664971  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 20:05:07.665019  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 20:05:07.665066  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 20:05:07.665112  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 20:05:07.665158  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 20:05:07.665211  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 20:05:07.665259  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 20:05:07.665307  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 20:05:07.665351  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 20:05:07.665397  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 20:05:07.665446  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 20:05:07.665491  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 20:05:07.665535  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 20:05:07.665586  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 20:05:07.665632  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 20:05:07.665680  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 20:05:07.665737  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 20:05:07.665796  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 20:05:07.665843  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 20:05:07.665889  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 20:05:07.665936  1665 net.cpp:198] conv1 needs backward computation.
I0405 20:05:07.665983  1665 net.cpp:198] data_scale needs backward computation.
I0405 20:05:07.666030  1665 net.cpp:200] data_bn does not need backward computation.
I0405 20:05:07.666079  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 20:05:07.666131  1665 net.cpp:200] data does not need backward computation.
I0405 20:05:07.666174  1665 net.cpp:242] This network produces output accuracy
I0405 20:05:07.666226  1665 net.cpp:242] This network produces output loss
I0405 20:05:07.666321  1665 net.cpp:255] Network initialization done.
I0405 20:05:47.589303  1665 solver.cpp:44] Initializing solver from parameters: 
test_iter: 0
test_interval: 469
base_lr: 0.001
display: 225
max_iter: 1800
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 1800
snapshot_prefix: "data/snapshots/train_batch_06"
solver_mode: GPU
random_seed: 0
net: "confs/sII/mid-caffeNet/inc_train_val.prototxt"
test_initialization: false
snapshot_format: HDF5
I0405 20:05:47.592381  1665 solver.cpp:87] Creating training net from net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 20:05:47.593500  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 20:05:47.593650  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 20:05:47.593858  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0405 20:05:47.593946  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0405 20:05:47.594221  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/train_batch_06_filelist.txt"
    batch_size: 256
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I0405 20:05:47.594480  1665 layer_factory.hpp:77] Creating layer data
I0405 20:05:47.594560  1665 net.cpp:84] Creating Layer data
I0405 20:05:47.594624  1665 net.cpp:380] data -> data
I0405 20:05:47.594681  1665 net.cpp:380] data -> label
I0405 20:05:47.594764  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/train_batch_06_filelist.txt
I0405 20:05:47.609019  1665 image_data_layer.cpp:53] Shuffling data
I0405 20:05:47.611385  1665 image_data_layer.cpp:63] A total of 95914 images.
I0405 20:05:47.613306  1665 image_data_layer.cpp:90] output data size: 256,3,128,128
I0405 20:05:47.737345  1665 net.cpp:122] Setting up data
I0405 20:05:47.737643  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 20:05:47.737730  1665 net.cpp:129] Top shape: 256 (256)
I0405 20:05:47.737870  1665 net.cpp:137] Memory required for data: 50332672
I0405 20:05:47.737967  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 20:05:47.738062  1665 net.cpp:84] Creating Layer data_bn
I0405 20:05:47.738137  1665 net.cpp:406] data_bn <- data
I0405 20:05:47.738204  1665 net.cpp:380] data_bn -> data_bn
I0405 20:05:47.738481  1665 net.cpp:122] Setting up data_bn
I0405 20:05:47.738565  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 20:05:47.738626  1665 net.cpp:137] Memory required for data: 100664320
I0405 20:05:47.738693  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:05:47.738765  1665 net.cpp:84] Creating Layer data_scale
I0405 20:05:47.738828  1665 net.cpp:406] data_scale <- data_bn
I0405 20:05:47.738889  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 20:05:47.738971  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:05:47.739148  1665 net.cpp:122] Setting up data_scale
I0405 20:05:47.739219  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 20:05:47.739280  1665 net.cpp:137] Memory required for data: 150995968
I0405 20:05:47.739348  1665 layer_factory.hpp:77] Creating layer conv1
I0405 20:05:47.739421  1665 net.cpp:84] Creating Layer conv1
I0405 20:05:47.739482  1665 net.cpp:406] conv1 <- data_bn
I0405 20:05:47.739544  1665 net.cpp:380] conv1 -> conv1
I0405 20:05:47.744462  1665 net.cpp:122] Setting up conv1
I0405 20:05:47.744606  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 20:05:47.744681  1665 net.cpp:137] Memory required for data: 419431424
I0405 20:05:47.744781  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 20:05:47.744848  1665 net.cpp:84] Creating Layer conv1_bn
I0405 20:05:47.744910  1665 net.cpp:406] conv1_bn <- conv1
I0405 20:05:47.744982  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 20:05:47.745172  1665 net.cpp:122] Setting up conv1_bn
I0405 20:05:47.745255  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 20:05:47.745317  1665 net.cpp:137] Memory required for data: 687866880
I0405 20:05:47.745394  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:05:47.745453  1665 net.cpp:84] Creating Layer conv1_scale
I0405 20:05:47.745515  1665 net.cpp:406] conv1_scale <- conv1
I0405 20:05:47.745585  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 20:05:47.745674  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:05:47.745849  1665 net.cpp:122] Setting up conv1_scale
I0405 20:05:47.745944  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 20:05:47.746004  1665 net.cpp:137] Memory required for data: 956302336
I0405 20:05:47.746073  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 20:05:47.746135  1665 net.cpp:84] Creating Layer conv1_relu
I0405 20:05:47.746196  1665 net.cpp:406] conv1_relu <- conv1
I0405 20:05:47.746268  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 20:05:47.746327  1665 net.cpp:122] Setting up conv1_relu
I0405 20:05:47.746389  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 20:05:47.746448  1665 net.cpp:137] Memory required for data: 1224737792
I0405 20:05:47.746516  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 20:05:47.746587  1665 net.cpp:84] Creating Layer conv1_pool
I0405 20:05:47.746649  1665 net.cpp:406] conv1_pool <- conv1
I0405 20:05:47.746728  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 20:05:47.746822  1665 net.cpp:122] Setting up conv1_pool
I0405 20:05:47.746889  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:05:47.746951  1665 net.cpp:137] Memory required for data: 1291846656
I0405 20:05:47.747015  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 20:05:47.747083  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 20:05:47.747144  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 20:05:47.747205  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 20:05:47.747265  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 20:05:47.747357  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 20:05:47.747419  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:05:47.747483  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:05:47.747545  1665 net.cpp:137] Memory required for data: 1426064384
I0405 20:05:47.747604  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 20:05:47.747676  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 20:05:47.747756  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 20:05:47.747818  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 20:05:47.748270  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 20:05:47.748345  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:05:47.748421  1665 net.cpp:137] Memory required for data: 1493173248
I0405 20:05:47.748481  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 20:05:47.748548  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 20:05:47.748610  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 20:05:47.748677  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 20:05:47.748885  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 20:05:47.748983  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:05:47.749047  1665 net.cpp:137] Memory required for data: 1560282112
I0405 20:05:47.749119  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:05:47.749188  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 20:05:47.749248  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 20:05:47.749334  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 20:05:47.749415  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:05:47.749563  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 20:05:47.749631  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:05:47.749696  1665 net.cpp:137] Memory required for data: 1627390976
I0405 20:05:47.749768  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 20:05:47.749830  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 20:05:47.749891  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 20:05:47.749954  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 20:05:47.750015  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 20:05:47.750080  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:05:47.750140  1665 net.cpp:137] Memory required for data: 1694499840
I0405 20:05:47.750200  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 20:05:47.750262  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 20:05:47.750321  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 20:05:47.750391  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 20:05:47.750882  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 20:05:47.750982  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:05:47.751044  1665 net.cpp:137] Memory required for data: 1761608704
I0405 20:05:47.751112  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 20:05:47.751178  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 20:05:47.751238  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 20:05:47.751300  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 20:05:47.751361  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 20:05:47.751441  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 20:05:47.751520  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:05:47.751586  1665 net.cpp:137] Memory required for data: 1828717568
I0405 20:05:47.751646  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 20:05:47.751721  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 20:05:47.751798  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 20:05:47.751857  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 20:05:47.752054  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 20:05:47.752140  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:05:47.752200  1665 net.cpp:137] Memory required for data: 1895826432
I0405 20:05:47.752262  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:05:47.752326  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 20:05:47.752388  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 20:05:47.752449  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 20:05:47.752532  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:05:47.752658  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 20:05:47.752784  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:05:47.752852  1665 net.cpp:137] Memory required for data: 1962935296
I0405 20:05:47.752916  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 20:05:47.752979  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 20:05:47.753039  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 20:05:47.753098  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 20:05:47.753160  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 20:05:47.753221  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:05:47.753291  1665 net.cpp:137] Memory required for data: 2030044160
I0405 20:05:47.753383  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:05:47.753468  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:05:47.753543  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 20:05:47.753624  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:05:47.753697  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:05:47.753811  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:05:47.753929  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:05:47.753995  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:05:47.754077  1665 net.cpp:137] Memory required for data: 2164261888
I0405 20:05:47.754176  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 20:05:47.754261  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 20:05:47.754329  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:05:47.754904  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 20:05:47.756441  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 20:05:47.756598  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:05:47.756685  1665 net.cpp:137] Memory required for data: 2197816320
I0405 20:05:47.756757  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 20:05:47.756825  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 20:05:47.756891  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 20:05:47.756959  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 20:05:47.757185  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 20:05:47.757273  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:05:47.757339  1665 net.cpp:137] Memory required for data: 2231370752
I0405 20:05:47.757409  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:05:47.757479  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 20:05:47.757550  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 20:05:47.757617  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 20:05:47.757727  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:05:47.757894  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 20:05:47.757982  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:05:47.758047  1665 net.cpp:137] Memory required for data: 2264925184
I0405 20:05:47.758123  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 20:05:47.758193  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 20:05:47.758260  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 20:05:47.758327  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 20:05:47.758394  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 20:05:47.758461  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:05:47.758527  1665 net.cpp:137] Memory required for data: 2298479616
I0405 20:05:47.758592  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 20:05:47.758663  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 20:05:47.758749  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 20:05:47.758816  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 20:05:47.760885  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 20:05:47.761010  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:05:47.761078  1665 net.cpp:137] Memory required for data: 2332034048
I0405 20:05:47.761142  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 20:05:47.761210  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 20:05:47.761270  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:05:47.761337  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 20:05:47.761696  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 20:05:47.761804  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:05:47.761868  1665 net.cpp:137] Memory required for data: 2365588480
I0405 20:05:47.761932  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 20:05:47.761997  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 20:05:47.762058  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 20:05:47.762120  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 20:05:47.762181  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 20:05:47.762269  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 20:05:47.762332  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:05:47.762392  1665 net.cpp:137] Memory required for data: 2399142912
I0405 20:05:47.762451  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 20:05:47.762513  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 20:05:47.762589  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 20:05:47.762651  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 20:05:47.762894  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 20:05:47.762977  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:05:47.763038  1665 net.cpp:137] Memory required for data: 2432697344
I0405 20:05:47.763103  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:05:47.763168  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 20:05:47.763229  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 20:05:47.763293  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 20:05:47.763394  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:05:47.763556  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 20:05:47.763813  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:05:47.763901  1665 net.cpp:137] Memory required for data: 2466251776
I0405 20:05:47.763981  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 20:05:47.764045  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 20:05:47.764111  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 20:05:47.764173  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 20:05:47.764243  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 20:05:47.764307  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:05:47.764369  1665 net.cpp:137] Memory required for data: 2499806208
I0405 20:05:47.764434  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:05:47.764497  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:05:47.764555  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 20:05:47.764619  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:05:47.764683  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:05:47.764804  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:05:47.764875  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:05:47.764935  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:05:47.764994  1665 net.cpp:137] Memory required for data: 2566915072
I0405 20:05:47.765091  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 20:05:47.765156  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 20:05:47.765219  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:05:47.765280  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 20:05:47.768698  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 20:05:47.768803  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:05:47.768862  1665 net.cpp:137] Memory required for data: 2583692288
I0405 20:05:47.768921  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 20:05:47.768982  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 20:05:47.769038  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 20:05:47.769100  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 20:05:47.769276  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 20:05:47.769356  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:05:47.769423  1665 net.cpp:137] Memory required for data: 2600469504
I0405 20:05:47.769480  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:05:47.769537  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 20:05:47.769589  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 20:05:47.769644  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 20:05:47.769752  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:05:47.769878  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 20:05:47.769954  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:05:47.770015  1665 net.cpp:137] Memory required for data: 2617246720
I0405 20:05:47.770082  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 20:05:47.770144  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 20:05:47.770206  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 20:05:47.770267  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 20:05:47.770330  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 20:05:47.770390  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:05:47.770450  1665 net.cpp:137] Memory required for data: 2634023936
I0405 20:05:47.770519  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 20:05:47.770587  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 20:05:47.770648  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 20:05:47.770706  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 20:05:47.776319  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 20:05:47.776438  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:05:47.776502  1665 net.cpp:137] Memory required for data: 2650801152
I0405 20:05:47.776571  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 20:05:47.776638  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 20:05:47.776702  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:05:47.776787  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 20:05:47.777222  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 20:05:47.777302  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:05:47.777360  1665 net.cpp:137] Memory required for data: 2667578368
I0405 20:05:47.777423  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 20:05:47.777492  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 20:05:47.777555  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 20:05:47.777621  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 20:05:47.777683  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 20:05:47.777771  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 20:05:47.777850  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:05:47.777910  1665 net.cpp:137] Memory required for data: 2684355584
I0405 20:05:47.777971  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 20:05:47.778034  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 20:05:47.778097  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 20:05:47.778159  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 20:05:47.778343  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 20:05:47.778424  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:05:47.778482  1665 net.cpp:137] Memory required for data: 2701132800
I0405 20:05:47.778551  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:05:47.778617  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 20:05:47.778687  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 20:05:47.778764  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 20:05:47.778848  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:05:47.778991  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 20:05:47.779074  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:05:47.779135  1665 net.cpp:137] Memory required for data: 2717910016
I0405 20:05:47.779198  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 20:05:47.779260  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 20:05:47.779320  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 20:05:47.779387  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 20:05:47.779451  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 20:05:47.779510  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:05:47.779568  1665 net.cpp:137] Memory required for data: 2734687232
I0405 20:05:47.779628  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:05:47.779695  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:05:47.779767  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 20:05:47.779834  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:05:47.779903  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:05:47.779984  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:05:47.780047  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:05:47.780113  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:05:47.780174  1665 net.cpp:137] Memory required for data: 2768241664
I0405 20:05:47.780234  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 20:05:47.780298  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 20:05:47.780360  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:05:47.780421  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 20:05:47.791270  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 20:05:47.791381  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:05:47.791447  1665 net.cpp:137] Memory required for data: 2776630272
I0405 20:05:47.791512  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 20:05:47.791579  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 20:05:47.791643  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 20:05:47.791709  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 20:05:47.791915  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 20:05:47.791985  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:05:47.792042  1665 net.cpp:137] Memory required for data: 2785018880
I0405 20:05:47.792112  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:05:47.792186  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 20:05:47.792248  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 20:05:47.792315  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 20:05:47.792387  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:05:47.792512  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 20:05:47.792589  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:05:47.792650  1665 net.cpp:137] Memory required for data: 2793407488
I0405 20:05:47.792724  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 20:05:47.792793  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 20:05:47.792855  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 20:05:47.792917  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 20:05:47.792977  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 20:05:47.793045  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:05:47.793110  1665 net.cpp:137] Memory required for data: 2801796096
I0405 20:05:47.793169  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 20:05:47.793231  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 20:05:47.793309  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 20:05:47.793366  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 20:05:47.814896  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 20:05:47.815011  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:05:47.815080  1665 net.cpp:137] Memory required for data: 2810184704
I0405 20:05:47.815151  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 20:05:47.815218  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 20:05:47.815284  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:05:47.815348  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 20:05:47.816572  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 20:05:47.816663  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:05:47.816766  1665 net.cpp:137] Memory required for data: 2818573312
I0405 20:05:47.816835  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 20:05:47.816901  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 20:05:47.816967  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 20:05:47.817028  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 20:05:47.817101  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 20:05:47.817178  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 20:05:47.817246  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:05:47.817318  1665 net.cpp:137] Memory required for data: 2826961920
I0405 20:05:47.817378  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 20:05:47.817442  1665 net.cpp:84] Creating Layer last_bn
I0405 20:05:47.817502  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 20:05:47.817579  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 20:05:47.817786  1665 net.cpp:122] Setting up last_bn
I0405 20:05:47.817870  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:05:47.817934  1665 net.cpp:137] Memory required for data: 2835350528
I0405 20:05:47.817996  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:05:47.818060  1665 net.cpp:84] Creating Layer last_scale
I0405 20:05:47.818120  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 20:05:47.818181  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 20:05:47.818261  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:05:47.818400  1665 net.cpp:122] Setting up last_scale
I0405 20:05:47.818475  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:05:47.818536  1665 net.cpp:137] Memory required for data: 2843739136
I0405 20:05:47.818605  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 20:05:47.818678  1665 net.cpp:84] Creating Layer last_relu
I0405 20:05:47.818770  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 20:05:47.818836  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 20:05:47.818899  1665 net.cpp:122] Setting up last_relu
I0405 20:05:47.819021  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:05:47.819110  1665 net.cpp:137] Memory required for data: 2852127744
I0405 20:05:47.819176  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 20:05:47.819242  1665 net.cpp:84] Creating Layer global_pool
I0405 20:05:47.819306  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 20:05:47.819372  1665 net.cpp:380] global_pool -> global_pool
I0405 20:05:47.819455  1665 net.cpp:122] Setting up global_pool
I0405 20:05:47.819528  1665 net.cpp:129] Top shape: 256 512 1 1 (131072)
I0405 20:05:47.819599  1665 net.cpp:137] Memory required for data: 2852652032
I0405 20:05:47.819660  1665 layer_factory.hpp:77] Creating layer score
I0405 20:05:47.819792  1665 net.cpp:84] Creating Layer score
I0405 20:05:47.819869  1665 net.cpp:406] score <- global_pool
I0405 20:05:47.819937  1665 net.cpp:380] score -> score
I0405 20:05:47.821281  1665 net.cpp:122] Setting up score
I0405 20:05:47.821384  1665 net.cpp:129] Top shape: 256 1000 (256000)
I0405 20:05:47.821449  1665 net.cpp:137] Memory required for data: 2853676032
I0405 20:05:47.821516  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:05:47.821581  1665 net.cpp:84] Creating Layer loss
I0405 20:05:47.821646  1665 net.cpp:406] loss <- score
I0405 20:05:47.821729  1665 net.cpp:406] loss <- label
I0405 20:05:47.821789  1665 net.cpp:380] loss -> loss
I0405 20:05:47.821854  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:05:47.823087  1665 net.cpp:122] Setting up loss
I0405 20:05:47.823184  1665 net.cpp:129] Top shape: (1)
I0405 20:05:47.823246  1665 net.cpp:132]     with loss weight 1
I0405 20:05:47.823313  1665 net.cpp:137] Memory required for data: 2853676036
I0405 20:05:47.823380  1665 net.cpp:198] loss needs backward computation.
I0405 20:05:47.823446  1665 net.cpp:198] score needs backward computation.
I0405 20:05:47.823508  1665 net.cpp:198] global_pool needs backward computation.
I0405 20:05:47.823568  1665 net.cpp:198] last_relu needs backward computation.
I0405 20:05:47.823635  1665 net.cpp:198] last_scale needs backward computation.
I0405 20:05:47.823696  1665 net.cpp:198] last_bn needs backward computation.
I0405 20:05:47.823770  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 20:05:47.823832  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 20:05:47.823894  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 20:05:47.823956  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 20:05:47.824033  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 20:05:47.824101  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 20:05:47.824160  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 20:05:47.824219  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 20:05:47.824280  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 20:05:47.824349  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 20:05:47.824414  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 20:05:47.824478  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 20:05:47.824542  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 20:05:47.824602  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 20:05:47.824666  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 20:05:47.824744  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 20:05:47.824811  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 20:05:47.824872  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 20:05:47.824934  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 20:05:47.824995  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 20:05:47.825054  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 20:05:47.825125  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 20:05:47.825192  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 20:05:47.825271  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 20:05:47.825346  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 20:05:47.825407  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 20:05:47.825497  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 20:05:47.825577  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 20:05:47.825650  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 20:05:47.825731  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 20:05:47.825794  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 20:05:47.825860  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 20:05:47.825924  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 20:05:47.825990  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 20:05:47.826054  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 20:05:47.826124  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 20:05:47.826189  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 20:05:47.826254  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 20:05:47.826319  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 20:05:47.826395  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 20:05:47.826462  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 20:05:47.826524  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 20:05:47.826587  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 20:05:47.826637  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 20:05:47.826696  1665 net.cpp:198] conv1 needs backward computation.
I0405 20:05:47.826786  1665 net.cpp:198] data_scale needs backward computation.
I0405 20:05:47.826853  1665 net.cpp:200] data_bn does not need backward computation.
I0405 20:05:47.826916  1665 net.cpp:200] data does not need backward computation.
I0405 20:05:47.826977  1665 net.cpp:242] This network produces output loss
I0405 20:05:47.827078  1665 net.cpp:255] Network initialization done.
I0405 20:05:47.828457  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 20:05:47.828606  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 20:05:47.828680  1665 solver.cpp:172] Creating test net (#0) specified by net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 20:05:47.828826  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 20:05:47.829156  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 20:05:47.829393  1665 layer_factory.hpp:77] Creating layer data
I0405 20:05:47.829480  1665 net.cpp:84] Creating Layer data
I0405 20:05:47.829545  1665 net.cpp:380] data -> data
I0405 20:05:47.829607  1665 net.cpp:380] data -> label
I0405 20:05:47.829675  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 20:05:47.836002  1665 image_data_layer.cpp:53] Shuffling data
I0405 20:05:47.837128  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 20:05:47.837896  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 20:05:47.887712  1665 net.cpp:122] Setting up data
I0405 20:05:47.887914  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:05:47.888015  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:05:47.888093  1665 net.cpp:137] Memory required for data: 19661200
I0405 20:05:47.888161  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 20:05:47.888257  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 20:05:47.888345  1665 net.cpp:406] label_data_1_split <- label
I0405 20:05:47.888413  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 20:05:47.888487  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 20:05:47.888610  1665 net.cpp:122] Setting up label_data_1_split
I0405 20:05:47.888695  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:05:47.888774  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:05:47.888850  1665 net.cpp:137] Memory required for data: 19662000
I0405 20:05:47.888923  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 20:05:47.889001  1665 net.cpp:84] Creating Layer data_bn
I0405 20:05:47.889102  1665 net.cpp:406] data_bn <- data
I0405 20:05:47.889181  1665 net.cpp:380] data_bn -> data_bn
I0405 20:05:47.890897  1665 net.cpp:122] Setting up data_bn
I0405 20:05:47.891038  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:05:47.891132  1665 net.cpp:137] Memory required for data: 39322800
I0405 20:05:47.891211  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:05:47.891283  1665 net.cpp:84] Creating Layer data_scale
I0405 20:05:47.891356  1665 net.cpp:406] data_scale <- data_bn
I0405 20:05:47.891423  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 20:05:47.891551  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:05:47.891793  1665 net.cpp:122] Setting up data_scale
I0405 20:05:47.891885  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:05:47.891958  1665 net.cpp:137] Memory required for data: 58983600
I0405 20:05:47.892035  1665 layer_factory.hpp:77] Creating layer conv1
I0405 20:05:47.892123  1665 net.cpp:84] Creating Layer conv1
I0405 20:05:47.892226  1665 net.cpp:406] conv1 <- data_bn
I0405 20:05:47.892311  1665 net.cpp:380] conv1 -> conv1
I0405 20:05:47.892786  1665 net.cpp:122] Setting up conv1
I0405 20:05:47.892902  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:05:47.892967  1665 net.cpp:137] Memory required for data: 163841200
I0405 20:05:47.893049  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 20:05:47.893124  1665 net.cpp:84] Creating Layer conv1_bn
I0405 20:05:47.893198  1665 net.cpp:406] conv1_bn <- conv1
I0405 20:05:47.893276  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 20:05:47.893563  1665 net.cpp:122] Setting up conv1_bn
I0405 20:05:47.893659  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:05:47.893766  1665 net.cpp:137] Memory required for data: 268698800
I0405 20:05:47.893851  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:05:47.893929  1665 net.cpp:84] Creating Layer conv1_scale
I0405 20:05:47.894001  1665 net.cpp:406] conv1_scale <- conv1
I0405 20:05:47.894089  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 20:05:47.894215  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:05:47.894420  1665 net.cpp:122] Setting up conv1_scale
I0405 20:05:47.894502  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:05:47.894569  1665 net.cpp:137] Memory required for data: 373556400
I0405 20:05:47.894645  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 20:05:47.894723  1665 net.cpp:84] Creating Layer conv1_relu
I0405 20:05:47.894790  1665 net.cpp:406] conv1_relu <- conv1
I0405 20:05:47.894861  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 20:05:47.894930  1665 net.cpp:122] Setting up conv1_relu
I0405 20:05:47.894999  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:05:47.895071  1665 net.cpp:137] Memory required for data: 478414000
I0405 20:05:47.895141  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 20:05:47.895216  1665 net.cpp:84] Creating Layer conv1_pool
I0405 20:05:47.895280  1665 net.cpp:406] conv1_pool <- conv1
I0405 20:05:47.895345  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 20:05:47.895475  1665 net.cpp:122] Setting up conv1_pool
I0405 20:05:47.895551  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:47.895638  1665 net.cpp:137] Memory required for data: 504628400
I0405 20:05:47.895705  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 20:05:47.895800  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 20:05:47.895874  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 20:05:47.895946  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 20:05:47.896014  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 20:05:47.896134  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 20:05:47.896211  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:47.896283  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:47.896348  1665 net.cpp:137] Memory required for data: 557057200
I0405 20:05:47.896420  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 20:05:47.896499  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 20:05:47.896579  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 20:05:47.896664  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 20:05:47.897444  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 20:05:47.897562  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:47.897636  1665 net.cpp:137] Memory required for data: 583271600
I0405 20:05:47.897763  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 20:05:47.897853  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 20:05:47.897920  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 20:05:47.897997  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 20:05:47.898283  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 20:05:47.898360  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:47.898438  1665 net.cpp:137] Memory required for data: 609486000
I0405 20:05:47.898509  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:05:47.898599  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 20:05:47.898670  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 20:05:47.898763  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 20:05:47.898892  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:05:47.899075  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 20:05:47.899166  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:47.899235  1665 net.cpp:137] Memory required for data: 635700400
I0405 20:05:47.899305  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 20:05:47.899379  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 20:05:47.899448  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 20:05:47.899515  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 20:05:47.899590  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 20:05:47.899663  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:47.899751  1665 net.cpp:137] Memory required for data: 661914800
I0405 20:05:47.899822  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 20:05:47.899899  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 20:05:47.899967  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 20:05:47.900035  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 20:05:47.900794  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 20:05:47.900907  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:47.900976  1665 net.cpp:137] Memory required for data: 688129200
I0405 20:05:47.901052  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 20:05:47.901126  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 20:05:47.901197  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 20:05:47.901266  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 20:05:47.901335  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 20:05:47.901433  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 20:05:47.901500  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:47.901569  1665 net.cpp:137] Memory required for data: 714343600
I0405 20:05:47.901638  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 20:05:47.901728  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 20:05:47.901803  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 20:05:47.901872  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 20:05:47.902151  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 20:05:47.902243  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:47.902323  1665 net.cpp:137] Memory required for data: 740558000
I0405 20:05:47.902395  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:05:47.902472  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 20:05:47.902551  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 20:05:47.902623  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 20:05:47.902761  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:05:47.902941  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 20:05:47.903038  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:47.903115  1665 net.cpp:137] Memory required for data: 766772400
I0405 20:05:47.903190  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 20:05:47.903264  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 20:05:47.903337  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 20:05:47.903417  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 20:05:47.903486  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 20:05:47.903554  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:47.903640  1665 net.cpp:137] Memory required for data: 792986800
I0405 20:05:47.903708  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:05:47.903800  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:05:47.903865  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 20:05:47.903934  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:05:47.904008  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:05:47.904125  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:05:47.904206  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:47.904278  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:05:47.904348  1665 net.cpp:137] Memory required for data: 845415600
I0405 20:05:47.904433  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 20:05:47.904511  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 20:05:47.904588  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:05:47.904659  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 20:05:47.905906  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 20:05:47.906023  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:47.906095  1665 net.cpp:137] Memory required for data: 858522800
I0405 20:05:47.906169  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 20:05:47.906244  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 20:05:47.906312  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 20:05:47.906386  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 20:05:47.906643  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 20:05:47.906764  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:47.906837  1665 net.cpp:137] Memory required for data: 871630000
I0405 20:05:47.906909  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:05:47.906985  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 20:05:47.907055  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 20:05:47.907128  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 20:05:47.907239  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:05:47.907418  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 20:05:47.907510  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:47.907590  1665 net.cpp:137] Memory required for data: 884737200
I0405 20:05:47.907673  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 20:05:47.907771  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 20:05:47.907842  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 20:05:47.907927  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 20:05:47.907996  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 20:05:47.908075  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:47.908146  1665 net.cpp:137] Memory required for data: 897844400
I0405 20:05:47.908217  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 20:05:47.908294  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 20:05:47.908370  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 20:05:47.908440  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 20:05:47.910593  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 20:05:47.910706  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:47.910851  1665 net.cpp:137] Memory required for data: 910951600
I0405 20:05:47.910926  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 20:05:47.911011  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 20:05:47.911098  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:05:47.911181  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 20:05:47.911586  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 20:05:47.911684  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:47.911787  1665 net.cpp:137] Memory required for data: 924058800
I0405 20:05:47.911852  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 20:05:47.911921  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 20:05:47.911990  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 20:05:47.912065  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 20:05:47.912143  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 20:05:47.912245  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 20:05:47.912322  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:47.912395  1665 net.cpp:137] Memory required for data: 937166000
I0405 20:05:47.912463  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 20:05:47.912544  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 20:05:47.912632  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 20:05:47.912698  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 20:05:47.912999  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 20:05:47.913090  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:47.913167  1665 net.cpp:137] Memory required for data: 950273200
I0405 20:05:47.913241  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:05:47.913324  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 20:05:47.913393  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 20:05:47.913462  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 20:05:47.913585  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:05:47.913774  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 20:05:47.913851  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:47.913916  1665 net.cpp:137] Memory required for data: 963380400
I0405 20:05:47.913990  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 20:05:47.914059  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 20:05:47.914155  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 20:05:47.914223  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 20:05:47.914295  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 20:05:47.914363  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:47.914429  1665 net.cpp:137] Memory required for data: 976487600
I0405 20:05:47.914495  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:05:47.914566  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:05:47.914633  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 20:05:47.914700  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:05:47.914779  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:05:47.914880  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:05:47.914954  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:47.915016  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:05:47.915087  1665 net.cpp:137] Memory required for data: 1002702000
I0405 20:05:47.915158  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 20:05:47.915243  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 20:05:47.915355  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:05:47.915428  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 20:05:47.920501  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 20:05:47.920733  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:47.920825  1665 net.cpp:137] Memory required for data: 1009255600
I0405 20:05:47.920889  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 20:05:47.920967  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 20:05:47.921032  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 20:05:47.921118  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 20:05:47.921416  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 20:05:47.921520  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:47.921608  1665 net.cpp:137] Memory required for data: 1015809200
I0405 20:05:47.921679  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:05:47.921779  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 20:05:47.921861  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 20:05:47.921941  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 20:05:47.922351  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:05:47.922538  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 20:05:47.922658  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:47.922744  1665 net.cpp:137] Memory required for data: 1022362800
I0405 20:05:47.923106  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 20:05:47.923184  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 20:05:47.923264  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 20:05:47.923328  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 20:05:47.923390  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 20:05:47.923457  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:47.923573  1665 net.cpp:137] Memory required for data: 1028916400
I0405 20:05:47.923666  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 20:05:47.923748  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 20:05:47.923811  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 20:05:47.923874  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 20:05:47.932577  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 20:05:47.932698  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:47.932778  1665 net.cpp:137] Memory required for data: 1035470000
I0405 20:05:47.932845  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 20:05:47.932915  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 20:05:47.932994  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:05:47.933059  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 20:05:47.933771  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 20:05:47.933871  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:47.933936  1665 net.cpp:137] Memory required for data: 1042023600
I0405 20:05:47.934002  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 20:05:47.934073  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 20:05:47.934137  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 20:05:47.934202  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 20:05:47.934273  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 20:05:47.934361  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 20:05:47.934443  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:47.934509  1665 net.cpp:137] Memory required for data: 1048577200
I0405 20:05:47.934583  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 20:05:47.934654  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 20:05:47.934733  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 20:05:47.934805  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 20:05:47.935081  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 20:05:47.935159  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:47.935226  1665 net.cpp:137] Memory required for data: 1055130800
I0405 20:05:47.935297  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:05:47.935364  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 20:05:47.935428  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 20:05:47.935497  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 20:05:47.935616  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:05:47.935818  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 20:05:47.935894  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:47.935972  1665 net.cpp:137] Memory required for data: 1061684400
I0405 20:05:47.936043  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 20:05:47.936112  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 20:05:47.936203  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 20:05:47.936270  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 20:05:47.936336  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 20:05:47.936400  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:47.936466  1665 net.cpp:137] Memory required for data: 1068238000
I0405 20:05:47.936537  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:05:47.936611  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:05:47.937201  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 20:05:47.937325  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:05:47.937412  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:05:47.937526  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:05:47.937613  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:47.937705  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:05:47.937785  1665 net.cpp:137] Memory required for data: 1081345200
I0405 20:05:47.937851  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 20:05:47.937922  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 20:05:47.937983  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:05:47.938048  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 20:05:47.956166  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 20:05:47.956312  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:47.956425  1665 net.cpp:137] Memory required for data: 1084622000
I0405 20:05:47.956507  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 20:05:47.956594  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 20:05:47.956701  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 20:05:47.956774  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 20:05:47.957083  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 20:05:47.957195  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:47.957273  1665 net.cpp:137] Memory required for data: 1087898800
I0405 20:05:47.957348  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:05:47.957427  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 20:05:47.957496  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 20:05:47.957581  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 20:05:47.957707  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:05:47.957921  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 20:05:47.958001  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:47.958072  1665 net.cpp:137] Memory required for data: 1091175600
I0405 20:05:47.958144  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 20:05:47.958217  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 20:05:47.958286  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 20:05:47.958354  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 20:05:47.958428  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 20:05:47.958500  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:47.958585  1665 net.cpp:137] Memory required for data: 1094452400
I0405 20:05:47.958657  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 20:05:47.958761  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 20:05:47.958835  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 20:05:47.958911  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 20:05:47.992333  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 20:05:47.992497  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:47.992588  1665 net.cpp:137] Memory required for data: 1097729200
I0405 20:05:47.992689  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 20:05:47.992816  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 20:05:47.992887  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:05:47.992962  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 20:05:47.995009  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 20:05:47.995127  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:47.995194  1665 net.cpp:137] Memory required for data: 1101006000
I0405 20:05:47.995260  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 20:05:47.995326  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 20:05:47.995390  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 20:05:47.995457  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 20:05:47.995522  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 20:05:47.995627  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 20:05:47.995689  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:47.995775  1665 net.cpp:137] Memory required for data: 1104282800
I0405 20:05:47.995836  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 20:05:47.995903  1665 net.cpp:84] Creating Layer last_bn
I0405 20:05:47.995970  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 20:05:47.996038  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 20:05:47.996333  1665 net.cpp:122] Setting up last_bn
I0405 20:05:47.996435  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:47.996512  1665 net.cpp:137] Memory required for data: 1107559600
I0405 20:05:47.996587  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:05:47.996656  1665 net.cpp:84] Creating Layer last_scale
I0405 20:05:47.996744  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 20:05:47.996815  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 20:05:47.996933  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:05:47.997148  1665 net.cpp:122] Setting up last_scale
I0405 20:05:47.997228  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:47.997301  1665 net.cpp:137] Memory required for data: 1110836400
I0405 20:05:47.997375  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 20:05:47.997442  1665 net.cpp:84] Creating Layer last_relu
I0405 20:05:47.997504  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 20:05:47.997575  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 20:05:47.997640  1665 net.cpp:122] Setting up last_relu
I0405 20:05:47.997704  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:05:47.997781  1665 net.cpp:137] Memory required for data: 1114113200
I0405 20:05:47.997854  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 20:05:47.997925  1665 net.cpp:84] Creating Layer global_pool
I0405 20:05:47.997987  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 20:05:47.998049  1665 net.cpp:380] global_pool -> global_pool
I0405 20:05:47.998154  1665 net.cpp:122] Setting up global_pool
I0405 20:05:47.998219  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 20:05:47.998284  1665 net.cpp:137] Memory required for data: 1114318000
I0405 20:05:47.998366  1665 layer_factory.hpp:77] Creating layer score
I0405 20:05:47.998437  1665 net.cpp:84] Creating Layer score
I0405 20:05:47.998502  1665 net.cpp:406] score <- global_pool
I0405 20:05:47.998575  1665 net.cpp:380] score -> score
I0405 20:05:48.000386  1665 net.cpp:122] Setting up score
I0405 20:05:48.000514  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:05:48.000602  1665 net.cpp:137] Memory required for data: 1114718000
I0405 20:05:48.000679  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 20:05:48.000766  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 20:05:48.000852  1665 net.cpp:406] score_score_0_split <- score
I0405 20:05:48.000919  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 20:05:48.001005  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 20:05:48.001118  1665 net.cpp:122] Setting up score_score_0_split
I0405 20:05:48.001204  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:05:48.001271  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:05:48.001338  1665 net.cpp:137] Memory required for data: 1115518000
I0405 20:05:48.001405  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:05:48.001479  1665 net.cpp:84] Creating Layer loss
I0405 20:05:48.001555  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 20:05:48.001623  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 20:05:48.001693  1665 net.cpp:380] loss -> loss
I0405 20:05:48.001788  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:05:48.003409  1665 net.cpp:122] Setting up loss
I0405 20:05:48.003545  1665 net.cpp:129] Top shape: (1)
I0405 20:05:48.003646  1665 net.cpp:132]     with loss weight 1
I0405 20:05:48.003748  1665 net.cpp:137] Memory required for data: 1115518004
I0405 20:05:48.003815  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 20:05:48.003882  1665 net.cpp:84] Creating Layer accuracy
I0405 20:05:48.003945  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 20:05:48.004016  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 20:05:48.004087  1665 net.cpp:380] accuracy -> accuracy
I0405 20:05:48.004156  1665 net.cpp:122] Setting up accuracy
I0405 20:05:48.004220  1665 net.cpp:129] Top shape: (1)
I0405 20:05:48.004281  1665 net.cpp:137] Memory required for data: 1115518008
I0405 20:05:48.004340  1665 net.cpp:200] accuracy does not need backward computation.
I0405 20:05:48.004411  1665 net.cpp:198] loss needs backward computation.
I0405 20:05:48.004480  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 20:05:48.004556  1665 net.cpp:198] score needs backward computation.
I0405 20:05:48.004619  1665 net.cpp:198] global_pool needs backward computation.
I0405 20:05:48.004683  1665 net.cpp:198] last_relu needs backward computation.
I0405 20:05:48.004762  1665 net.cpp:198] last_scale needs backward computation.
I0405 20:05:48.004833  1665 net.cpp:198] last_bn needs backward computation.
I0405 20:05:48.004900  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 20:05:48.004964  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 20:05:48.005028  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 20:05:48.005097  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 20:05:48.005177  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 20:05:48.005239  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 20:05:48.005300  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 20:05:48.005368  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 20:05:48.005429  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 20:05:48.005496  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 20:05:48.005569  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 20:05:48.005636  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 20:05:48.005699  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 20:05:48.005784  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 20:05:48.005865  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 20:05:48.005928  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 20:05:48.005990  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 20:05:48.006052  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 20:05:48.006124  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 20:05:48.006191  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 20:05:48.006275  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 20:05:48.006336  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 20:05:48.006397  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 20:05:48.006458  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 20:05:48.006538  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 20:05:48.006613  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 20:05:48.006677  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 20:05:48.006760  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 20:05:48.006825  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 20:05:48.006888  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 20:05:48.006963  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 20:05:48.007028  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 20:05:48.007091  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 20:05:48.007154  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 20:05:48.007218  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 20:05:48.007287  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 20:05:48.007380  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 20:05:48.007442  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 20:05:48.007503  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 20:05:48.007570  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 20:05:48.007642  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 20:05:48.007709  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 20:05:48.007788  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 20:05:48.007859  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 20:05:48.007930  1665 net.cpp:198] conv1 needs backward computation.
I0405 20:05:48.007999  1665 net.cpp:198] data_scale needs backward computation.
I0405 20:05:48.008070  1665 net.cpp:200] data_bn does not need backward computation.
I0405 20:05:48.008143  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 20:05:48.008217  1665 net.cpp:200] data does not need backward computation.
I0405 20:05:48.008287  1665 net.cpp:242] This network produces output accuracy
I0405 20:05:48.008358  1665 net.cpp:242] This network produces output loss
I0405 20:05:48.008502  1665 net.cpp:255] Network initialization done.
I0405 20:05:48.008837  1665 solver.cpp:56] Solver scaffolding done.
I0405 20:05:48.048856  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: data/resnet10_cvgj_iter_320000.caffemodel
I0405 20:05:48.049062  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 20:05:48.521569  1665 solver.cpp:218] Iteration 0 (1.66721e-09 iter/s, 0.468064s/225 iters), loss = 12.9895
I0405 20:05:48.521806  1665 solver.cpp:237]     Train net output #0: loss = 12.9895 (* 1 = 12.9895 loss)
I0405 20:05:48.521970  1665 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I0405 20:07:27.069350  1665 solver.cpp:218] Iteration 225 (2.28313 iter/s, 98.5487s/225 iters), loss = 0.556796
I0405 20:07:27.069682  1665 solver.cpp:237]     Train net output #0: loss = 0.556796 (* 1 = 0.556796 loss)
I0405 20:07:27.069833  1665 sgd_solver.cpp:105] Iteration 225, lr = 0.000875
I0405 20:09:05.601260  1665 solver.cpp:218] Iteration 450 (2.2835 iter/s, 98.5328s/225 iters), loss = 0.372169
I0405 20:09:05.601784  1665 solver.cpp:237]     Train net output #0: loss = 0.372169 (* 1 = 0.372169 loss)
I0405 20:09:05.601910  1665 sgd_solver.cpp:105] Iteration 450, lr = 0.00075
I0405 20:09:13.485366  1665 solver.cpp:330] Iteration 469, Testing net (#0)
I0405 20:10:44.142859  1665 solver.cpp:218] Iteration 675 (2.28328 iter/s, 98.5424s/225 iters), loss = 0.280253
I0405 20:10:44.143219  1665 solver.cpp:237]     Train net output #0: loss = 0.280253 (* 1 = 0.280253 loss)
I0405 20:10:44.143304  1665 sgd_solver.cpp:105] Iteration 675, lr = 0.000625
I0405 20:12:22.682265  1665 solver.cpp:218] Iteration 900 (2.28333 iter/s, 98.5403s/225 iters), loss = 0.272276
I0405 20:12:22.682687  1665 solver.cpp:237]     Train net output #0: loss = 0.272276 (* 1 = 0.272276 loss)
I0405 20:12:22.682891  1665 sgd_solver.cpp:105] Iteration 900, lr = 0.0005
I0405 20:12:38.888445  1665 solver.cpp:330] Iteration 938, Testing net (#0)
I0405 20:14:01.208503  1665 solver.cpp:218] Iteration 1125 (2.28363 iter/s, 98.5271s/225 iters), loss = 0.167985
I0405 20:14:01.208875  1665 solver.cpp:237]     Train net output #0: loss = 0.167985 (* 1 = 0.167985 loss)
I0405 20:14:01.208956  1665 sgd_solver.cpp:105] Iteration 1125, lr = 0.000375
I0405 20:15:39.739013  1665 solver.cpp:218] Iteration 1350 (2.28359 iter/s, 98.5289s/225 iters), loss = 0.146783
I0405 20:15:39.739317  1665 solver.cpp:237]     Train net output #0: loss = 0.146783 (* 1 = 0.146783 loss)
I0405 20:15:39.739492  1665 sgd_solver.cpp:105] Iteration 1350, lr = 0.00025
I0405 20:16:04.265604  1665 solver.cpp:330] Iteration 1407, Testing net (#0)
I0405 20:17:18.265502  1665 solver.cpp:218] Iteration 1575 (2.28369 iter/s, 98.5248s/225 iters), loss = 0.169297
I0405 20:17:18.265888  1665 solver.cpp:237]     Train net output #0: loss = 0.169297 (* 1 = 0.169297 loss)
I0405 20:17:18.266152  1665 sgd_solver.cpp:105] Iteration 1575, lr = 0.000125
I0405 20:18:56.354348  1665 solver.cpp:457] Snapshotting to HDF5 file data/snapshots/train_batch_06_iter_1800.caffemodel.h5
I0405 20:18:56.412878  1665 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file data/snapshots/train_batch_06_iter_1800.solverstate.h5
W0405 20:18:58.939613  1665 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W0405 20:18:58.939944  1665 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W0405 20:18:58.939998  1665 _caffe.cpp:142] Net('confs/sII/mid-caffeNet/inc_train_val.prototxt', 1, weights='data/snapshots/train_batch_06_iter_1800.caffemodel.h5')
I0405 20:18:58.943341  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 20:18:58.943470  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 20:18:58.943584  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 20:18:58.943894  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 20:18:58.944151  1665 layer_factory.hpp:77] Creating layer data
I0405 20:18:58.944216  1665 net.cpp:84] Creating Layer data
I0405 20:18:58.944263  1665 net.cpp:380] data -> data
I0405 20:18:58.944312  1665 net.cpp:380] data -> label
I0405 20:18:58.944360  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 20:18:58.952481  1665 image_data_layer.cpp:53] Shuffling data
I0405 20:18:58.953584  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 20:18:58.954560  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 20:18:59.001463  1665 net.cpp:122] Setting up data
I0405 20:18:59.001703  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:18:59.001797  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:18:59.001861  1665 net.cpp:137] Memory required for data: 19661200
I0405 20:18:59.001926  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 20:18:59.001996  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 20:18:59.002117  1665 net.cpp:406] label_data_1_split <- label
I0405 20:18:59.002200  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 20:18:59.002378  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 20:18:59.002651  1665 net.cpp:122] Setting up label_data_1_split
I0405 20:18:59.002791  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:18:59.002915  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:18:59.003001  1665 net.cpp:137] Memory required for data: 19662000
I0405 20:18:59.003080  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 20:18:59.003163  1665 net.cpp:84] Creating Layer data_bn
I0405 20:18:59.003242  1665 net.cpp:406] data_bn <- data
I0405 20:18:59.003324  1665 net.cpp:380] data_bn -> data_bn
I0405 20:18:59.005295  1665 net.cpp:122] Setting up data_bn
I0405 20:18:59.005434  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:18:59.005534  1665 net.cpp:137] Memory required for data: 39322800
I0405 20:18:59.005623  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:18:59.005705  1665 net.cpp:84] Creating Layer data_scale
I0405 20:18:59.014140  1665 net.cpp:406] data_scale <- data_bn
I0405 20:18:59.014292  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 20:18:59.014432  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:18:59.014606  1665 net.cpp:122] Setting up data_scale
I0405 20:18:59.014701  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:18:59.014796  1665 net.cpp:137] Memory required for data: 58983600
I0405 20:18:59.014858  1665 layer_factory.hpp:77] Creating layer conv1
I0405 20:18:59.014923  1665 net.cpp:84] Creating Layer conv1
I0405 20:18:59.014987  1665 net.cpp:406] conv1 <- data_bn
I0405 20:18:59.015045  1665 net.cpp:380] conv1 -> conv1
I0405 20:18:59.015352  1665 net.cpp:122] Setting up conv1
I0405 20:18:59.015455  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:18:59.015524  1665 net.cpp:137] Memory required for data: 163841200
I0405 20:18:59.015583  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 20:18:59.015643  1665 net.cpp:84] Creating Layer conv1_bn
I0405 20:18:59.015722  1665 net.cpp:406] conv1_bn <- conv1
I0405 20:18:59.015817  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 20:18:59.016011  1665 net.cpp:122] Setting up conv1_bn
I0405 20:18:59.016088  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:18:59.016145  1665 net.cpp:137] Memory required for data: 268698800
I0405 20:18:59.016218  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:18:59.016288  1665 net.cpp:84] Creating Layer conv1_scale
I0405 20:18:59.016350  1665 net.cpp:406] conv1_scale <- conv1
I0405 20:18:59.016410  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 20:18:59.016515  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:18:59.016667  1665 net.cpp:122] Setting up conv1_scale
I0405 20:18:59.016819  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:18:59.016883  1665 net.cpp:137] Memory required for data: 373556400
I0405 20:18:59.016958  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 20:18:59.017024  1665 net.cpp:84] Creating Layer conv1_relu
I0405 20:18:59.017084  1665 net.cpp:406] conv1_relu <- conv1
I0405 20:18:59.017144  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 20:18:59.017205  1665 net.cpp:122] Setting up conv1_relu
I0405 20:18:59.017267  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:18:59.017326  1665 net.cpp:137] Memory required for data: 478414000
I0405 20:18:59.017391  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 20:18:59.017454  1665 net.cpp:84] Creating Layer conv1_pool
I0405 20:18:59.017542  1665 net.cpp:406] conv1_pool <- conv1
I0405 20:18:59.017603  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 20:18:59.017688  1665 net.cpp:122] Setting up conv1_pool
I0405 20:18:59.017772  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:18:59.017845  1665 net.cpp:137] Memory required for data: 504628400
I0405 20:18:59.017921  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 20:18:59.017984  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 20:18:59.018033  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 20:18:59.018083  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 20:18:59.018147  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 20:18:59.018236  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 20:18:59.018302  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:18:59.018362  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:18:59.018419  1665 net.cpp:137] Memory required for data: 557057200
I0405 20:18:59.018479  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 20:18:59.018543  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 20:18:59.018610  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 20:18:59.018684  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 20:18:59.019233  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 20:18:59.019341  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:18:59.019404  1665 net.cpp:137] Memory required for data: 583271600
I0405 20:18:59.019464  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 20:18:59.019541  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 20:18:59.019613  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 20:18:59.019680  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 20:18:59.019891  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 20:18:59.019978  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:18:59.020040  1665 net.cpp:137] Memory required for data: 609486000
I0405 20:18:59.020102  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:18:59.020167  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 20:18:59.020229  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 20:18:59.020304  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 20:18:59.020385  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:18:59.020534  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 20:18:59.020603  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:18:59.020668  1665 net.cpp:137] Memory required for data: 635700400
I0405 20:18:59.020766  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 20:18:59.020879  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 20:18:59.020946  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 20:18:59.020999  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 20:18:59.021049  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 20:18:59.021098  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:18:59.021147  1665 net.cpp:137] Memory required for data: 661914800
I0405 20:18:59.021222  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 20:18:59.021275  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 20:18:59.021324  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 20:18:59.021376  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 20:18:59.021868  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 20:18:59.021965  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:18:59.022065  1665 net.cpp:137] Memory required for data: 688129200
I0405 20:18:59.022130  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 20:18:59.022197  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 20:18:59.022245  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 20:18:59.022294  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 20:18:59.022372  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 20:18:59.022459  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 20:18:59.022528  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:18:59.022577  1665 net.cpp:137] Memory required for data: 714343600
I0405 20:18:59.022626  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 20:18:59.022677  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 20:18:59.022737  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 20:18:59.022789  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 20:18:59.022970  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 20:18:59.023025  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:18:59.023072  1665 net.cpp:137] Memory required for data: 740558000
I0405 20:18:59.023123  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:18:59.023175  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 20:18:59.023247  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 20:18:59.023322  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 20:18:59.023396  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:18:59.023515  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 20:18:59.023582  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:18:59.023630  1665 net.cpp:137] Memory required for data: 766772400
I0405 20:18:59.023681  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 20:18:59.023744  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 20:18:59.023792  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 20:18:59.023842  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 20:18:59.023892  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 20:18:59.023967  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:18:59.024020  1665 net.cpp:137] Memory required for data: 792986800
I0405 20:18:59.024070  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:18:59.024121  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:18:59.024166  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 20:18:59.024235  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:18:59.024292  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:18:59.024379  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:18:59.024432  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:18:59.024482  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:18:59.024530  1665 net.cpp:137] Memory required for data: 845415600
I0405 20:18:59.024580  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 20:18:59.024633  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 20:18:59.024683  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:18:59.024750  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 20:18:59.025497  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 20:18:59.025573  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:18:59.025624  1665 net.cpp:137] Memory required for data: 858522800
I0405 20:18:59.025676  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 20:18:59.025756  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 20:18:59.025859  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 20:18:59.025918  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 20:18:59.026118  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 20:18:59.026198  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:18:59.026258  1665 net.cpp:137] Memory required for data: 871630000
I0405 20:18:59.026320  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:18:59.026386  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 20:18:59.026446  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 20:18:59.026511  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 20:18:59.026595  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:18:59.026768  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 20:18:59.026865  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:18:59.026937  1665 net.cpp:137] Memory required for data: 884737200
I0405 20:18:59.026998  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 20:18:59.027058  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 20:18:59.027119  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 20:18:59.027206  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 20:18:59.027269  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 20:18:59.027330  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:18:59.027391  1665 net.cpp:137] Memory required for data: 897844400
I0405 20:18:59.027451  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 20:18:59.027514  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 20:18:59.027576  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 20:18:59.027637  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 20:18:59.029003  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 20:18:59.029083  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:18:59.029146  1665 net.cpp:137] Memory required for data: 910951600
I0405 20:18:59.029208  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 20:18:59.029273  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 20:18:59.029336  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:18:59.029397  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 20:18:59.029640  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 20:18:59.029763  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:18:59.029829  1665 net.cpp:137] Memory required for data: 924058800
I0405 20:18:59.029886  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 20:18:59.029953  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 20:18:59.030025  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 20:18:59.030092  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 20:18:59.030164  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 20:18:59.030241  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 20:18:59.030303  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:18:59.030362  1665 net.cpp:137] Memory required for data: 937166000
I0405 20:18:59.030422  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 20:18:59.030483  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 20:18:59.030545  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 20:18:59.030606  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 20:18:59.030794  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 20:18:59.030870  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:18:59.030926  1665 net.cpp:137] Memory required for data: 950273200
I0405 20:18:59.030984  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:18:59.031047  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 20:18:59.031118  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 20:18:59.031193  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 20:18:59.031276  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:18:59.031402  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 20:18:59.031477  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:18:59.031535  1665 net.cpp:137] Memory required for data: 963380400
I0405 20:18:59.031597  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 20:18:59.031657  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 20:18:59.031716  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 20:18:59.031786  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 20:18:59.031847  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 20:18:59.031924  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:18:59.031987  1665 net.cpp:137] Memory required for data: 976487600
I0405 20:18:59.032047  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:18:59.032105  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:18:59.032179  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 20:18:59.032255  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:18:59.032320  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:18:59.032397  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:18:59.032461  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:18:59.032522  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:18:59.032583  1665 net.cpp:137] Memory required for data: 1002702000
I0405 20:18:59.032644  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 20:18:59.032707  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 20:18:59.032775  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:18:59.032855  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 20:18:59.036371  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 20:18:59.036487  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:18:59.036540  1665 net.cpp:137] Memory required for data: 1009255600
I0405 20:18:59.036593  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 20:18:59.036649  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 20:18:59.036701  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 20:18:59.036769  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 20:18:59.036957  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 20:18:59.037031  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:18:59.037082  1665 net.cpp:137] Memory required for data: 1015809200
I0405 20:18:59.037137  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:18:59.037212  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 20:18:59.037286  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 20:18:59.037338  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 20:18:59.037413  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:18:59.037533  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 20:18:59.037597  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:18:59.037647  1665 net.cpp:137] Memory required for data: 1022362800
I0405 20:18:59.037699  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 20:18:59.037787  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 20:18:59.037842  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 20:18:59.037914  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 20:18:59.037973  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 20:18:59.038022  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:18:59.038069  1665 net.cpp:137] Memory required for data: 1028916400
I0405 20:18:59.038120  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 20:18:59.038193  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 20:18:59.038272  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 20:18:59.038329  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 20:18:59.043951  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 20:18:59.044055  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:18:59.044112  1665 net.cpp:137] Memory required for data: 1035470000
I0405 20:18:59.044165  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 20:18:59.044220  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 20:18:59.044272  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:18:59.044806  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 20:18:59.045303  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 20:18:59.045393  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:18:59.045444  1665 net.cpp:137] Memory required for data: 1042023600
I0405 20:18:59.045495  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 20:18:59.045547  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 20:18:59.045595  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 20:18:59.045646  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 20:18:59.045696  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 20:18:59.045778  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 20:18:59.045848  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:18:59.045897  1665 net.cpp:137] Memory required for data: 1048577200
I0405 20:18:59.045959  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 20:18:59.046011  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 20:18:59.046097  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 20:18:59.046172  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 20:18:59.046360  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 20:18:59.046427  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:18:59.046488  1665 net.cpp:137] Memory required for data: 1055130800
I0405 20:18:59.046540  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:18:59.046589  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 20:18:59.046636  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 20:18:59.046686  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 20:18:59.046790  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:18:59.046931  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 20:18:59.047008  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:18:59.047066  1665 net.cpp:137] Memory required for data: 1061684400
I0405 20:18:59.047148  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 20:18:59.047227  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 20:18:59.047286  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 20:18:59.047348  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 20:18:59.047408  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 20:18:59.047475  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:18:59.047536  1665 net.cpp:137] Memory required for data: 1068238000
I0405 20:18:59.047596  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:18:59.047658  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:18:59.047724  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 20:18:59.047788  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:18:59.047848  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:18:59.047940  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:18:59.048002  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:18:59.048059  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:18:59.048117  1665 net.cpp:137] Memory required for data: 1081345200
I0405 20:18:59.048190  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 20:18:59.048280  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 20:18:59.048339  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:18:59.048399  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 20:18:59.059335  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 20:18:59.059444  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:18:59.059520  1665 net.cpp:137] Memory required for data: 1084622000
I0405 20:18:59.059581  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 20:18:59.059659  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 20:18:59.059733  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 20:18:59.059813  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 20:18:59.060015  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 20:18:59.060093  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:18:59.060156  1665 net.cpp:137] Memory required for data: 1087898800
I0405 20:18:59.060218  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:18:59.060282  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 20:18:59.060359  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 20:18:59.060421  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 20:18:59.060523  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:18:59.060660  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 20:18:59.060772  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:18:59.060827  1665 net.cpp:137] Memory required for data: 1091175600
I0405 20:18:59.060902  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 20:18:59.060963  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 20:18:59.061022  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 20:18:59.061084  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 20:18:59.061143  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 20:18:59.061203  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:18:59.061273  1665 net.cpp:137] Memory required for data: 1094452400
I0405 20:18:59.061336  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 20:18:59.061398  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 20:18:59.061467  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 20:18:59.061538  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 20:18:59.083587  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 20:18:59.083806  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:18:59.083880  1665 net.cpp:137] Memory required for data: 1097729200
I0405 20:18:59.083937  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 20:18:59.084017  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 20:18:59.084074  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:18:59.084131  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 20:18:59.085367  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 20:18:59.085481  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:18:59.085536  1665 net.cpp:137] Memory required for data: 1101006000
I0405 20:18:59.085590  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 20:18:59.085645  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 20:18:59.085698  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 20:18:59.085774  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 20:18:59.085826  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 20:18:59.085904  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 20:18:59.085963  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:18:59.086066  1665 net.cpp:137] Memory required for data: 1104282800
I0405 20:18:59.086174  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 20:18:59.086247  1665 net.cpp:84] Creating Layer last_bn
I0405 20:18:59.086308  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 20:18:59.086361  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 20:18:59.086570  1665 net.cpp:122] Setting up last_bn
I0405 20:18:59.086640  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:18:59.086696  1665 net.cpp:137] Memory required for data: 1107559600
I0405 20:18:59.086761  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:18:59.086817  1665 net.cpp:84] Creating Layer last_scale
I0405 20:18:59.086860  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 20:18:59.086908  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 20:18:59.087014  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:18:59.087157  1665 net.cpp:122] Setting up last_scale
I0405 20:18:59.087231  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:18:59.087285  1665 net.cpp:137] Memory required for data: 1110836400
I0405 20:18:59.087344  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 20:18:59.087394  1665 net.cpp:84] Creating Layer last_relu
I0405 20:18:59.087445  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 20:18:59.087497  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 20:18:59.087548  1665 net.cpp:122] Setting up last_relu
I0405 20:18:59.087591  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:18:59.087641  1665 net.cpp:137] Memory required for data: 1114113200
I0405 20:18:59.087689  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 20:18:59.087761  1665 net.cpp:84] Creating Layer global_pool
I0405 20:18:59.087816  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 20:18:59.087873  1665 net.cpp:380] global_pool -> global_pool
I0405 20:18:59.087944  1665 net.cpp:122] Setting up global_pool
I0405 20:18:59.088019  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 20:18:59.088074  1665 net.cpp:137] Memory required for data: 1114318000
I0405 20:18:59.088127  1665 layer_factory.hpp:77] Creating layer score
I0405 20:18:59.088183  1665 net.cpp:84] Creating Layer score
I0405 20:18:59.088258  1665 net.cpp:406] score <- global_pool
I0405 20:18:59.088320  1665 net.cpp:380] score -> score
I0405 20:18:59.089757  1665 net.cpp:122] Setting up score
I0405 20:18:59.089857  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:18:59.089917  1665 net.cpp:137] Memory required for data: 1114718000
I0405 20:18:59.089984  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 20:18:59.090037  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 20:18:59.090090  1665 net.cpp:406] score_score_0_split <- score
I0405 20:18:59.090143  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 20:18:59.090196  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 20:18:59.090272  1665 net.cpp:122] Setting up score_score_0_split
I0405 20:18:59.090337  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:18:59.090387  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:18:59.090437  1665 net.cpp:137] Memory required for data: 1115518000
I0405 20:18:59.090487  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:18:59.090536  1665 net.cpp:84] Creating Layer loss
I0405 20:18:59.090587  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 20:18:59.090636  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 20:18:59.090696  1665 net.cpp:380] loss -> loss
I0405 20:18:59.090762  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:18:59.091925  1665 net.cpp:122] Setting up loss
I0405 20:18:59.092022  1665 net.cpp:129] Top shape: (1)
I0405 20:18:59.092085  1665 net.cpp:132]     with loss weight 1
I0405 20:18:59.092139  1665 net.cpp:137] Memory required for data: 1115518004
I0405 20:18:59.092186  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 20:18:59.092242  1665 net.cpp:84] Creating Layer accuracy
I0405 20:18:59.092293  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 20:18:59.092350  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 20:18:59.092401  1665 net.cpp:380] accuracy -> accuracy
I0405 20:18:59.092458  1665 net.cpp:122] Setting up accuracy
I0405 20:18:59.092510  1665 net.cpp:129] Top shape: (1)
I0405 20:18:59.092558  1665 net.cpp:137] Memory required for data: 1115518008
I0405 20:18:59.092607  1665 net.cpp:200] accuracy does not need backward computation.
I0405 20:18:59.092654  1665 net.cpp:198] loss needs backward computation.
I0405 20:18:59.092702  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 20:18:59.092779  1665 net.cpp:198] score needs backward computation.
I0405 20:18:59.092833  1665 net.cpp:198] global_pool needs backward computation.
I0405 20:18:59.092883  1665 net.cpp:198] last_relu needs backward computation.
I0405 20:18:59.092931  1665 net.cpp:198] last_scale needs backward computation.
I0405 20:18:59.092983  1665 net.cpp:198] last_bn needs backward computation.
I0405 20:18:59.093034  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 20:18:59.093082  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 20:18:59.093130  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 20:18:59.093181  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 20:18:59.093231  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 20:18:59.093279  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 20:18:59.093327  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 20:18:59.093375  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 20:18:59.093425  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 20:18:59.093472  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 20:18:59.093520  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 20:18:59.093569  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 20:18:59.093617  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 20:18:59.093667  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 20:18:59.093724  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 20:18:59.093771  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 20:18:59.093822  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 20:18:59.093868  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 20:18:59.093915  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 20:18:59.093966  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 20:18:59.094022  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 20:18:59.094070  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 20:18:59.094118  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 20:18:59.094166  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 20:18:59.094216  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 20:18:59.094308  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 20:18:59.094355  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 20:18:59.094413  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 20:18:59.094461  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 20:18:59.094511  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 20:18:59.094558  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 20:18:59.094605  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 20:18:59.094651  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 20:18:59.094698  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 20:18:59.094769  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 20:18:59.094818  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 20:18:59.094868  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 20:18:59.094915  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 20:18:59.094966  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 20:18:59.095026  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 20:18:59.095077  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 20:18:59.095141  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 20:18:59.095193  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 20:18:59.095245  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 20:18:59.095299  1665 net.cpp:198] conv1 needs backward computation.
I0405 20:18:59.095347  1665 net.cpp:198] data_scale needs backward computation.
I0405 20:18:59.095396  1665 net.cpp:200] data_bn does not need backward computation.
I0405 20:18:59.095449  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 20:18:59.095494  1665 net.cpp:200] data does not need backward computation.
I0405 20:18:59.095541  1665 net.cpp:242] This network produces output accuracy
I0405 20:18:59.095592  1665 net.cpp:242] This network produces output loss
I0405 20:18:59.095664  1665 net.cpp:255] Network initialization done.
I0405 20:19:24.947423  1665 blocking_queue.cpp:49] Waiting for data
I0405 20:19:39.421636  1665 solver.cpp:44] Initializing solver from parameters: 
test_iter: 0
test_interval: 469
base_lr: 0.001
display: 225
max_iter: 1800
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 1800
snapshot_prefix: "data/snapshots/train_batch_07"
solver_mode: GPU
random_seed: 0
net: "confs/sII/mid-caffeNet/inc_train_val.prototxt"
test_initialization: false
snapshot_format: HDF5
I0405 20:19:39.425799  1665 solver.cpp:87] Creating training net from net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 20:19:39.426741  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 20:19:39.426818  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 20:19:39.426987  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0405 20:19:39.427062  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0405 20:19:39.427306  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/train_batch_07_filelist.txt"
    batch_size: 256
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I0405 20:19:39.427534  1665 layer_factory.hpp:77] Creating layer data
I0405 20:19:39.427589  1665 net.cpp:84] Creating Layer data
I0405 20:19:39.427628  1665 net.cpp:380] data -> data
I0405 20:19:39.427668  1665 net.cpp:380] data -> label
I0405 20:19:39.427712  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/train_batch_07_filelist.txt
I0405 20:19:39.443869  1665 image_data_layer.cpp:53] Shuffling data
I0405 20:19:39.446841  1665 image_data_layer.cpp:63] A total of 107901 images.
I0405 20:19:39.449025  1665 image_data_layer.cpp:90] output data size: 256,3,128,128
I0405 20:19:39.578050  1665 net.cpp:122] Setting up data
I0405 20:19:39.578285  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 20:19:39.578368  1665 net.cpp:129] Top shape: 256 (256)
I0405 20:19:39.578428  1665 net.cpp:137] Memory required for data: 50332672
I0405 20:19:39.578490  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 20:19:39.578560  1665 net.cpp:84] Creating Layer data_bn
I0405 20:19:39.578620  1665 net.cpp:406] data_bn <- data
I0405 20:19:39.578687  1665 net.cpp:380] data_bn -> data_bn
I0405 20:19:39.579023  1665 net.cpp:122] Setting up data_bn
I0405 20:19:39.579124  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 20:19:39.579185  1665 net.cpp:137] Memory required for data: 100664320
I0405 20:19:39.579255  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:19:39.579321  1665 net.cpp:84] Creating Layer data_scale
I0405 20:19:39.579380  1665 net.cpp:406] data_scale <- data_bn
I0405 20:19:39.579442  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 20:19:39.584641  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:19:39.584857  1665 net.cpp:122] Setting up data_scale
I0405 20:19:39.584960  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 20:19:39.585055  1665 net.cpp:137] Memory required for data: 150995968
I0405 20:19:39.585122  1665 layer_factory.hpp:77] Creating layer conv1
I0405 20:19:39.585191  1665 net.cpp:84] Creating Layer conv1
I0405 20:19:39.585253  1665 net.cpp:406] conv1 <- data_bn
I0405 20:19:39.585315  1665 net.cpp:380] conv1 -> conv1
I0405 20:19:39.585690  1665 net.cpp:122] Setting up conv1
I0405 20:19:39.585798  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 20:19:39.585853  1665 net.cpp:137] Memory required for data: 419431424
I0405 20:19:39.585911  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 20:19:39.585966  1665 net.cpp:84] Creating Layer conv1_bn
I0405 20:19:39.586019  1665 net.cpp:406] conv1_bn <- conv1
I0405 20:19:39.586073  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 20:19:39.586284  1665 net.cpp:122] Setting up conv1_bn
I0405 20:19:39.586372  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 20:19:39.586458  1665 net.cpp:137] Memory required for data: 687866880
I0405 20:19:39.586530  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:19:39.586591  1665 net.cpp:84] Creating Layer conv1_scale
I0405 20:19:39.586644  1665 net.cpp:406] conv1_scale <- conv1
I0405 20:19:39.586699  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 20:19:39.586824  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:19:39.587016  1665 net.cpp:122] Setting up conv1_scale
I0405 20:19:39.587091  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 20:19:39.587152  1665 net.cpp:137] Memory required for data: 956302336
I0405 20:19:39.587220  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 20:19:39.587289  1665 net.cpp:84] Creating Layer conv1_relu
I0405 20:19:39.587339  1665 net.cpp:406] conv1_relu <- conv1
I0405 20:19:39.587400  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 20:19:39.587461  1665 net.cpp:122] Setting up conv1_relu
I0405 20:19:39.587528  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 20:19:39.587589  1665 net.cpp:137] Memory required for data: 1224737792
I0405 20:19:39.587647  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 20:19:39.587710  1665 net.cpp:84] Creating Layer conv1_pool
I0405 20:19:39.587782  1665 net.cpp:406] conv1_pool <- conv1
I0405 20:19:39.587842  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 20:19:39.587958  1665 net.cpp:122] Setting up conv1_pool
I0405 20:19:39.588049  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:19:39.588116  1665 net.cpp:137] Memory required for data: 1291846656
I0405 20:19:39.588179  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 20:19:39.588255  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 20:19:39.588321  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 20:19:39.588383  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 20:19:39.588454  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 20:19:39.588557  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 20:19:39.588625  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:19:39.588690  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:19:39.588773  1665 net.cpp:137] Memory required for data: 1426064384
I0405 20:19:39.588835  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 20:19:39.588905  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 20:19:39.588968  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 20:19:39.589038  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 20:19:39.589587  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 20:19:39.589704  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:19:39.589797  1665 net.cpp:137] Memory required for data: 1493173248
I0405 20:19:39.589857  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 20:19:39.589918  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 20:19:39.589977  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 20:19:39.590041  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 20:19:39.590257  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 20:19:39.590335  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:19:39.590387  1665 net.cpp:137] Memory required for data: 1560282112
I0405 20:19:39.590445  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:19:39.590533  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 20:19:39.590586  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 20:19:39.590641  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 20:19:39.590749  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:19:39.590906  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 20:19:39.590991  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:19:39.591058  1665 net.cpp:137] Memory required for data: 1627390976
I0405 20:19:39.591140  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 20:19:39.591208  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 20:19:39.591267  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 20:19:39.591352  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 20:19:39.591410  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 20:19:39.591471  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:19:39.591531  1665 net.cpp:137] Memory required for data: 1694499840
I0405 20:19:39.591593  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 20:19:39.591657  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 20:19:39.591725  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 20:19:39.591789  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 20:19:39.592356  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 20:19:39.592461  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:19:39.592538  1665 net.cpp:137] Memory required for data: 1761608704
I0405 20:19:39.592597  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 20:19:39.592665  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 20:19:39.592754  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 20:19:39.592820  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 20:19:39.592885  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 20:19:39.592977  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 20:19:39.593048  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:19:39.593124  1665 net.cpp:137] Memory required for data: 1828717568
I0405 20:19:39.593183  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 20:19:39.593250  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 20:19:39.593320  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 20:19:39.593394  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 20:19:39.593612  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 20:19:39.593698  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:19:39.593796  1665 net.cpp:137] Memory required for data: 1895826432
I0405 20:19:39.593864  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:19:39.593933  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 20:19:39.594022  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 20:19:39.594074  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 20:19:39.594172  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:19:39.594346  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 20:19:39.594434  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:19:39.594494  1665 net.cpp:137] Memory required for data: 1962935296
I0405 20:19:39.594554  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 20:19:39.594648  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 20:19:39.594709  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 20:19:39.594799  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 20:19:39.594880  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 20:19:39.594930  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:19:39.595001  1665 net.cpp:137] Memory required for data: 2030044160
I0405 20:19:39.595068  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:19:39.595134  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:19:39.595181  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 20:19:39.595243  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:19:39.595304  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:19:39.595399  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:19:39.595464  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:19:39.595530  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:19:39.595590  1665 net.cpp:137] Memory required for data: 2164261888
I0405 20:19:39.595652  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 20:19:39.595727  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 20:19:39.595788  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:19:39.595854  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 20:19:39.596855  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 20:19:39.596963  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:19:39.597043  1665 net.cpp:137] Memory required for data: 2197816320
I0405 20:19:39.597115  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 20:19:39.597189  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 20:19:39.597261  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 20:19:39.597334  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 20:19:39.597577  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 20:19:39.597662  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:19:39.597767  1665 net.cpp:137] Memory required for data: 2231370752
I0405 20:19:39.597853  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:19:39.597923  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 20:19:39.597985  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 20:19:39.598146  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 20:19:39.598255  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:19:39.598429  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 20:19:39.598515  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:19:39.598598  1665 net.cpp:137] Memory required for data: 2264925184
I0405 20:19:39.598672  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 20:19:39.598762  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 20:19:39.598832  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 20:19:39.598903  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 20:19:39.598975  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 20:19:39.599050  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:19:39.599119  1665 net.cpp:137] Memory required for data: 2298479616
I0405 20:19:39.599189  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 20:19:39.599284  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 20:19:39.599370  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 20:19:39.599436  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 20:19:39.601016  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 20:19:39.601152  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:19:39.601233  1665 net.cpp:137] Memory required for data: 2332034048
I0405 20:19:39.601317  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 20:19:39.601400  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 20:19:39.601478  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:19:39.601552  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 20:19:39.601866  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 20:19:39.602001  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:19:39.602087  1665 net.cpp:137] Memory required for data: 2365588480
I0405 20:19:39.602157  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 20:19:39.602238  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 20:19:39.602316  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 20:19:39.602385  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 20:19:39.602453  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 20:19:39.602555  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 20:19:39.602643  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:19:39.602710  1665 net.cpp:137] Memory required for data: 2399142912
I0405 20:19:39.602825  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 20:19:39.602900  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 20:19:39.602977  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 20:19:39.603047  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 20:19:39.603266  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 20:19:39.603355  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:19:39.603418  1665 net.cpp:137] Memory required for data: 2432697344
I0405 20:19:39.603488  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:19:39.603559  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 20:19:39.603624  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 20:19:39.603734  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 20:19:39.603854  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:19:39.604034  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 20:19:39.604127  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:19:39.604194  1665 net.cpp:137] Memory required for data: 2466251776
I0405 20:19:39.604264  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 20:19:39.604346  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 20:19:39.604413  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 20:19:39.604481  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 20:19:39.604581  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 20:19:39.604652  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:19:39.604722  1665 net.cpp:137] Memory required for data: 2499806208
I0405 20:19:39.604800  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:19:39.604868  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:19:39.604944  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 20:19:39.605021  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:19:39.605084  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:19:39.605173  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:19:39.605238  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:19:39.605299  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:19:39.605408  1665 net.cpp:137] Memory required for data: 2566915072
I0405 20:19:39.605486  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 20:19:39.605563  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 20:19:39.605651  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:19:39.605705  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 20:19:39.609455  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 20:19:39.609551  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:19:39.609606  1665 net.cpp:137] Memory required for data: 2583692288
I0405 20:19:39.609661  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 20:19:39.609735  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 20:19:39.609791  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 20:19:39.609845  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 20:19:39.610059  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 20:19:39.610152  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:19:39.610206  1665 net.cpp:137] Memory required for data: 2600469504
I0405 20:19:39.610263  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:19:39.610328  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 20:19:39.610383  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 20:19:39.610435  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 20:19:39.610520  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:19:39.610659  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 20:19:39.610764  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:19:39.610816  1665 net.cpp:137] Memory required for data: 2617246720
I0405 20:19:39.610870  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 20:19:39.610929  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 20:19:39.610985  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 20:19:39.611043  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 20:19:39.611104  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 20:19:39.611158  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:19:39.611210  1665 net.cpp:137] Memory required for data: 2634023936
I0405 20:19:39.611261  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 20:19:39.611318  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 20:19:39.611371  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 20:19:39.611424  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 20:19:39.617772  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 20:19:39.617882  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:19:39.617950  1665 net.cpp:137] Memory required for data: 2650801152
I0405 20:19:39.618034  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 20:19:39.618096  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 20:19:39.618157  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:19:39.618224  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 20:19:39.618685  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 20:19:39.618810  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:19:39.618861  1665 net.cpp:137] Memory required for data: 2667578368
I0405 20:19:39.618968  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 20:19:39.619103  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 20:19:39.619163  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 20:19:39.619217  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 20:19:39.619272  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 20:19:39.619362  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 20:19:39.619421  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:19:39.619474  1665 net.cpp:137] Memory required for data: 2684355584
I0405 20:19:39.619534  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 20:19:39.619590  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 20:19:39.619654  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 20:19:39.619709  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 20:19:39.619984  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 20:19:39.620064  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:19:39.620126  1665 net.cpp:137] Memory required for data: 2701132800
I0405 20:19:39.620182  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:19:39.620242  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 20:19:39.620296  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 20:19:39.620357  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 20:19:39.620443  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:19:39.620600  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 20:19:39.620689  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:19:39.620774  1665 net.cpp:137] Memory required for data: 2717910016
I0405 20:19:39.620837  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 20:19:39.620894  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 20:19:39.620946  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 20:19:39.621001  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 20:19:39.621057  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 20:19:39.621127  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:19:39.621182  1665 net.cpp:137] Memory required for data: 2734687232
I0405 20:19:39.621234  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:19:39.621292  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:19:39.621349  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 20:19:39.621405  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:19:39.621460  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:19:39.621568  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:19:39.621628  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:19:39.621682  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:19:39.621744  1665 net.cpp:137] Memory required for data: 2768241664
I0405 20:19:39.621796  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 20:19:39.621855  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 20:19:39.621907  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:19:39.621963  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 20:19:39.634678  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 20:19:39.634841  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:19:39.634919  1665 net.cpp:137] Memory required for data: 2776630272
I0405 20:19:39.634980  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 20:19:39.635047  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 20:19:39.635104  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 20:19:39.635179  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 20:19:39.635385  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 20:19:39.635458  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:19:39.635514  1665 net.cpp:137] Memory required for data: 2785018880
I0405 20:19:39.635572  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:19:39.635630  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 20:19:39.635687  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 20:19:39.635753  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 20:19:39.635833  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:19:39.635967  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 20:19:39.636029  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:19:39.636081  1665 net.cpp:137] Memory required for data: 2793407488
I0405 20:19:39.636134  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 20:19:39.636193  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 20:19:39.636253  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 20:19:39.636317  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 20:19:39.636374  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 20:19:39.636431  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:19:39.636485  1665 net.cpp:137] Memory required for data: 2801796096
I0405 20:19:39.636538  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 20:19:39.636597  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 20:19:39.636656  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 20:19:39.636709  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 20:19:39.658735  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 20:19:39.658887  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:19:39.658954  1665 net.cpp:137] Memory required for data: 2810184704
I0405 20:19:39.659013  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 20:19:39.659085  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 20:19:39.659153  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:19:39.659214  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 20:19:39.660435  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 20:19:39.660528  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:19:39.660599  1665 net.cpp:137] Memory required for data: 2818573312
I0405 20:19:39.660657  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 20:19:39.660737  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 20:19:39.660790  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 20:19:39.660848  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 20:19:39.660903  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 20:19:39.660972  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 20:19:39.661044  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:19:39.661118  1665 net.cpp:137] Memory required for data: 2826961920
I0405 20:19:39.661191  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 20:19:39.661247  1665 net.cpp:84] Creating Layer last_bn
I0405 20:19:39.661301  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 20:19:39.661356  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 20:19:39.661550  1665 net.cpp:122] Setting up last_bn
I0405 20:19:39.661619  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:19:39.661674  1665 net.cpp:137] Memory required for data: 2835350528
I0405 20:19:39.661763  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:19:39.661824  1665 net.cpp:84] Creating Layer last_scale
I0405 20:19:39.661880  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 20:19:39.661936  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 20:19:39.662016  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:19:39.662151  1665 net.cpp:122] Setting up last_scale
I0405 20:19:39.662210  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:19:39.662262  1665 net.cpp:137] Memory required for data: 2843739136
I0405 20:19:39.662317  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 20:19:39.662374  1665 net.cpp:84] Creating Layer last_relu
I0405 20:19:39.662427  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 20:19:39.662484  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 20:19:39.662542  1665 net.cpp:122] Setting up last_relu
I0405 20:19:39.662597  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:19:39.662650  1665 net.cpp:137] Memory required for data: 2852127744
I0405 20:19:39.662706  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 20:19:39.662775  1665 net.cpp:84] Creating Layer global_pool
I0405 20:19:39.662833  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 20:19:39.662887  1665 net.cpp:380] global_pool -> global_pool
I0405 20:19:39.662961  1665 net.cpp:122] Setting up global_pool
I0405 20:19:39.663017  1665 net.cpp:129] Top shape: 256 512 1 1 (131072)
I0405 20:19:39.663084  1665 net.cpp:137] Memory required for data: 2852652032
I0405 20:19:39.663138  1665 layer_factory.hpp:77] Creating layer score
I0405 20:19:39.663203  1665 net.cpp:84] Creating Layer score
I0405 20:19:39.663254  1665 net.cpp:406] score <- global_pool
I0405 20:19:39.663314  1665 net.cpp:380] score -> score
I0405 20:19:39.664652  1665 net.cpp:122] Setting up score
I0405 20:19:39.664779  1665 net.cpp:129] Top shape: 256 1000 (256000)
I0405 20:19:39.664846  1665 net.cpp:137] Memory required for data: 2853676032
I0405 20:19:39.664898  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:19:39.664952  1665 net.cpp:84] Creating Layer loss
I0405 20:19:39.665012  1665 net.cpp:406] loss <- score
I0405 20:19:39.665078  1665 net.cpp:406] loss <- label
I0405 20:19:39.665132  1665 net.cpp:380] loss -> loss
I0405 20:19:39.665187  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:19:39.666381  1665 net.cpp:122] Setting up loss
I0405 20:19:39.666468  1665 net.cpp:129] Top shape: (1)
I0405 20:19:39.666534  1665 net.cpp:132]     with loss weight 1
I0405 20:19:39.666595  1665 net.cpp:137] Memory required for data: 2853676036
I0405 20:19:39.666641  1665 net.cpp:198] loss needs backward computation.
I0405 20:19:39.666693  1665 net.cpp:198] score needs backward computation.
I0405 20:19:39.666766  1665 net.cpp:198] global_pool needs backward computation.
I0405 20:19:39.666826  1665 net.cpp:198] last_relu needs backward computation.
I0405 20:19:39.666877  1665 net.cpp:198] last_scale needs backward computation.
I0405 20:19:39.666924  1665 net.cpp:198] last_bn needs backward computation.
I0405 20:19:39.666972  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 20:19:39.667021  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 20:19:39.667076  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 20:19:39.667129  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 20:19:39.667179  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 20:19:39.667227  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 20:19:39.667274  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 20:19:39.667322  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 20:19:39.667374  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 20:19:39.667426  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 20:19:39.667477  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 20:19:39.667529  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 20:19:39.667593  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 20:19:39.667640  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 20:19:39.667690  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 20:19:39.667743  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 20:19:39.667793  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 20:19:39.667853  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 20:19:39.667910  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 20:19:39.667968  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 20:19:39.668018  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 20:19:39.668071  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 20:19:39.668120  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 20:19:39.668169  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 20:19:39.668216  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 20:19:39.668264  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 20:19:39.668305  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 20:19:39.668354  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 20:19:39.668409  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 20:19:39.668462  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 20:19:39.668509  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 20:19:39.668558  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 20:19:39.668606  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 20:19:39.668665  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 20:19:39.668710  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 20:19:39.668771  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 20:19:39.668818  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 20:19:39.668869  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 20:19:39.668917  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 20:19:39.668982  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 20:19:39.669047  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 20:19:39.669098  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 20:19:39.669148  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 20:19:39.669196  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 20:19:39.669243  1665 net.cpp:198] conv1 needs backward computation.
I0405 20:19:39.669292  1665 net.cpp:198] data_scale needs backward computation.
I0405 20:19:39.669344  1665 net.cpp:200] data_bn does not need backward computation.
I0405 20:19:39.669396  1665 net.cpp:200] data does not need backward computation.
I0405 20:19:39.669447  1665 net.cpp:242] This network produces output loss
I0405 20:19:39.669535  1665 net.cpp:255] Network initialization done.
I0405 20:19:39.671038  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 20:19:39.671190  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 20:19:39.671257  1665 solver.cpp:172] Creating test net (#0) specified by net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 20:19:39.671397  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 20:19:39.671689  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 20:19:39.671957  1665 layer_factory.hpp:77] Creating layer data
I0405 20:19:39.672035  1665 net.cpp:84] Creating Layer data
I0405 20:19:39.672087  1665 net.cpp:380] data -> data
I0405 20:19:39.672140  1665 net.cpp:380] data -> label
I0405 20:19:39.672204  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 20:19:39.680388  1665 image_data_layer.cpp:53] Shuffling data
I0405 20:19:39.682842  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 20:19:39.683782  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 20:19:39.729343  1665 net.cpp:122] Setting up data
I0405 20:19:39.729511  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:19:39.729599  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:19:39.729727  1665 net.cpp:137] Memory required for data: 19661200
I0405 20:19:39.729802  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 20:19:39.729876  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 20:19:39.729936  1665 net.cpp:406] label_data_1_split <- label
I0405 20:19:39.730012  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 20:19:39.730093  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 20:19:39.730259  1665 net.cpp:122] Setting up label_data_1_split
I0405 20:19:39.730377  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:19:39.730449  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:19:39.730533  1665 net.cpp:137] Memory required for data: 19662000
I0405 20:19:39.730590  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 20:19:39.730649  1665 net.cpp:84] Creating Layer data_bn
I0405 20:19:39.730703  1665 net.cpp:406] data_bn <- data
I0405 20:19:39.730809  1665 net.cpp:380] data_bn -> data_bn
I0405 20:19:39.732762  1665 net.cpp:122] Setting up data_bn
I0405 20:19:39.732867  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:19:39.732925  1665 net.cpp:137] Memory required for data: 39322800
I0405 20:19:39.732988  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:19:39.733055  1665 net.cpp:84] Creating Layer data_scale
I0405 20:19:39.733112  1665 net.cpp:406] data_scale <- data_bn
I0405 20:19:39.733168  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 20:19:39.733269  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:19:39.733464  1665 net.cpp:122] Setting up data_scale
I0405 20:19:39.733541  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:19:39.733625  1665 net.cpp:137] Memory required for data: 58983600
I0405 20:19:39.733702  1665 layer_factory.hpp:77] Creating layer conv1
I0405 20:19:39.733777  1665 net.cpp:84] Creating Layer conv1
I0405 20:19:39.733834  1665 net.cpp:406] conv1 <- data_bn
I0405 20:19:39.733891  1665 net.cpp:380] conv1 -> conv1
I0405 20:19:39.734334  1665 net.cpp:122] Setting up conv1
I0405 20:19:39.734453  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:19:39.734515  1665 net.cpp:137] Memory required for data: 163841200
I0405 20:19:39.734576  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 20:19:39.734633  1665 net.cpp:84] Creating Layer conv1_bn
I0405 20:19:39.734688  1665 net.cpp:406] conv1_bn <- conv1
I0405 20:19:39.734777  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 20:19:39.735056  1665 net.cpp:122] Setting up conv1_bn
I0405 20:19:39.735131  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:19:39.735193  1665 net.cpp:137] Memory required for data: 268698800
I0405 20:19:39.735261  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:19:39.735318  1665 net.cpp:84] Creating Layer conv1_scale
I0405 20:19:39.735370  1665 net.cpp:406] conv1_scale <- conv1
I0405 20:19:39.735430  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 20:19:39.735553  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:19:39.735735  1665 net.cpp:122] Setting up conv1_scale
I0405 20:19:39.735808  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:19:39.735872  1665 net.cpp:137] Memory required for data: 373556400
I0405 20:19:39.735937  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 20:19:39.736008  1665 net.cpp:84] Creating Layer conv1_relu
I0405 20:19:39.736078  1665 net.cpp:406] conv1_relu <- conv1
I0405 20:19:39.736142  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 20:19:39.736207  1665 net.cpp:122] Setting up conv1_relu
I0405 20:19:39.736284  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:19:39.736346  1665 net.cpp:137] Memory required for data: 478414000
I0405 20:19:39.736407  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 20:19:39.736471  1665 net.cpp:84] Creating Layer conv1_pool
I0405 20:19:39.736531  1665 net.cpp:406] conv1_pool <- conv1
I0405 20:19:39.736599  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 20:19:39.736706  1665 net.cpp:122] Setting up conv1_pool
I0405 20:19:39.736801  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:19:39.736866  1665 net.cpp:137] Memory required for data: 504628400
I0405 20:19:39.736937  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 20:19:39.737001  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 20:19:39.737082  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 20:19:39.737148  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 20:19:39.737213  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 20:19:39.737318  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 20:19:39.737386  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:19:39.737449  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:19:39.737509  1665 net.cpp:137] Memory required for data: 557057200
I0405 20:19:39.737576  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 20:19:39.737651  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 20:19:39.737725  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 20:19:39.737794  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 20:19:39.738528  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 20:19:39.738621  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:19:39.738678  1665 net.cpp:137] Memory required for data: 583271600
I0405 20:19:39.738759  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 20:19:39.738828  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 20:19:39.738889  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 20:19:39.738955  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 20:19:39.739205  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 20:19:39.739269  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:19:39.739332  1665 net.cpp:137] Memory required for data: 609486000
I0405 20:19:39.739398  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:19:39.739468  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 20:19:39.739527  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 20:19:39.739594  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 20:19:39.739698  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:19:39.739889  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 20:19:39.739969  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:19:39.740044  1665 net.cpp:137] Memory required for data: 635700400
I0405 20:19:39.740113  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 20:19:39.740178  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 20:19:39.740236  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 20:19:39.740324  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 20:19:39.740388  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 20:19:39.740451  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:19:39.740514  1665 net.cpp:137] Memory required for data: 661914800
I0405 20:19:39.740573  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 20:19:39.740643  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 20:19:39.740707  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 20:19:39.740779  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 20:19:39.741499  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 20:19:39.741578  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:19:39.741647  1665 net.cpp:137] Memory required for data: 688129200
I0405 20:19:39.741726  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 20:19:39.741788  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 20:19:39.741842  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 20:19:39.741899  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 20:19:39.741986  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 20:19:39.742069  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 20:19:39.742127  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:19:39.742209  1665 net.cpp:137] Memory required for data: 714343600
I0405 20:19:39.742264  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 20:19:39.742329  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 20:19:39.742383  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 20:19:39.742460  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 20:19:39.742755  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 20:19:39.742833  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:19:39.742895  1665 net.cpp:137] Memory required for data: 740558000
I0405 20:19:39.742960  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:19:39.743024  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 20:19:39.743088  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 20:19:39.743156  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 20:19:39.743283  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:19:39.743454  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 20:19:39.743516  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:19:39.743589  1665 net.cpp:137] Memory required for data: 766772400
I0405 20:19:39.743666  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 20:19:39.743746  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 20:19:39.743811  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 20:19:39.743873  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 20:19:39.743933  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 20:19:39.743993  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:19:39.744060  1665 net.cpp:137] Memory required for data: 792986800
I0405 20:19:39.744120  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:19:39.744182  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:19:39.744254  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 20:19:39.744318  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:19:39.744381  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:19:39.744475  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:19:39.744537  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:19:39.744596  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:19:39.744666  1665 net.cpp:137] Memory required for data: 845415600
I0405 20:19:39.744725  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 20:19:39.744798  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 20:19:39.744859  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:19:39.744921  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 20:19:39.746119  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 20:19:39.746219  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:19:39.746273  1665 net.cpp:137] Memory required for data: 858522800
I0405 20:19:39.746348  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 20:19:39.746404  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 20:19:39.746464  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 20:19:39.746523  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 20:19:39.746783  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 20:19:39.746857  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:19:39.746912  1665 net.cpp:137] Memory required for data: 871630000
I0405 20:19:39.746970  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:19:39.747027  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 20:19:39.747082  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 20:19:39.747139  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 20:19:39.747231  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:19:39.747391  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 20:19:39.747524  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:19:39.747576  1665 net.cpp:137] Memory required for data: 884737200
I0405 20:19:39.747637  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 20:19:39.747695  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 20:19:39.747779  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 20:19:39.747839  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 20:19:39.747900  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 20:19:39.747964  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:19:39.748025  1665 net.cpp:137] Memory required for data: 897844400
I0405 20:19:39.748091  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 20:19:39.748158  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 20:19:39.748220  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 20:19:39.748294  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 20:19:39.750468  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 20:19:39.750591  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:19:39.750658  1665 net.cpp:137] Memory required for data: 910951600
I0405 20:19:39.750728  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 20:19:39.750799  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 20:19:39.750865  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:19:39.750963  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 20:19:39.751350  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 20:19:39.751449  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:19:39.751523  1665 net.cpp:137] Memory required for data: 924058800
I0405 20:19:39.751593  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 20:19:39.751667  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 20:19:39.751757  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 20:19:39.751844  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 20:19:39.751915  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 20:19:39.752027  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 20:19:39.752544  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:19:39.752636  1665 net.cpp:137] Memory required for data: 937166000
I0405 20:19:39.752701  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 20:19:39.752804  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 20:19:39.752924  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 20:19:39.753012  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 20:19:39.753309  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 20:19:39.753405  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:19:39.753471  1665 net.cpp:137] Memory required for data: 950273200
I0405 20:19:39.753545  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:19:39.753628  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 20:19:39.753686  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 20:19:39.753782  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 20:19:39.753882  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:19:39.754068  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 20:19:39.754138  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:19:39.754202  1665 net.cpp:137] Memory required for data: 963380400
I0405 20:19:39.754266  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 20:19:39.754328  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 20:19:39.754388  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 20:19:39.754449  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 20:19:39.754511  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 20:19:39.754572  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:19:39.754645  1665 net.cpp:137] Memory required for data: 976487600
I0405 20:19:39.754703  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:19:39.754791  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:19:39.754851  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 20:19:39.754920  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:19:39.755008  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:19:39.755129  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:19:39.755229  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:19:39.755285  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:19:39.755342  1665 net.cpp:137] Memory required for data: 1002702000
I0405 20:19:39.755407  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 20:19:39.755475  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 20:19:39.755540  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:19:39.755606  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 20:19:39.760919  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 20:19:39.761010  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:19:39.761101  1665 net.cpp:137] Memory required for data: 1009255600
I0405 20:19:39.761170  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 20:19:39.761238  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 20:19:39.761296  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 20:19:39.761356  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 20:19:39.761627  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 20:19:39.761729  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:19:39.761787  1665 net.cpp:137] Memory required for data: 1015809200
I0405 20:19:39.761860  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:19:39.761919  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 20:19:39.761974  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 20:19:39.762040  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 20:19:39.762145  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:19:39.762305  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 20:19:39.762377  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:19:39.762432  1665 net.cpp:137] Memory required for data: 1022362800
I0405 20:19:39.762490  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 20:19:39.762547  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 20:19:39.762603  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 20:19:39.762662  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 20:19:39.762735  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 20:19:39.762794  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:19:39.762848  1665 net.cpp:137] Memory required for data: 1028916400
I0405 20:19:39.762908  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 20:19:39.762974  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 20:19:39.763041  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 20:19:39.763095  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 20:19:39.771922  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 20:19:39.772007  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:19:39.772069  1665 net.cpp:137] Memory required for data: 1035470000
I0405 20:19:39.772125  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 20:19:39.772205  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 20:19:39.772264  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:19:39.772321  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 20:19:39.773015  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 20:19:39.773105  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:19:39.773167  1665 net.cpp:137] Memory required for data: 1042023600
I0405 20:19:39.773228  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 20:19:39.773304  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 20:19:39.773375  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 20:19:39.773432  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 20:19:39.773492  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 20:19:39.773583  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 20:19:39.773638  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:19:39.773695  1665 net.cpp:137] Memory required for data: 1048577200
I0405 20:19:39.773769  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 20:19:39.773831  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 20:19:39.773888  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 20:19:39.773948  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 20:19:39.774212  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 20:19:39.774277  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:19:39.774335  1665 net.cpp:137] Memory required for data: 1055130800
I0405 20:19:39.774394  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:19:39.774453  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 20:19:39.774509  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 20:19:39.774577  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 20:19:39.774675  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:19:39.774863  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 20:19:39.774936  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:19:39.774991  1665 net.cpp:137] Memory required for data: 1061684400
I0405 20:19:39.775053  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 20:19:39.775110  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 20:19:39.775164  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 20:19:39.775220  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 20:19:39.775285  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 20:19:39.775353  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:19:39.775403  1665 net.cpp:137] Memory required for data: 1068238000
I0405 20:19:39.775456  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:19:39.775527  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:19:39.775583  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 20:19:39.775643  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:19:39.775705  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:19:39.775825  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:19:39.775910  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:19:39.775974  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:19:39.776046  1665 net.cpp:137] Memory required for data: 1081345200
I0405 20:19:39.776109  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 20:19:39.776180  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 20:19:39.776254  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:19:39.776316  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 20:19:39.794302  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 20:19:39.794433  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:19:39.794514  1665 net.cpp:137] Memory required for data: 1084622000
I0405 20:19:39.794600  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 20:19:39.794682  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 20:19:39.794785  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 20:19:39.794862  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 20:19:39.795163  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 20:19:39.795259  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:19:39.795337  1665 net.cpp:137] Memory required for data: 1087898800
I0405 20:19:39.795430  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:19:39.795529  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 20:19:39.795610  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 20:19:39.795696  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 20:19:39.795848  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:19:39.796067  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 20:19:39.796145  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:19:39.796231  1665 net.cpp:137] Memory required for data: 1091175600
I0405 20:19:39.796300  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 20:19:39.796376  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 20:19:39.796465  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 20:19:39.796535  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 20:19:39.796604  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 20:19:39.796701  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:19:39.796805  1665 net.cpp:137] Memory required for data: 1094452400
I0405 20:19:39.796885  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 20:19:39.796968  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 20:19:39.797055  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 20:19:39.797137  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 20:19:39.835487  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 20:19:39.835696  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:19:39.835794  1665 net.cpp:137] Memory required for data: 1097729200
I0405 20:19:39.835878  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 20:19:39.835958  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 20:19:39.836041  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:19:39.836122  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 20:19:39.838148  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 20:19:39.838279  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:19:39.838359  1665 net.cpp:137] Memory required for data: 1101006000
I0405 20:19:39.838445  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 20:19:39.838516  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 20:19:39.838589  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 20:19:39.838649  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 20:19:39.838757  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 20:19:39.838871  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 20:19:39.838958  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:19:39.839030  1665 net.cpp:137] Memory required for data: 1104282800
I0405 20:19:39.839099  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 20:19:39.839172  1665 net.cpp:84] Creating Layer last_bn
I0405 20:19:39.839239  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 20:19:39.839309  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 20:19:39.839576  1665 net.cpp:122] Setting up last_bn
I0405 20:19:39.839674  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:19:39.839763  1665 net.cpp:137] Memory required for data: 1107559600
I0405 20:19:39.839836  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:19:39.839922  1665 net.cpp:84] Creating Layer last_scale
I0405 20:19:39.839995  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 20:19:39.840065  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 20:19:39.840188  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:19:39.840376  1665 net.cpp:122] Setting up last_scale
I0405 20:19:39.840459  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:19:39.840559  1665 net.cpp:137] Memory required for data: 1110836400
I0405 20:19:39.840628  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 20:19:39.840696  1665 net.cpp:84] Creating Layer last_relu
I0405 20:19:39.840778  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 20:19:39.840844  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 20:19:39.840904  1665 net.cpp:122] Setting up last_relu
I0405 20:19:39.840975  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:19:39.841039  1665 net.cpp:137] Memory required for data: 1114113200
I0405 20:19:39.841105  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 20:19:39.841181  1665 net.cpp:84] Creating Layer global_pool
I0405 20:19:39.841246  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 20:19:39.841315  1665 net.cpp:380] global_pool -> global_pool
I0405 20:19:39.841418  1665 net.cpp:122] Setting up global_pool
I0405 20:19:39.841487  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 20:19:39.841552  1665 net.cpp:137] Memory required for data: 1114318000
I0405 20:19:39.841625  1665 layer_factory.hpp:77] Creating layer score
I0405 20:19:39.841696  1665 net.cpp:84] Creating Layer score
I0405 20:19:39.841781  1665 net.cpp:406] score <- global_pool
I0405 20:19:39.841866  1665 net.cpp:380] score -> score
I0405 20:19:39.846684  1665 net.cpp:122] Setting up score
I0405 20:19:39.846801  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:19:39.846861  1665 net.cpp:137] Memory required for data: 1114718000
I0405 20:19:39.846937  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 20:19:39.847003  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 20:19:39.847061  1665 net.cpp:406] score_score_0_split <- score
I0405 20:19:39.847121  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 20:19:39.847180  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 20:19:39.847278  1665 net.cpp:122] Setting up score_score_0_split
I0405 20:19:39.847342  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:19:39.847404  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:19:39.847461  1665 net.cpp:137] Memory required for data: 1115518000
I0405 20:19:39.847527  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:19:39.847612  1665 net.cpp:84] Creating Layer loss
I0405 20:19:39.847671  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 20:19:39.847752  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 20:19:39.847815  1665 net.cpp:380] loss -> loss
I0405 20:19:39.847877  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:19:39.853420  1665 net.cpp:122] Setting up loss
I0405 20:19:39.853576  1665 net.cpp:129] Top shape: (1)
I0405 20:19:39.853638  1665 net.cpp:132]     with loss weight 1
I0405 20:19:39.853709  1665 net.cpp:137] Memory required for data: 1115518004
I0405 20:19:39.853792  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 20:19:39.853855  1665 net.cpp:84] Creating Layer accuracy
I0405 20:19:39.853931  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 20:19:39.853997  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 20:19:39.854061  1665 net.cpp:380] accuracy -> accuracy
I0405 20:19:39.854127  1665 net.cpp:122] Setting up accuracy
I0405 20:19:39.854202  1665 net.cpp:129] Top shape: (1)
I0405 20:19:39.854301  1665 net.cpp:137] Memory required for data: 1115518008
I0405 20:19:39.854377  1665 net.cpp:200] accuracy does not need backward computation.
I0405 20:19:39.854439  1665 net.cpp:198] loss needs backward computation.
I0405 20:19:39.854498  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 20:19:39.854562  1665 net.cpp:198] score needs backward computation.
I0405 20:19:39.854620  1665 net.cpp:198] global_pool needs backward computation.
I0405 20:19:39.854682  1665 net.cpp:198] last_relu needs backward computation.
I0405 20:19:39.854753  1665 net.cpp:198] last_scale needs backward computation.
I0405 20:19:39.854811  1665 net.cpp:198] last_bn needs backward computation.
I0405 20:19:39.854869  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 20:19:39.854933  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 20:19:39.855000  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 20:19:39.855067  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 20:19:39.855119  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 20:19:39.855185  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 20:19:39.855259  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 20:19:39.855335  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 20:19:39.855398  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 20:19:39.855459  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 20:19:39.855525  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 20:19:39.855584  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 20:19:39.855643  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 20:19:39.855702  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 20:19:39.855772  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 20:19:39.855831  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 20:19:39.855890  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 20:19:39.855947  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 20:19:39.856009  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 20:19:39.856074  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 20:19:39.856148  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 20:19:39.856199  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 20:19:39.856264  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 20:19:39.856339  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 20:19:39.856400  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 20:19:39.856475  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 20:19:39.856542  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 20:19:39.856602  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 20:19:39.856662  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 20:19:39.856727  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 20:19:39.856798  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 20:19:39.856863  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 20:19:39.856925  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 20:19:39.856987  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 20:19:39.857197  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 20:19:39.857280  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 20:19:39.857411  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 20:19:39.857492  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 20:19:39.857558  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 20:19:39.857619  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 20:19:39.857684  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 20:19:39.857761  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 20:19:39.857823  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 20:19:39.857884  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 20:19:39.857942  1665 net.cpp:198] conv1 needs backward computation.
I0405 20:19:39.858001  1665 net.cpp:198] data_scale needs backward computation.
I0405 20:19:39.858062  1665 net.cpp:200] data_bn does not need backward computation.
I0405 20:19:39.858121  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 20:19:39.858180  1665 net.cpp:200] data does not need backward computation.
I0405 20:19:39.858238  1665 net.cpp:242] This network produces output accuracy
I0405 20:19:39.858296  1665 net.cpp:242] This network produces output loss
I0405 20:19:39.858417  1665 net.cpp:255] Network initialization done.
I0405 20:19:39.858789  1665 solver.cpp:56] Solver scaffolding done.
I0405 20:19:39.898507  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: data/resnet10_cvgj_iter_320000.caffemodel
I0405 20:19:39.898744  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 20:19:40.387899  1665 solver.cpp:218] Iteration 0 (1.60988e-09 iter/s, 0.484776s/225 iters), loss = 12.7532
I0405 20:19:40.388103  1665 solver.cpp:237]     Train net output #0: loss = 12.7532 (* 1 = 12.7532 loss)
I0405 20:19:40.388180  1665 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I0405 20:21:18.958068  1665 solver.cpp:218] Iteration 225 (2.28265 iter/s, 98.5695s/225 iters), loss = 0.638191
I0405 20:21:18.958465  1665 solver.cpp:237]     Train net output #0: loss = 0.638191 (* 1 = 0.638191 loss)
I0405 20:21:18.958550  1665 sgd_solver.cpp:105] Iteration 225, lr = 0.000875
I0405 20:22:57.524696  1665 solver.cpp:218] Iteration 450 (2.28273 iter/s, 98.5661s/225 iters), loss = 0.398144
I0405 20:22:57.525038  1665 solver.cpp:237]     Train net output #0: loss = 0.398144 (* 1 = 0.398144 loss)
I0405 20:22:57.525125  1665 sgd_solver.cpp:105] Iteration 450, lr = 0.00075
I0405 20:23:05.411360  1665 solver.cpp:330] Iteration 469, Testing net (#0)
I0405 20:24:36.100232  1665 solver.cpp:218] Iteration 675 (2.28252 iter/s, 98.5752s/225 iters), loss = 0.287833
I0405 20:24:36.100492  1665 solver.cpp:237]     Train net output #0: loss = 0.287833 (* 1 = 0.287833 loss)
I0405 20:24:36.100620  1665 sgd_solver.cpp:105] Iteration 675, lr = 0.000625
I0405 20:26:14.674870  1665 solver.cpp:218] Iteration 900 (2.28254 iter/s, 98.5746s/225 iters), loss = 0.269259
I0405 20:26:14.675137  1665 solver.cpp:237]     Train net output #0: loss = 0.269259 (* 1 = 0.269259 loss)
I0405 20:26:14.675225  1665 sgd_solver.cpp:105] Iteration 900, lr = 0.0005
I0405 20:26:30.889721  1665 solver.cpp:330] Iteration 938, Testing net (#0)
I0405 20:27:53.257627  1665 solver.cpp:218] Iteration 1125 (2.28234 iter/s, 98.5829s/225 iters), loss = 0.198195
I0405 20:27:53.257957  1665 solver.cpp:237]     Train net output #0: loss = 0.198195 (* 1 = 0.198195 loss)
I0405 20:27:53.258054  1665 sgd_solver.cpp:105] Iteration 1125, lr = 0.000375
I0405 20:29:31.824276  1665 solver.cpp:218] Iteration 1350 (2.28272 iter/s, 98.5668s/225 iters), loss = 0.19064
I0405 20:29:31.824537  1665 solver.cpp:237]     Train net output #0: loss = 0.19064 (* 1 = 0.19064 loss)
I0405 20:29:31.824631  1665 sgd_solver.cpp:105] Iteration 1350, lr = 0.00025
I0405 20:29:56.357297  1665 solver.cpp:330] Iteration 1407, Testing net (#0)
I0405 20:31:10.390370  1665 solver.cpp:218] Iteration 1575 (2.28272 iter/s, 98.5664s/225 iters), loss = 0.170947
I0405 20:31:10.390695  1665 solver.cpp:237]     Train net output #0: loss = 0.170947 (* 1 = 0.170947 loss)
I0405 20:31:10.390774  1665 sgd_solver.cpp:105] Iteration 1575, lr = 0.000125
I0405 20:32:48.518841  1665 solver.cpp:457] Snapshotting to HDF5 file data/snapshots/train_batch_07_iter_1800.caffemodel.h5
I0405 20:32:48.587241  1665 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file data/snapshots/train_batch_07_iter_1800.solverstate.h5
W0405 20:32:51.325137  1665 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W0405 20:32:51.325340  1665 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W0405 20:32:51.325443  1665 _caffe.cpp:142] Net('confs/sII/mid-caffeNet/inc_train_val.prototxt', 1, weights='data/snapshots/train_batch_07_iter_1800.caffemodel.h5')
I0405 20:32:51.329150  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 20:32:51.329311  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 20:32:51.329475  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 20:32:51.329831  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 20:32:51.330133  1665 layer_factory.hpp:77] Creating layer data
I0405 20:32:51.330231  1665 net.cpp:84] Creating Layer data
I0405 20:32:51.330303  1665 net.cpp:380] data -> data
I0405 20:32:51.330366  1665 net.cpp:380] data -> label
I0405 20:32:51.330435  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 20:32:51.338938  1665 image_data_layer.cpp:53] Shuffling data
I0405 20:32:51.340046  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 20:32:51.341090  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 20:32:51.390425  1665 net.cpp:122] Setting up data
I0405 20:32:51.390657  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:32:51.390765  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:32:51.390828  1665 net.cpp:137] Memory required for data: 19661200
I0405 20:32:51.390890  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 20:32:51.390985  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 20:32:51.391048  1665 net.cpp:406] label_data_1_split <- label
I0405 20:32:51.391157  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 20:32:51.391234  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 20:32:51.391346  1665 net.cpp:122] Setting up label_data_1_split
I0405 20:32:51.391449  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:32:51.391513  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:32:51.391572  1665 net.cpp:137] Memory required for data: 19662000
I0405 20:32:51.391633  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 20:32:51.391703  1665 net.cpp:84] Creating Layer data_bn
I0405 20:32:51.391774  1665 net.cpp:406] data_bn <- data
I0405 20:32:51.391849  1665 net.cpp:380] data_bn -> data_bn
I0405 20:32:51.394189  1665 net.cpp:122] Setting up data_bn
I0405 20:32:51.394311  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:32:51.394387  1665 net.cpp:137] Memory required for data: 39322800
I0405 20:32:51.394467  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:32:51.394541  1665 net.cpp:84] Creating Layer data_scale
I0405 20:32:51.394603  1665 net.cpp:406] data_scale <- data_bn
I0405 20:32:51.394697  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 20:32:51.394834  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:32:51.395064  1665 net.cpp:122] Setting up data_scale
I0405 20:32:51.395148  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:32:51.395207  1665 net.cpp:137] Memory required for data: 58983600
I0405 20:32:51.395268  1665 layer_factory.hpp:77] Creating layer conv1
I0405 20:32:51.395336  1665 net.cpp:84] Creating Layer conv1
I0405 20:32:51.395404  1665 net.cpp:406] conv1 <- data_bn
I0405 20:32:51.395471  1665 net.cpp:380] conv1 -> conv1
I0405 20:32:51.395869  1665 net.cpp:122] Setting up conv1
I0405 20:32:51.395963  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:32:51.396026  1665 net.cpp:137] Memory required for data: 163841200
I0405 20:32:51.396091  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 20:32:51.396175  1665 net.cpp:84] Creating Layer conv1_bn
I0405 20:32:51.396236  1665 net.cpp:406] conv1_bn <- conv1
I0405 20:32:51.396299  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 20:32:51.396519  1665 net.cpp:122] Setting up conv1_bn
I0405 20:32:51.396603  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:32:51.396664  1665 net.cpp:137] Memory required for data: 268698800
I0405 20:32:51.396785  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:32:51.396852  1665 net.cpp:84] Creating Layer conv1_scale
I0405 20:32:51.396919  1665 net.cpp:406] conv1_scale <- conv1
I0405 20:32:51.396994  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 20:32:51.397095  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:32:51.397256  1665 net.cpp:122] Setting up conv1_scale
I0405 20:32:51.397351  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:32:51.397405  1665 net.cpp:137] Memory required for data: 373556400
I0405 20:32:51.397469  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 20:32:51.397539  1665 net.cpp:84] Creating Layer conv1_relu
I0405 20:32:51.397595  1665 net.cpp:406] conv1_relu <- conv1
I0405 20:32:51.397653  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 20:32:51.397723  1665 net.cpp:122] Setting up conv1_relu
I0405 20:32:51.397791  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:32:51.397850  1665 net.cpp:137] Memory required for data: 478414000
I0405 20:32:51.397914  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 20:32:51.397980  1665 net.cpp:84] Creating Layer conv1_pool
I0405 20:32:51.398061  1665 net.cpp:406] conv1_pool <- conv1
I0405 20:32:51.398123  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 20:32:51.398227  1665 net.cpp:122] Setting up conv1_pool
I0405 20:32:51.398298  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:32:51.398360  1665 net.cpp:137] Memory required for data: 504628400
I0405 20:32:51.398424  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 20:32:51.398488  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 20:32:51.398548  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 20:32:51.398609  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 20:32:51.398672  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 20:32:51.398838  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 20:32:51.398916  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:32:51.398978  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:32:51.399039  1665 net.cpp:137] Memory required for data: 557057200
I0405 20:32:51.399099  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 20:32:51.399166  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 20:32:51.399227  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 20:32:51.399291  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 20:32:51.399888  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 20:32:51.399981  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:32:51.400043  1665 net.cpp:137] Memory required for data: 583271600
I0405 20:32:51.400104  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 20:32:51.400167  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 20:32:51.400228  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 20:32:51.400291  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 20:32:51.400506  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 20:32:51.400599  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:32:51.400667  1665 net.cpp:137] Memory required for data: 609486000
I0405 20:32:51.400744  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:32:51.400808  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 20:32:51.400868  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 20:32:51.400930  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 20:32:51.401033  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:32:51.401209  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 20:32:51.401279  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:32:51.401347  1665 net.cpp:137] Memory required for data: 635700400
I0405 20:32:51.401414  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 20:32:51.401475  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 20:32:51.401536  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 20:32:51.401597  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 20:32:51.401661  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 20:32:51.401732  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:32:51.401787  1665 net.cpp:137] Memory required for data: 661914800
I0405 20:32:51.401840  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 20:32:51.401899  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 20:32:51.401966  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 20:32:51.402022  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 20:32:51.402523  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 20:32:51.402622  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:32:51.402704  1665 net.cpp:137] Memory required for data: 688129200
I0405 20:32:51.402774  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 20:32:51.402837  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 20:32:51.402894  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 20:32:51.402957  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 20:32:51.403017  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 20:32:51.403100  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 20:32:51.403173  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:32:51.403229  1665 net.cpp:137] Memory required for data: 714343600
I0405 20:32:51.403285  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 20:32:51.403344  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 20:32:51.403399  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 20:32:51.403460  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 20:32:51.403712  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 20:32:51.403810  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:32:51.403867  1665 net.cpp:137] Memory required for data: 740558000
I0405 20:32:51.403926  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:32:51.403986  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 20:32:51.404042  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 20:32:51.404100  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 20:32:51.404199  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:32:51.404363  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 20:32:51.404467  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:32:51.404526  1665 net.cpp:137] Memory required for data: 766772400
I0405 20:32:51.404583  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 20:32:51.404644  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 20:32:51.404700  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 20:32:51.404769  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 20:32:51.404829  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 20:32:51.404886  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:32:51.404953  1665 net.cpp:137] Memory required for data: 792986800
I0405 20:32:51.405010  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:32:51.405076  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:32:51.405133  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 20:32:51.405189  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:32:51.405252  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:32:51.405344  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:32:51.405406  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:32:51.405463  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:32:51.405534  1665 net.cpp:137] Memory required for data: 845415600
I0405 20:32:51.405591  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 20:32:51.405653  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 20:32:51.405710  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:32:51.405799  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 20:32:51.406687  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 20:32:51.406791  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:32:51.406850  1665 net.cpp:137] Memory required for data: 858522800
I0405 20:32:51.406914  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 20:32:51.406975  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 20:32:51.407045  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 20:32:51.407104  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 20:32:51.407325  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 20:32:51.407407  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:32:51.407465  1665 net.cpp:137] Memory required for data: 871630000
I0405 20:32:51.407526  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:32:51.407586  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 20:32:51.407644  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 20:32:51.407709  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 20:32:51.407833  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:32:51.408021  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 20:32:51.408098  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:32:51.408155  1665 net.cpp:137] Memory required for data: 884737200
I0405 20:32:51.408213  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 20:32:51.408272  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 20:32:51.408329  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 20:32:51.408409  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 20:32:51.408468  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 20:32:51.408527  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:32:51.408588  1665 net.cpp:137] Memory required for data: 897844400
I0405 20:32:51.408649  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 20:32:51.408710  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 20:32:51.408784  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 20:32:51.408843  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 20:32:51.410356  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 20:32:51.410450  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:32:51.410519  1665 net.cpp:137] Memory required for data: 910951600
I0405 20:32:51.410584  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 20:32:51.410645  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 20:32:51.410732  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:32:51.410797  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 20:32:51.411062  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 20:32:51.411159  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:32:51.411212  1665 net.cpp:137] Memory required for data: 924058800
I0405 20:32:51.411281  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 20:32:51.411366  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 20:32:51.411430  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 20:32:51.411489  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 20:32:51.411546  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 20:32:51.411628  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 20:32:51.411794  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:32:51.411860  1665 net.cpp:137] Memory required for data: 937166000
I0405 20:32:51.411932  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 20:32:51.411991  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 20:32:51.412048  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 20:32:51.412115  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 20:32:51.412330  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 20:32:51.412410  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:32:51.412467  1665 net.cpp:137] Memory required for data: 950273200
I0405 20:32:51.412530  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:32:51.412590  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 20:32:51.412647  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 20:32:51.412711  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 20:32:51.412837  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:32:51.412997  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 20:32:51.413060  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:32:51.413116  1665 net.cpp:137] Memory required for data: 963380400
I0405 20:32:51.413174  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 20:32:51.413233  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 20:32:51.413290  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 20:32:51.413348  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 20:32:51.413408  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 20:32:51.413484  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:32:51.413539  1665 net.cpp:137] Memory required for data: 976487600
I0405 20:32:51.413595  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:32:51.413661  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:32:51.413718  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 20:32:51.413779  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:32:51.413839  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:32:51.413933  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:32:51.413997  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:32:51.414054  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:32:51.414109  1665 net.cpp:137] Memory required for data: 1002702000
I0405 20:32:51.414165  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 20:32:51.414229  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 20:32:51.414288  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:32:51.414366  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 20:32:51.418113  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 20:32:51.418212  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:32:51.418269  1665 net.cpp:137] Memory required for data: 1009255600
I0405 20:32:51.418325  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 20:32:51.418385  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 20:32:51.418437  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 20:32:51.418493  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 20:32:51.418709  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 20:32:51.418797  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:32:51.418853  1665 net.cpp:137] Memory required for data: 1015809200
I0405 20:32:51.418920  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:32:51.419021  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 20:32:51.419072  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 20:32:51.419128  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 20:32:51.419226  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:32:51.419389  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 20:32:51.419528  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:32:51.419584  1665 net.cpp:137] Memory required for data: 1022362800
I0405 20:32:51.419641  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 20:32:51.419703  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 20:32:51.419775  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 20:32:51.419831  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 20:32:51.419888  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 20:32:51.419943  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:32:51.419997  1665 net.cpp:137] Memory required for data: 1028916400
I0405 20:32:51.420054  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 20:32:51.420114  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 20:32:51.420172  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 20:32:51.420229  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 20:32:51.426548  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 20:32:51.426645  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:32:51.426702  1665 net.cpp:137] Memory required for data: 1035470000
I0405 20:32:51.426762  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 20:32:51.426826  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 20:32:51.426880  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:32:51.426954  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 20:32:51.427510  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 20:32:51.427600  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:32:51.427670  1665 net.cpp:137] Memory required for data: 1042023600
I0405 20:32:51.427753  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 20:32:51.427814  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 20:32:51.427868  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 20:32:51.427932  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 20:32:51.427994  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 20:32:51.428073  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 20:32:51.428146  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:32:51.428202  1665 net.cpp:137] Memory required for data: 1048577200
I0405 20:32:51.428257  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 20:32:51.428313  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 20:32:51.428367  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 20:32:51.428427  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 20:32:51.428671  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 20:32:51.428755  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:32:51.428810  1665 net.cpp:137] Memory required for data: 1055130800
I0405 20:32:51.428866  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:32:51.428926  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 20:32:51.428982  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 20:32:51.429036  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 20:32:51.429129  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:32:51.429301  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 20:32:51.429378  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:32:51.429445  1665 net.cpp:137] Memory required for data: 1061684400
I0405 20:32:51.429508  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 20:32:51.429567  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 20:32:51.429622  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 20:32:51.429677  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 20:32:51.429754  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 20:32:51.429811  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:32:51.429864  1665 net.cpp:137] Memory required for data: 1068238000
I0405 20:32:51.429919  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:32:51.429976  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:32:51.430037  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 20:32:51.430092  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:32:51.430148  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:32:51.430248  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:32:51.430317  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:32:51.430371  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:32:51.430429  1665 net.cpp:137] Memory required for data: 1081345200
I0405 20:32:51.430483  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 20:32:51.430544  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 20:32:51.430624  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:32:51.430685  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 20:32:51.442857  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 20:32:51.442986  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:32:51.443058  1665 net.cpp:137] Memory required for data: 1084622000
I0405 20:32:51.443132  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 20:32:51.443192  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 20:32:51.443250  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 20:32:51.443320  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 20:32:51.443531  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 20:32:51.443612  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:32:51.443671  1665 net.cpp:137] Memory required for data: 1087898800
I0405 20:32:51.443758  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:32:51.443830  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 20:32:51.443889  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 20:32:51.443958  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 20:32:51.444077  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:32:51.444247  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 20:32:51.444325  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:32:51.444383  1665 net.cpp:137] Memory required for data: 1091175600
I0405 20:32:51.444440  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 20:32:51.444522  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 20:32:51.444574  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 20:32:51.444633  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 20:32:51.444701  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 20:32:51.444783  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:32:51.444835  1665 net.cpp:137] Memory required for data: 1094452400
I0405 20:32:51.444891  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 20:32:51.444954  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 20:32:51.445011  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 20:32:51.445070  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 20:32:51.468655  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 20:32:51.468783  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:32:51.468856  1665 net.cpp:137] Memory required for data: 1097729200
I0405 20:32:51.468925  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 20:32:51.469007  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 20:32:51.469065  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:32:51.469126  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 20:32:51.470422  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 20:32:51.470535  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:32:51.470600  1665 net.cpp:137] Memory required for data: 1101006000
I0405 20:32:51.470660  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 20:32:51.470723  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 20:32:51.470789  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 20:32:51.470847  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 20:32:51.470911  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 20:32:51.472750  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 20:32:51.472846  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:32:51.472923  1665 net.cpp:137] Memory required for data: 1104282800
I0405 20:32:51.472995  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 20:32:51.473057  1665 net.cpp:84] Creating Layer last_bn
I0405 20:32:51.473114  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 20:32:51.473172  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 20:32:51.473403  1665 net.cpp:122] Setting up last_bn
I0405 20:32:51.473474  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:32:51.473532  1665 net.cpp:137] Memory required for data: 1107559600
I0405 20:32:51.473601  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:32:51.473670  1665 net.cpp:84] Creating Layer last_scale
I0405 20:32:51.473747  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 20:32:51.473805  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 20:32:51.473918  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:32:51.474087  1665 net.cpp:122] Setting up last_scale
I0405 20:32:51.474174  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:32:51.474231  1665 net.cpp:137] Memory required for data: 1110836400
I0405 20:32:51.474289  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 20:32:51.474354  1665 net.cpp:84] Creating Layer last_relu
I0405 20:32:51.474412  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 20:32:51.474474  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 20:32:51.474534  1665 net.cpp:122] Setting up last_relu
I0405 20:32:51.474592  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:32:51.474648  1665 net.cpp:137] Memory required for data: 1114113200
I0405 20:32:51.474704  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 20:32:51.474789  1665 net.cpp:84] Creating Layer global_pool
I0405 20:32:51.474845  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 20:32:51.474917  1665 net.cpp:380] global_pool -> global_pool
I0405 20:32:51.474997  1665 net.cpp:122] Setting up global_pool
I0405 20:32:51.475059  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 20:32:51.475121  1665 net.cpp:137] Memory required for data: 1114318000
I0405 20:32:51.475181  1665 layer_factory.hpp:77] Creating layer score
I0405 20:32:51.475244  1665 net.cpp:84] Creating Layer score
I0405 20:32:51.475299  1665 net.cpp:406] score <- global_pool
I0405 20:32:51.475358  1665 net.cpp:380] score -> score
I0405 20:32:51.476819  1665 net.cpp:122] Setting up score
I0405 20:32:51.476917  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:32:51.476975  1665 net.cpp:137] Memory required for data: 1114718000
I0405 20:32:51.477037  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 20:32:51.477097  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 20:32:51.477157  1665 net.cpp:406] score_score_0_split <- score
I0405 20:32:51.477216  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 20:32:51.477273  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 20:32:51.477370  1665 net.cpp:122] Setting up score_score_0_split
I0405 20:32:51.477435  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:32:51.477490  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:32:51.477543  1665 net.cpp:137] Memory required for data: 1115518000
I0405 20:32:51.477597  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:32:51.477653  1665 net.cpp:84] Creating Layer loss
I0405 20:32:51.477707  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 20:32:51.477768  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 20:32:51.477823  1665 net.cpp:380] loss -> loss
I0405 20:32:51.477912  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:32:51.479176  1665 net.cpp:122] Setting up loss
I0405 20:32:51.479285  1665 net.cpp:129] Top shape: (1)
I0405 20:32:51.479351  1665 net.cpp:132]     with loss weight 1
I0405 20:32:51.479432  1665 net.cpp:137] Memory required for data: 1115518004
I0405 20:32:51.479504  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 20:32:51.479565  1665 net.cpp:84] Creating Layer accuracy
I0405 20:32:51.479621  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 20:32:51.479683  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 20:32:51.479756  1665 net.cpp:380] accuracy -> accuracy
I0405 20:32:51.479817  1665 net.cpp:122] Setting up accuracy
I0405 20:32:51.479873  1665 net.cpp:129] Top shape: (1)
I0405 20:32:51.479926  1665 net.cpp:137] Memory required for data: 1115518008
I0405 20:32:51.479987  1665 net.cpp:200] accuracy does not need backward computation.
I0405 20:32:51.480041  1665 net.cpp:198] loss needs backward computation.
I0405 20:32:51.480098  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 20:32:51.480152  1665 net.cpp:198] score needs backward computation.
I0405 20:32:51.480219  1665 net.cpp:198] global_pool needs backward computation.
I0405 20:32:51.480273  1665 net.cpp:198] last_relu needs backward computation.
I0405 20:32:51.480325  1665 net.cpp:198] last_scale needs backward computation.
I0405 20:32:51.480378  1665 net.cpp:198] last_bn needs backward computation.
I0405 20:32:51.480444  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 20:32:51.480505  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 20:32:51.480559  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 20:32:51.480613  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 20:32:51.480677  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 20:32:51.480741  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 20:32:51.480794  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 20:32:51.480849  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 20:32:51.480901  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 20:32:51.480960  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 20:32:51.481025  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 20:32:51.481079  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 20:32:51.481134  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 20:32:51.481194  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 20:32:51.481253  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 20:32:51.481307  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 20:32:51.481360  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 20:32:51.481417  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 20:32:51.481472  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 20:32:51.481643  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 20:32:51.481724  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 20:32:51.481792  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 20:32:51.481848  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 20:32:51.481902  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 20:32:51.481963  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 20:32:51.482023  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 20:32:51.482079  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 20:32:51.482132  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 20:32:51.482185  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 20:32:51.482239  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 20:32:51.482292  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 20:32:51.482347  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 20:32:51.482399  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 20:32:51.482461  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 20:32:51.482527  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 20:32:51.482578  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 20:32:51.482632  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 20:32:51.482700  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 20:32:51.482779  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 20:32:51.482833  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 20:32:51.482888  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 20:32:51.482944  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 20:32:51.482996  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 20:32:51.483050  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 20:32:51.483109  1665 net.cpp:198] conv1 needs backward computation.
I0405 20:32:51.483162  1665 net.cpp:198] data_scale needs backward computation.
I0405 20:32:51.483222  1665 net.cpp:200] data_bn does not need backward computation.
I0405 20:32:51.483286  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 20:32:51.483337  1665 net.cpp:200] data does not need backward computation.
I0405 20:32:51.483391  1665 net.cpp:242] This network produces output accuracy
I0405 20:32:51.483450  1665 net.cpp:242] This network produces output loss
I0405 20:32:51.483554  1665 net.cpp:255] Network initialization done.
I0405 20:33:32.037504  1665 solver.cpp:44] Initializing solver from parameters: 
test_iter: 0
test_interval: 469
base_lr: 0.001
display: 225
max_iter: 1800
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 1800
snapshot_prefix: "data/snapshots/train_batch_08"
solver_mode: GPU
random_seed: 0
net: "confs/sII/mid-caffeNet/inc_train_val.prototxt"
test_initialization: false
snapshot_format: HDF5
I0405 20:33:32.040585  1665 solver.cpp:87] Creating training net from net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 20:33:32.041738  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 20:33:32.041857  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 20:33:32.042003  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0405 20:33:32.042079  1665 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0405 20:33:32.042345  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/train_batch_08_filelist.txt"
    batch_size: 256
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I0405 20:33:32.042587  1665 layer_factory.hpp:77] Creating layer data
I0405 20:33:32.042651  1665 net.cpp:84] Creating Layer data
I0405 20:33:32.042698  1665 net.cpp:380] data -> data
I0405 20:33:32.042783  1665 net.cpp:380] data -> label
I0405 20:33:32.042838  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/train_batch_08_filelist.txt
I0405 20:33:32.061324  1665 image_data_layer.cpp:53] Shuffling data
I0405 20:33:32.065436  1665 image_data_layer.cpp:63] A total of 119894 images.
I0405 20:33:32.067508  1665 image_data_layer.cpp:90] output data size: 256,3,128,128
I0405 20:33:32.192771  1665 net.cpp:122] Setting up data
I0405 20:33:32.193063  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 20:33:32.193151  1665 net.cpp:129] Top shape: 256 (256)
I0405 20:33:32.193207  1665 net.cpp:137] Memory required for data: 50332672
I0405 20:33:32.193265  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 20:33:32.193331  1665 net.cpp:84] Creating Layer data_bn
I0405 20:33:32.193388  1665 net.cpp:406] data_bn <- data
I0405 20:33:32.193449  1665 net.cpp:380] data_bn -> data_bn
I0405 20:33:32.193789  1665 net.cpp:122] Setting up data_bn
I0405 20:33:32.193917  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 20:33:32.193982  1665 net.cpp:137] Memory required for data: 100664320
I0405 20:33:32.194044  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:33:32.194114  1665 net.cpp:84] Creating Layer data_scale
I0405 20:33:32.194169  1665 net.cpp:406] data_scale <- data_bn
I0405 20:33:32.194226  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 20:33:32.194303  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:33:32.194468  1665 net.cpp:122] Setting up data_scale
I0405 20:33:32.194541  1665 net.cpp:129] Top shape: 256 3 128 128 (12582912)
I0405 20:33:32.194595  1665 net.cpp:137] Memory required for data: 150995968
I0405 20:33:32.194653  1665 layer_factory.hpp:77] Creating layer conv1
I0405 20:33:32.194721  1665 net.cpp:84] Creating Layer conv1
I0405 20:33:32.194793  1665 net.cpp:406] conv1 <- data_bn
I0405 20:33:32.194852  1665 net.cpp:380] conv1 -> conv1
I0405 20:33:32.200214  1665 net.cpp:122] Setting up conv1
I0405 20:33:32.200341  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 20:33:32.200405  1665 net.cpp:137] Memory required for data: 419431424
I0405 20:33:32.200465  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 20:33:32.200525  1665 net.cpp:84] Creating Layer conv1_bn
I0405 20:33:32.200580  1665 net.cpp:406] conv1_bn <- conv1
I0405 20:33:32.200649  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 20:33:32.200860  1665 net.cpp:122] Setting up conv1_bn
I0405 20:33:32.200940  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 20:33:32.200994  1665 net.cpp:137] Memory required for data: 687866880
I0405 20:33:32.201052  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:33:32.201122  1665 net.cpp:84] Creating Layer conv1_scale
I0405 20:33:32.201174  1665 net.cpp:406] conv1_scale <- conv1
I0405 20:33:32.201234  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 20:33:32.201316  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:33:32.201443  1665 net.cpp:122] Setting up conv1_scale
I0405 20:33:32.201514  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 20:33:32.201568  1665 net.cpp:137] Memory required for data: 956302336
I0405 20:33:32.201624  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 20:33:32.201683  1665 net.cpp:84] Creating Layer conv1_relu
I0405 20:33:32.201752  1665 net.cpp:406] conv1_relu <- conv1
I0405 20:33:32.201810  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 20:33:32.201867  1665 net.cpp:122] Setting up conv1_relu
I0405 20:33:32.201937  1665 net.cpp:129] Top shape: 256 64 64 64 (67108864)
I0405 20:33:32.201992  1665 net.cpp:137] Memory required for data: 1224737792
I0405 20:33:32.202045  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 20:33:32.202101  1665 net.cpp:84] Creating Layer conv1_pool
I0405 20:33:32.202155  1665 net.cpp:406] conv1_pool <- conv1
I0405 20:33:32.202219  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 20:33:32.202301  1665 net.cpp:122] Setting up conv1_pool
I0405 20:33:32.202358  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:33:32.202411  1665 net.cpp:137] Memory required for data: 1291846656
I0405 20:33:32.202466  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 20:33:32.202523  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 20:33:32.202579  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 20:33:32.202633  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 20:33:32.202689  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 20:33:32.202766  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 20:33:32.202822  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:33:32.202877  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:33:32.202937  1665 net.cpp:137] Memory required for data: 1426064384
I0405 20:33:32.202991  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 20:33:32.203063  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 20:33:32.203117  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 20:33:32.203173  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 20:33:32.203629  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 20:33:32.203711  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:33:32.203788  1665 net.cpp:137] Memory required for data: 1493173248
I0405 20:33:32.203845  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 20:33:32.203923  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 20:33:32.203990  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 20:33:32.204056  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 20:33:32.204229  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 20:33:32.204294  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:33:32.204355  1665 net.cpp:137] Memory required for data: 1560282112
I0405 20:33:32.204409  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:33:32.204468  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 20:33:32.204522  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 20:33:32.204577  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 20:33:32.204646  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:33:32.204787  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 20:33:32.204864  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:33:32.204926  1665 net.cpp:137] Memory required for data: 1627390976
I0405 20:33:32.204983  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 20:33:32.205039  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 20:33:32.205103  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 20:33:32.205155  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 20:33:32.205210  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 20:33:32.205265  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:33:32.205319  1665 net.cpp:137] Memory required for data: 1694499840
I0405 20:33:32.205381  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 20:33:32.205446  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 20:33:32.205502  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 20:33:32.205556  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 20:33:32.206039  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 20:33:32.206104  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:33:32.206171  1665 net.cpp:137] Memory required for data: 1761608704
I0405 20:33:32.206224  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 20:33:32.206281  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 20:33:32.206342  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 20:33:32.206414  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 20:33:32.206471  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 20:33:32.206537  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 20:33:32.206614  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:33:32.206670  1665 net.cpp:137] Memory required for data: 1828717568
I0405 20:33:32.206737  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 20:33:32.206794  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 20:33:32.206848  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 20:33:32.206912  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 20:33:32.207093  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 20:33:32.207165  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:33:32.207218  1665 net.cpp:137] Memory required for data: 1895826432
I0405 20:33:32.207273  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:33:32.207330  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 20:33:32.207391  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 20:33:32.207453  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 20:33:32.207527  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:33:32.207648  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 20:33:32.207724  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:33:32.207774  1665 net.cpp:137] Memory required for data: 1962935296
I0405 20:33:32.207829  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 20:33:32.207886  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 20:33:32.207949  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 20:33:32.208005  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 20:33:32.208062  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 20:33:32.208117  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:33:32.208195  1665 net.cpp:137] Memory required for data: 2030044160
I0405 20:33:32.208246  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:33:32.208302  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:33:32.208354  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 20:33:32.208410  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:33:32.208474  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:33:32.208550  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:33:32.208607  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:33:32.208662  1665 net.cpp:129] Top shape: 256 64 32 32 (16777216)
I0405 20:33:32.208720  1665 net.cpp:137] Memory required for data: 2164261888
I0405 20:33:32.208792  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 20:33:32.208853  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 20:33:32.208914  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:33:32.208971  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 20:33:32.209702  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 20:33:32.209794  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:33:32.209849  1665 net.cpp:137] Memory required for data: 2197816320
I0405 20:33:32.209920  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 20:33:32.209978  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 20:33:32.210034  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 20:33:32.210091  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 20:33:32.210261  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 20:33:32.210320  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:33:32.210373  1665 net.cpp:137] Memory required for data: 2231370752
I0405 20:33:32.210425  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:33:32.210482  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 20:33:32.210542  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 20:33:32.210606  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 20:33:32.210680  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:33:32.210831  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 20:33:32.210914  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:33:32.210969  1665 net.cpp:137] Memory required for data: 2264925184
I0405 20:33:32.211025  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 20:33:32.211082  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 20:33:32.211138  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 20:33:32.211194  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 20:33:32.211251  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 20:33:32.211316  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:33:32.211372  1665 net.cpp:137] Memory required for data: 2298479616
I0405 20:33:32.211426  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 20:33:32.211481  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 20:33:32.211534  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 20:33:32.211591  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 20:33:32.212945  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 20:33:32.213037  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:33:32.213114  1665 net.cpp:137] Memory required for data: 2332034048
I0405 20:33:32.213176  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 20:33:32.213234  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 20:33:32.213289  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:33:32.213344  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 20:33:32.213582  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 20:33:32.213657  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:33:32.213721  1665 net.cpp:137] Memory required for data: 2365588480
I0405 20:33:32.213781  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 20:33:32.213837  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 20:33:32.213891  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 20:33:32.214047  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 20:33:32.214112  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 20:33:32.214181  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 20:33:32.214270  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:33:32.214332  1665 net.cpp:137] Memory required for data: 2399142912
I0405 20:33:32.214386  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 20:33:32.214443  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 20:33:32.214496  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 20:33:32.214561  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 20:33:32.214753  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 20:33:32.214841  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:33:32.214896  1665 net.cpp:137] Memory required for data: 2432697344
I0405 20:33:32.214968  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:33:32.215027  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 20:33:32.215082  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 20:33:32.215137  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 20:33:32.215211  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:33:32.215323  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 20:33:32.215410  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:33:32.215466  1665 net.cpp:137] Memory required for data: 2466251776
I0405 20:33:32.215520  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 20:33:32.215574  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 20:33:32.215628  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 20:33:32.215692  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 20:33:32.215768  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 20:33:32.215824  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:33:32.215879  1665 net.cpp:137] Memory required for data: 2499806208
I0405 20:33:32.215942  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:33:32.215999  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:33:32.216053  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 20:33:32.216109  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:33:32.216164  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:33:32.216235  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:33:32.216293  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:33:32.216348  1665 net.cpp:129] Top shape: 256 128 16 16 (8388608)
I0405 20:33:32.216403  1665 net.cpp:137] Memory required for data: 2566915072
I0405 20:33:32.216467  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 20:33:32.216527  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 20:33:32.216583  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:33:32.216641  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 20:33:32.220085  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 20:33:32.220191  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:33:32.220257  1665 net.cpp:137] Memory required for data: 2583692288
I0405 20:33:32.220310  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 20:33:32.220367  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 20:33:32.220429  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 20:33:32.220484  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 20:33:32.220666  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 20:33:32.220754  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:33:32.220813  1665 net.cpp:137] Memory required for data: 2600469504
I0405 20:33:32.220865  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:33:32.220927  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 20:33:32.220988  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 20:33:32.221040  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 20:33:32.221114  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:33:32.221242  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 20:33:32.221318  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:33:32.221371  1665 net.cpp:137] Memory required for data: 2617246720
I0405 20:33:32.221457  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 20:33:32.221531  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 20:33:32.221585  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 20:33:32.221637  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 20:33:32.221688  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 20:33:32.221765  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:33:32.221818  1665 net.cpp:137] Memory required for data: 2634023936
I0405 20:33:32.221870  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 20:33:32.221930  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 20:33:32.221983  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 20:33:32.222035  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 20:33:32.227882  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 20:33:32.227988  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:33:32.228063  1665 net.cpp:137] Memory required for data: 2650801152
I0405 20:33:32.228132  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 20:33:32.228205  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 20:33:32.228255  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:33:32.228315  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 20:33:32.228806  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 20:33:32.228890  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:33:32.228951  1665 net.cpp:137] Memory required for data: 2667578368
I0405 20:33:32.229013  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 20:33:32.229075  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 20:33:32.229130  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 20:33:32.229185  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 20:33:32.229240  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 20:33:32.229318  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 20:33:32.229390  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:33:32.229449  1665 net.cpp:137] Memory required for data: 2684355584
I0405 20:33:32.229516  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 20:33:32.229573  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 20:33:32.229629  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 20:33:32.229686  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 20:33:32.229959  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 20:33:32.230078  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:33:32.230145  1665 net.cpp:137] Memory required for data: 2701132800
I0405 20:33:32.230204  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:33:32.230263  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 20:33:32.230317  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 20:33:32.230373  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 20:33:32.230453  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:33:32.230579  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 20:33:32.230648  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:33:32.230703  1665 net.cpp:137] Memory required for data: 2717910016
I0405 20:33:32.230780  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 20:33:32.230844  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 20:33:32.230906  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 20:33:32.230962  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 20:33:32.231016  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 20:33:32.231072  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:33:32.231127  1665 net.cpp:137] Memory required for data: 2734687232
I0405 20:33:32.231180  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:33:32.231236  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:33:32.231292  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 20:33:32.231346  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:33:32.231402  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:33:32.231478  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:33:32.231534  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:33:32.231600  1665 net.cpp:129] Top shape: 256 256 8 8 (4194304)
I0405 20:33:32.231653  1665 net.cpp:137] Memory required for data: 2768241664
I0405 20:33:32.231705  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 20:33:32.231784  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 20:33:32.231839  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:33:32.231906  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 20:33:32.242797  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 20:33:32.242903  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:33:32.242971  1665 net.cpp:137] Memory required for data: 2776630272
I0405 20:33:32.243028  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 20:33:32.243088  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 20:33:32.243149  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 20:33:32.243206  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 20:33:32.243382  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 20:33:32.243454  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:33:32.243510  1665 net.cpp:137] Memory required for data: 2785018880
I0405 20:33:32.243568  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:33:32.243624  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 20:33:32.243680  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 20:33:32.243752  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 20:33:32.243826  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:33:32.243952  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 20:33:32.244020  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:33:32.244074  1665 net.cpp:137] Memory required for data: 2793407488
I0405 20:33:32.244129  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 20:33:32.244190  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 20:33:32.244254  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 20:33:32.244309  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 20:33:32.244364  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 20:33:32.244423  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:33:32.244487  1665 net.cpp:137] Memory required for data: 2801796096
I0405 20:33:32.244544  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 20:33:32.244607  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 20:33:32.244663  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 20:33:32.244721  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 20:33:32.266656  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 20:33:32.266782  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:33:32.266841  1665 net.cpp:137] Memory required for data: 2810184704
I0405 20:33:32.266899  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 20:33:32.266960  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 20:33:32.267016  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:33:32.267077  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 20:33:32.268290  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 20:33:32.268424  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:33:32.268486  1665 net.cpp:137] Memory required for data: 2818573312
I0405 20:33:32.268544  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 20:33:32.268602  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 20:33:32.268657  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 20:33:32.268726  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 20:33:32.268790  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 20:33:32.268882  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 20:33:32.268962  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:33:32.269017  1665 net.cpp:137] Memory required for data: 2826961920
I0405 20:33:32.269071  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 20:33:32.269129  1665 net.cpp:84] Creating Layer last_bn
I0405 20:33:32.269183  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 20:33:32.269250  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 20:33:32.269433  1665 net.cpp:122] Setting up last_bn
I0405 20:33:32.269520  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:33:32.269582  1665 net.cpp:137] Memory required for data: 2835350528
I0405 20:33:32.269639  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:33:32.269697  1665 net.cpp:84] Creating Layer last_scale
I0405 20:33:32.269757  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 20:33:32.269812  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 20:33:32.269886  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:33:32.270012  1665 net.cpp:122] Setting up last_scale
I0405 20:33:32.270087  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:33:32.270141  1665 net.cpp:137] Memory required for data: 2843739136
I0405 20:33:32.270197  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 20:33:32.270278  1665 net.cpp:84] Creating Layer last_relu
I0405 20:33:32.270332  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 20:33:32.270391  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 20:33:32.270447  1665 net.cpp:122] Setting up last_relu
I0405 20:33:32.270504  1665 net.cpp:129] Top shape: 256 512 4 4 (2097152)
I0405 20:33:32.270568  1665 net.cpp:137] Memory required for data: 2852127744
I0405 20:33:32.270630  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 20:33:32.270687  1665 net.cpp:84] Creating Layer global_pool
I0405 20:33:32.270754  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 20:33:32.270812  1665 net.cpp:380] global_pool -> global_pool
I0405 20:33:32.270881  1665 net.cpp:122] Setting up global_pool
I0405 20:33:32.270938  1665 net.cpp:129] Top shape: 256 512 1 1 (131072)
I0405 20:33:32.270999  1665 net.cpp:137] Memory required for data: 2852652032
I0405 20:33:32.271054  1665 layer_factory.hpp:77] Creating layer score
I0405 20:33:32.271111  1665 net.cpp:84] Creating Layer score
I0405 20:33:32.271165  1665 net.cpp:406] score <- global_pool
I0405 20:33:32.271232  1665 net.cpp:380] score -> score
I0405 20:33:32.272529  1665 net.cpp:122] Setting up score
I0405 20:33:32.272624  1665 net.cpp:129] Top shape: 256 1000 (256000)
I0405 20:33:32.272680  1665 net.cpp:137] Memory required for data: 2853676032
I0405 20:33:32.272753  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:33:32.272819  1665 net.cpp:84] Creating Layer loss
I0405 20:33:32.272874  1665 net.cpp:406] loss <- score
I0405 20:33:32.272930  1665 net.cpp:406] loss <- label
I0405 20:33:32.272985  1665 net.cpp:380] loss -> loss
I0405 20:33:32.273043  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:33:32.274214  1665 net.cpp:122] Setting up loss
I0405 20:33:32.274298  1665 net.cpp:129] Top shape: (1)
I0405 20:33:32.274355  1665 net.cpp:132]     with loss weight 1
I0405 20:33:32.274425  1665 net.cpp:137] Memory required for data: 2853676036
I0405 20:33:32.274478  1665 net.cpp:198] loss needs backward computation.
I0405 20:33:32.274531  1665 net.cpp:198] score needs backward computation.
I0405 20:33:32.274585  1665 net.cpp:198] global_pool needs backward computation.
I0405 20:33:32.274641  1665 net.cpp:198] last_relu needs backward computation.
I0405 20:33:32.274691  1665 net.cpp:198] last_scale needs backward computation.
I0405 20:33:32.274747  1665 net.cpp:198] last_bn needs backward computation.
I0405 20:33:32.274799  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 20:33:32.274850  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 20:33:32.274906  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 20:33:32.274958  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 20:33:32.275012  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 20:33:32.275086  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 20:33:32.275137  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 20:33:32.275192  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 20:33:32.275244  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 20:33:32.275296  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 20:33:32.275359  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 20:33:32.275429  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 20:33:32.275482  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 20:33:32.275534  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 20:33:32.275589  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 20:33:32.275641  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 20:33:32.275696  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 20:33:32.275768  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 20:33:32.275828  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 20:33:32.275882  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 20:33:32.275938  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 20:33:32.275988  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 20:33:32.276039  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 20:33:32.276090  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 20:33:32.276144  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 20:33:32.276207  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 20:33:32.276270  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 20:33:32.276322  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 20:33:32.276374  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 20:33:32.276430  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 20:33:32.276494  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 20:33:32.276556  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 20:33:32.276609  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 20:33:32.276662  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 20:33:32.276729  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 20:33:32.276789  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 20:33:32.276845  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 20:33:32.276897  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 20:33:32.276948  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 20:33:32.276999  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 20:33:32.277050  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 20:33:32.277107  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 20:33:32.277158  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 20:33:32.277221  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 20:33:32.277292  1665 net.cpp:198] conv1 needs backward computation.
I0405 20:33:32.277344  1665 net.cpp:198] data_scale needs backward computation.
I0405 20:33:32.277400  1665 net.cpp:200] data_bn does not need backward computation.
I0405 20:33:32.277453  1665 net.cpp:200] data does not need backward computation.
I0405 20:33:32.277523  1665 net.cpp:242] This network produces output loss
I0405 20:33:32.277601  1665 net.cpp:255] Network initialization done.
I0405 20:33:32.278993  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 20:33:32.279157  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 20:33:32.279219  1665 solver.cpp:172] Creating test net (#0) specified by net file: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 20:33:32.279350  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 20:33:32.279635  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 20:33:32.279893  1665 layer_factory.hpp:77] Creating layer data
I0405 20:33:32.279978  1665 net.cpp:84] Creating Layer data
I0405 20:33:32.280036  1665 net.cpp:380] data -> data
I0405 20:33:32.280092  1665 net.cpp:380] data -> label
I0405 20:33:32.280148  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 20:33:32.286265  1665 image_data_layer.cpp:53] Shuffling data
I0405 20:33:32.287340  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 20:33:32.288095  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 20:33:32.339257  1665 net.cpp:122] Setting up data
I0405 20:33:32.339460  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:33:32.339551  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:33:32.339622  1665 net.cpp:137] Memory required for data: 19661200
I0405 20:33:32.339696  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 20:33:32.339802  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 20:33:32.339871  1665 net.cpp:406] label_data_1_split <- label
I0405 20:33:32.339988  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 20:33:32.340075  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 20:33:32.340210  1665 net.cpp:122] Setting up label_data_1_split
I0405 20:33:32.340298  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:33:32.340366  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:33:32.340433  1665 net.cpp:137] Memory required for data: 19662000
I0405 20:33:32.340782  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 20:33:32.340917  1665 net.cpp:84] Creating Layer data_bn
I0405 20:33:32.340998  1665 net.cpp:406] data_bn <- data
I0405 20:33:32.341075  1665 net.cpp:380] data_bn -> data_bn
I0405 20:33:32.342711  1665 net.cpp:122] Setting up data_bn
I0405 20:33:32.342885  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:33:32.342991  1665 net.cpp:137] Memory required for data: 39322800
I0405 20:33:32.343068  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:33:32.343158  1665 net.cpp:84] Creating Layer data_scale
I0405 20:33:32.343225  1665 net.cpp:406] data_scale <- data_bn
I0405 20:33:32.343295  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 20:33:32.343430  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:33:32.343663  1665 net.cpp:122] Setting up data_scale
I0405 20:33:32.343794  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:33:32.343863  1665 net.cpp:137] Memory required for data: 58983600
I0405 20:33:32.343940  1665 layer_factory.hpp:77] Creating layer conv1
I0405 20:33:32.344018  1665 net.cpp:84] Creating Layer conv1
I0405 20:33:32.344112  1665 net.cpp:406] conv1 <- data_bn
I0405 20:33:32.344190  1665 net.cpp:380] conv1 -> conv1
I0405 20:33:32.344657  1665 net.cpp:122] Setting up conv1
I0405 20:33:32.344771  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:33:32.344842  1665 net.cpp:137] Memory required for data: 163841200
I0405 20:33:32.344925  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 20:33:32.345002  1665 net.cpp:84] Creating Layer conv1_bn
I0405 20:33:32.345073  1665 net.cpp:406] conv1_bn <- conv1
I0405 20:33:32.345142  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 20:33:32.345417  1665 net.cpp:122] Setting up conv1_bn
I0405 20:33:32.345512  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:33:32.345582  1665 net.cpp:137] Memory required for data: 268698800
I0405 20:33:32.345657  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:33:32.345746  1665 net.cpp:84] Creating Layer conv1_scale
I0405 20:33:32.345811  1665 net.cpp:406] conv1_scale <- conv1
I0405 20:33:32.345875  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 20:33:32.345996  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:33:32.346174  1665 net.cpp:122] Setting up conv1_scale
I0405 20:33:32.346274  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:33:32.346333  1665 net.cpp:137] Memory required for data: 373556400
I0405 20:33:32.346402  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 20:33:32.346469  1665 net.cpp:84] Creating Layer conv1_relu
I0405 20:33:32.346534  1665 net.cpp:406] conv1_relu <- conv1
I0405 20:33:32.346601  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 20:33:32.346666  1665 net.cpp:122] Setting up conv1_relu
I0405 20:33:32.346755  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:33:32.346818  1665 net.cpp:137] Memory required for data: 478414000
I0405 20:33:32.346884  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 20:33:32.346956  1665 net.cpp:84] Creating Layer conv1_pool
I0405 20:33:32.347018  1665 net.cpp:406] conv1_pool <- conv1
I0405 20:33:32.347081  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 20:33:32.347213  1665 net.cpp:122] Setting up conv1_pool
I0405 20:33:32.347293  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:33:32.347353  1665 net.cpp:137] Memory required for data: 504628400
I0405 20:33:32.347417  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 20:33:32.347486  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 20:33:32.347548  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 20:33:32.347615  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 20:33:32.347681  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 20:33:32.347821  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 20:33:32.347923  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:33:32.347985  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:33:32.348049  1665 net.cpp:137] Memory required for data: 557057200
I0405 20:33:32.348119  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 20:33:32.348196  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 20:33:32.348294  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 20:33:32.348364  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 20:33:32.349241  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 20:33:32.349354  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:33:32.349434  1665 net.cpp:137] Memory required for data: 583271600
I0405 20:33:32.349536  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 20:33:32.349617  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 20:33:32.349691  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 20:33:32.349794  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 20:33:32.350069  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 20:33:32.350160  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:33:32.350219  1665 net.cpp:137] Memory required for data: 609486000
I0405 20:33:32.350301  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:33:32.350373  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 20:33:32.350443  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 20:33:32.350508  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 20:33:32.350608  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:33:32.350800  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 20:33:32.350893  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:33:32.350975  1665 net.cpp:137] Memory required for data: 635700400
I0405 20:33:32.351044  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 20:33:32.351119  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 20:33:32.351187  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 20:33:32.351260  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 20:33:32.351323  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 20:33:32.351393  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:33:32.351470  1665 net.cpp:137] Memory required for data: 661914800
I0405 20:33:32.351536  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 20:33:32.351606  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 20:33:32.351692  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 20:33:32.351776  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 20:33:32.352519  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 20:33:32.352602  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:33:32.352665  1665 net.cpp:137] Memory required for data: 688129200
I0405 20:33:32.352746  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 20:33:32.352814  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 20:33:32.352877  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 20:33:32.352952  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 20:33:32.353015  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 20:33:32.353106  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 20:33:32.353175  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:33:32.353247  1665 net.cpp:137] Memory required for data: 714343600
I0405 20:33:32.353307  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 20:33:32.353374  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 20:33:32.353435  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 20:33:32.353497  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 20:33:32.353793  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 20:33:32.353893  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:33:32.353983  1665 net.cpp:137] Memory required for data: 740558000
I0405 20:33:32.354056  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:33:32.354130  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 20:33:32.354212  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 20:33:32.354291  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 20:33:32.354416  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:33:32.354605  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 20:33:32.354684  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:33:32.354763  1665 net.cpp:137] Memory required for data: 766772400
I0405 20:33:32.354837  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 20:33:32.354908  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 20:33:32.354979  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 20:33:32.355048  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 20:33:32.355118  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 20:33:32.355187  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:33:32.355257  1665 net.cpp:137] Memory required for data: 792986800
I0405 20:33:32.355324  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:33:32.355391  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:33:32.355484  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 20:33:32.355557  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:33:32.355629  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:33:32.355753  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:33:32.355825  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:33:32.355895  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:33:32.355965  1665 net.cpp:137] Memory required for data: 845415600
I0405 20:33:32.356034  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 20:33:32.356109  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 20:33:32.356178  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:33:32.356247  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 20:33:32.357477  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 20:33:32.357583  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:33:32.357659  1665 net.cpp:137] Memory required for data: 858522800
I0405 20:33:32.357753  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 20:33:32.357821  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 20:33:32.357894  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 20:33:32.357964  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 20:33:32.358222  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 20:33:32.358310  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:33:32.358386  1665 net.cpp:137] Memory required for data: 871630000
I0405 20:33:32.358459  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:33:32.358530  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 20:33:32.358611  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 20:33:32.358688  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 20:33:32.358832  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:33:32.359000  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 20:33:32.359086  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:33:32.359172  1665 net.cpp:137] Memory required for data: 884737200
I0405 20:33:32.359241  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 20:33:32.359310  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 20:33:32.359377  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 20:33:32.359441  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 20:33:32.359509  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 20:33:32.359586  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:33:32.359656  1665 net.cpp:137] Memory required for data: 897844400
I0405 20:33:32.359726  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 20:33:32.359803  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 20:33:32.359864  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 20:33:32.359936  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 20:33:32.362092  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 20:33:32.362198  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:33:32.362289  1665 net.cpp:137] Memory required for data: 910951600
I0405 20:33:32.362356  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 20:33:32.362437  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 20:33:32.362504  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:33:32.362574  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 20:33:32.363075  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 20:33:32.363224  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:33:32.363304  1665 net.cpp:137] Memory required for data: 924058800
I0405 20:33:32.363375  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 20:33:32.363443  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 20:33:32.363510  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 20:33:32.363575  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 20:33:32.363641  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 20:33:32.363770  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 20:33:32.363844  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:33:32.363929  1665 net.cpp:137] Memory required for data: 937166000
I0405 20:33:32.363994  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 20:33:32.364061  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 20:33:32.364126  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 20:33:32.364193  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 20:33:32.364457  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 20:33:32.364547  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:33:32.364614  1665 net.cpp:137] Memory required for data: 950273200
I0405 20:33:32.364686  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:33:32.364775  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 20:33:32.364843  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 20:33:32.364936  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 20:33:32.365057  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:33:32.365247  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 20:33:32.365311  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:33:32.365376  1665 net.cpp:137] Memory required for data: 963380400
I0405 20:33:32.365451  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 20:33:32.365525  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 20:33:32.365590  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 20:33:32.365661  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 20:33:32.365756  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 20:33:32.365828  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:33:32.365897  1665 net.cpp:137] Memory required for data: 976487600
I0405 20:33:32.365969  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:33:32.366042  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:33:32.366137  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 20:33:32.366200  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:33:32.366266  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:33:32.366374  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:33:32.366439  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:33:32.366500  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:33:32.366567  1665 net.cpp:137] Memory required for data: 1002702000
I0405 20:33:32.366631  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 20:33:32.366704  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 20:33:32.366792  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:33:32.366863  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 20:33:32.372056  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 20:33:32.372160  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:33:32.372225  1665 net.cpp:137] Memory required for data: 1009255600
I0405 20:33:32.372287  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 20:33:32.372372  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 20:33:32.372426  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 20:33:32.372490  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 20:33:32.372764  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 20:33:32.372846  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:33:32.372913  1665 net.cpp:137] Memory required for data: 1015809200
I0405 20:33:32.372975  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:33:32.373035  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 20:33:32.373096  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 20:33:32.373154  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 20:33:32.373250  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:33:32.373435  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 20:33:32.373497  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:33:32.373554  1665 net.cpp:137] Memory required for data: 1022362800
I0405 20:33:32.373615  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 20:33:32.373675  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 20:33:32.373751  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 20:33:32.373816  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 20:33:32.373878  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 20:33:32.373934  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:33:32.373991  1665 net.cpp:137] Memory required for data: 1028916400
I0405 20:33:32.374047  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 20:33:32.374109  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 20:33:32.374166  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 20:33:32.374224  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 20:33:32.383141  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 20:33:32.383263  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:33:32.383323  1665 net.cpp:137] Memory required for data: 1035470000
I0405 20:33:32.383383  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 20:33:32.383457  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 20:33:32.383517  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:33:32.383579  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 20:33:32.384270  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 20:33:32.384361  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:33:32.384418  1665 net.cpp:137] Memory required for data: 1042023600
I0405 20:33:32.384479  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 20:33:32.384546  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 20:33:32.384605  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 20:33:32.384670  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 20:33:32.384755  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 20:33:32.384850  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 20:33:32.384917  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:33:32.384972  1665 net.cpp:137] Memory required for data: 1048577200
I0405 20:33:32.385030  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 20:33:32.385093  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 20:33:32.385154  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 20:33:32.385224  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 20:33:32.385488  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 20:33:32.385574  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:33:32.385640  1665 net.cpp:137] Memory required for data: 1055130800
I0405 20:33:32.385709  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:33:32.385782  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 20:33:32.385859  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 20:33:32.385942  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 20:33:32.386049  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:33:32.386242  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 20:33:32.386312  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:33:32.386375  1665 net.cpp:137] Memory required for data: 1061684400
I0405 20:33:32.386440  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 20:33:32.386505  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 20:33:32.386569  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 20:33:32.386631  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 20:33:32.386695  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 20:33:32.386786  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:33:32.386845  1665 net.cpp:137] Memory required for data: 1068238000
I0405 20:33:32.386915  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:33:32.386976  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:33:32.387037  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 20:33:32.387099  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:33:32.387161  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:33:32.387264  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:33:32.387328  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:33:32.387387  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:33:32.387446  1665 net.cpp:137] Memory required for data: 1081345200
I0405 20:33:32.387503  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 20:33:32.387569  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 20:33:32.387627  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:33:32.387687  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 20:33:32.405177  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 20:33:32.405324  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:33:32.405409  1665 net.cpp:137] Memory required for data: 1084622000
I0405 20:33:32.405483  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 20:33:32.405570  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 20:33:32.405644  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 20:33:32.405709  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 20:33:32.406019  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 20:33:32.406121  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:33:32.406186  1665 net.cpp:137] Memory required for data: 1087898800
I0405 20:33:32.406258  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:33:32.406334  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 20:33:32.406394  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 20:33:32.406463  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 20:33:32.406587  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:33:32.406792  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 20:33:32.406893  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:33:32.406960  1665 net.cpp:137] Memory required for data: 1091175600
I0405 20:33:32.407028  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 20:33:32.407097  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 20:33:32.407162  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 20:33:32.407248  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 20:33:32.407317  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 20:33:32.407383  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:33:32.407454  1665 net.cpp:137] Memory required for data: 1094452400
I0405 20:33:32.407544  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 20:33:32.407613  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 20:33:32.407680  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 20:33:32.407769  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 20:33:32.441439  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 20:33:32.441570  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:33:32.441669  1665 net.cpp:137] Memory required for data: 1097729200
I0405 20:33:32.441772  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 20:33:32.441841  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 20:33:32.441900  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:33:32.441965  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 20:33:32.443935  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 20:33:32.444046  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:33:32.444118  1665 net.cpp:137] Memory required for data: 1101006000
I0405 20:33:32.444185  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 20:33:32.444254  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 20:33:32.444321  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 20:33:32.444388  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 20:33:32.444463  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 20:33:32.444553  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 20:33:32.444633  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:33:32.444700  1665 net.cpp:137] Memory required for data: 1104282800
I0405 20:33:32.444785  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 20:33:32.444854  1665 net.cpp:84] Creating Layer last_bn
I0405 20:33:32.444944  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 20:33:32.445008  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 20:33:32.445274  1665 net.cpp:122] Setting up last_bn
I0405 20:33:32.445356  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:33:32.445427  1665 net.cpp:137] Memory required for data: 1107559600
I0405 20:33:32.445498  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:33:32.445569  1665 net.cpp:84] Creating Layer last_scale
I0405 20:33:32.445634  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 20:33:32.445703  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 20:33:32.445823  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:33:32.445993  1665 net.cpp:122] Setting up last_scale
I0405 20:33:32.446070  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:33:32.446130  1665 net.cpp:137] Memory required for data: 1110836400
I0405 20:33:32.446199  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 20:33:32.446266  1665 net.cpp:84] Creating Layer last_relu
I0405 20:33:32.446332  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 20:33:32.446404  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 20:33:32.446472  1665 net.cpp:122] Setting up last_relu
I0405 20:33:32.446540  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:33:32.446605  1665 net.cpp:137] Memory required for data: 1114113200
I0405 20:33:32.446689  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 20:33:32.446755  1665 net.cpp:84] Creating Layer global_pool
I0405 20:33:32.446820  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 20:33:32.446889  1665 net.cpp:380] global_pool -> global_pool
I0405 20:33:32.446983  1665 net.cpp:122] Setting up global_pool
I0405 20:33:32.447053  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 20:33:32.447113  1665 net.cpp:137] Memory required for data: 1114318000
I0405 20:33:32.447180  1665 layer_factory.hpp:77] Creating layer score
I0405 20:33:32.447261  1665 net.cpp:84] Creating Layer score
I0405 20:33:32.447327  1665 net.cpp:406] score <- global_pool
I0405 20:33:32.447396  1665 net.cpp:380] score -> score
I0405 20:33:32.449084  1665 net.cpp:122] Setting up score
I0405 20:33:32.449172  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:33:32.449236  1665 net.cpp:137] Memory required for data: 1114718000
I0405 20:33:32.449311  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 20:33:32.449376  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 20:33:32.449443  1665 net.cpp:406] score_score_0_split <- score
I0405 20:33:32.449506  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 20:33:32.449568  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 20:33:32.449673  1665 net.cpp:122] Setting up score_score_0_split
I0405 20:33:32.449753  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:33:32.449823  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:33:32.449882  1665 net.cpp:137] Memory required for data: 1115518000
I0405 20:33:32.449944  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:33:32.450011  1665 net.cpp:84] Creating Layer loss
I0405 20:33:32.450073  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 20:33:32.450134  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 20:33:32.450197  1665 net.cpp:380] loss -> loss
I0405 20:33:32.450266  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:33:32.451699  1665 net.cpp:122] Setting up loss
I0405 20:33:32.452548  1665 net.cpp:129] Top shape: (1)
I0405 20:33:32.452610  1665 net.cpp:132]     with loss weight 1
I0405 20:33:32.452677  1665 net.cpp:137] Memory required for data: 1115518004
I0405 20:33:32.452761  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 20:33:32.452826  1665 net.cpp:84] Creating Layer accuracy
I0405 20:33:32.452891  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 20:33:32.452963  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 20:33:32.453025  1665 net.cpp:380] accuracy -> accuracy
I0405 20:33:32.453102  1665 net.cpp:122] Setting up accuracy
I0405 20:33:32.453176  1665 net.cpp:129] Top shape: (1)
I0405 20:33:32.453233  1665 net.cpp:137] Memory required for data: 1115518008
I0405 20:33:32.453289  1665 net.cpp:200] accuracy does not need backward computation.
I0405 20:33:32.453347  1665 net.cpp:198] loss needs backward computation.
I0405 20:33:32.453423  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 20:33:32.453483  1665 net.cpp:198] score needs backward computation.
I0405 20:33:32.453550  1665 net.cpp:198] global_pool needs backward computation.
I0405 20:33:32.453608  1665 net.cpp:198] last_relu needs backward computation.
I0405 20:33:32.453665  1665 net.cpp:198] last_scale needs backward computation.
I0405 20:33:32.453744  1665 net.cpp:198] last_bn needs backward computation.
I0405 20:33:32.453838  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 20:33:32.453902  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 20:33:32.453964  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 20:33:32.454026  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 20:33:32.454107  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 20:33:32.454178  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 20:33:32.454236  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 20:33:32.454294  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 20:33:32.454353  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 20:33:32.454417  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 20:33:32.454475  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 20:33:32.454533  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 20:33:32.454592  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 20:33:32.454651  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 20:33:32.454731  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 20:33:32.454793  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 20:33:32.454850  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 20:33:32.454915  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 20:33:32.454988  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 20:33:32.455049  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 20:33:32.455107  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 20:33:32.455179  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 20:33:32.455242  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 20:33:32.455303  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 20:33:32.455363  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 20:33:32.455425  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 20:33:32.455483  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 20:33:32.455541  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 20:33:32.455598  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 20:33:32.455657  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 20:33:32.455729  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 20:33:32.455806  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 20:33:32.455871  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 20:33:32.455930  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 20:33:32.455988  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 20:33:32.456051  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 20:33:32.456111  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 20:33:32.456174  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 20:33:32.456235  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 20:33:32.456295  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 20:33:32.456352  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 20:33:32.456414  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 20:33:32.456473  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 20:33:32.456530  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 20:33:32.456589  1665 net.cpp:198] conv1 needs backward computation.
I0405 20:33:32.456646  1665 net.cpp:198] data_scale needs backward computation.
I0405 20:33:32.456704  1665 net.cpp:200] data_bn does not need backward computation.
I0405 20:33:32.456774  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 20:33:32.456840  1665 net.cpp:200] data does not need backward computation.
I0405 20:33:32.456909  1665 net.cpp:242] This network produces output accuracy
I0405 20:33:32.456969  1665 net.cpp:242] This network produces output loss
I0405 20:33:32.457065  1665 net.cpp:255] Network initialization done.
I0405 20:33:32.457352  1665 solver.cpp:56] Solver scaffolding done.
I0405 20:33:32.501675  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: data/resnet10_cvgj_iter_320000.caffemodel
I0405 20:33:32.501883  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 20:33:32.983198  1665 solver.cpp:218] Iteration 0 (1.63771e-09 iter/s, 0.476954s/225 iters), loss = 12.9927
I0405 20:33:32.983395  1665 solver.cpp:237]     Train net output #0: loss = 12.9927 (* 1 = 12.9927 loss)
I0405 20:33:32.983475  1665 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I0405 20:35:11.559612  1665 solver.cpp:218] Iteration 225 (2.28248 iter/s, 98.577s/225 iters), loss = 0.796821
I0405 20:35:11.559937  1665 solver.cpp:237]     Train net output #0: loss = 0.796821 (* 1 = 0.796821 loss)
I0405 20:35:11.560011  1665 sgd_solver.cpp:105] Iteration 225, lr = 0.000875
I0405 20:36:50.133424  1665 solver.cpp:218] Iteration 450 (2.28254 iter/s, 98.5743s/225 iters), loss = 0.339613
I0405 20:36:50.133843  1665 solver.cpp:237]     Train net output #0: loss = 0.339613 (* 1 = 0.339613 loss)
I0405 20:36:50.133924  1665 sgd_solver.cpp:105] Iteration 450, lr = 0.00075
I0405 20:36:58.020424  1665 solver.cpp:330] Iteration 469, Testing net (#0)
I0405 20:38:28.705458  1665 solver.cpp:218] Iteration 675 (2.28258 iter/s, 98.5725s/225 iters), loss = 0.344782
I0405 20:38:28.705751  1665 solver.cpp:237]     Train net output #0: loss = 0.344782 (* 1 = 0.344782 loss)
I0405 20:38:28.705859  1665 sgd_solver.cpp:105] Iteration 675, lr = 0.000625
I0405 20:40:07.286041  1665 solver.cpp:218] Iteration 900 (2.28238 iter/s, 98.5812s/225 iters), loss = 0.23291
I0405 20:40:07.286356  1665 solver.cpp:237]     Train net output #0: loss = 0.23291 (* 1 = 0.23291 loss)
I0405 20:40:07.286438  1665 sgd_solver.cpp:105] Iteration 900, lr = 0.0005
I0405 20:40:23.499557  1665 solver.cpp:330] Iteration 938, Testing net (#0)
I0405 20:41:45.859961  1665 solver.cpp:218] Iteration 1125 (2.28254 iter/s, 98.5745s/225 iters), loss = 0.23043
I0405 20:41:45.860258  1665 solver.cpp:237]     Train net output #0: loss = 0.23043 (* 1 = 0.23043 loss)
I0405 20:41:45.860328  1665 sgd_solver.cpp:105] Iteration 1125, lr = 0.000375
I0405 20:43:24.420176  1665 solver.cpp:218] Iteration 1350 (2.28285 iter/s, 98.5609s/225 iters), loss = 0.139943
I0405 20:43:24.420459  1665 solver.cpp:237]     Train net output #0: loss = 0.139943 (* 1 = 0.139943 loss)
I0405 20:43:24.420536  1665 sgd_solver.cpp:105] Iteration 1350, lr = 0.00025
I0405 20:43:48.951930  1665 solver.cpp:330] Iteration 1407, Testing net (#0)
I0405 20:45:02.977630  1665 solver.cpp:218] Iteration 1575 (2.28292 iter/s, 98.5581s/225 iters), loss = 0.228481
I0405 20:45:02.977959  1665 solver.cpp:237]     Train net output #0: loss = 0.228481 (* 1 = 0.228481 loss)
I0405 20:45:02.978066  1665 sgd_solver.cpp:105] Iteration 1575, lr = 0.000125
I0405 20:46:41.107296  1665 solver.cpp:457] Snapshotting to HDF5 file data/snapshots/train_batch_08_iter_1800.caffemodel.h5
I0405 20:46:41.173262  1665 sgd_solver.cpp:283] Snapshotting solver state to HDF5 file data/snapshots/train_batch_08_iter_1800.solverstate.h5
W0405 20:46:44.272377  1665 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W0405 20:46:44.272616  1665 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W0405 20:46:44.272734  1665 _caffe.cpp:142] Net('confs/sII/mid-caffeNet/inc_train_val.prototxt', 1, weights='data/snapshots/train_batch_08_iter_1800.caffemodel.h5')
I0405 20:46:44.276501  1665 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: confs/sII/mid-caffeNet/inc_train_val.prototxt
I0405 20:46:44.276671  1665 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0405 20:46:44.276865  1665 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0405 20:46:44.277243  1665 net.cpp:51] Initializing net from parameters: 
name: "ResNet-10_CORe50_mid_CaffeNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
  }
  image_data_param {
    source: "data/sII_cum/run0/test_filelist.txt"
    batch_size: 100
    shuffle: true
    root_folder: "data/core50_128x128/"
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv2"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv2"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv2"
  bottom: "layer_512_1_conv_expand"
  top: "layer_512_1_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_1_sum"
  top: "layer_512_1_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_1_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0405 20:46:44.277567  1665 layer_factory.hpp:77] Creating layer data
I0405 20:46:44.277685  1665 net.cpp:84] Creating Layer data
I0405 20:46:44.277802  1665 net.cpp:380] data -> data
I0405 20:46:44.277878  1665 net.cpp:380] data -> label
I0405 20:46:44.277956  1665 image_data_layer.cpp:38] Opening file data/sII_cum/run0/test_filelist.txt
I0405 20:46:44.286892  1665 image_data_layer.cpp:53] Shuffling data
I0405 20:46:44.288017  1665 image_data_layer.cpp:63] A total of 44972 images.
I0405 20:46:44.289140  1665 image_data_layer.cpp:90] output data size: 100,3,128,128
I0405 20:46:44.336400  1665 net.cpp:122] Setting up data
I0405 20:46:44.336637  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:46:44.336724  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:46:44.336787  1665 net.cpp:137] Memory required for data: 19661200
I0405 20:46:44.336850  1665 layer_factory.hpp:77] Creating layer label_data_1_split
I0405 20:46:44.336918  1665 net.cpp:84] Creating Layer label_data_1_split
I0405 20:46:44.336979  1665 net.cpp:406] label_data_1_split <- label
I0405 20:46:44.337041  1665 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0405 20:46:44.337105  1665 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0405 20:46:44.337216  1665 net.cpp:122] Setting up label_data_1_split
I0405 20:46:44.337308  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:46:44.337393  1665 net.cpp:129] Top shape: 100 (100)
I0405 20:46:44.337451  1665 net.cpp:137] Memory required for data: 19662000
I0405 20:46:44.337509  1665 layer_factory.hpp:77] Creating layer data_bn
I0405 20:46:44.337574  1665 net.cpp:84] Creating Layer data_bn
I0405 20:46:44.337632  1665 net.cpp:406] data_bn <- data
I0405 20:46:44.337693  1665 net.cpp:380] data_bn -> data_bn
I0405 20:46:44.337944  1665 net.cpp:122] Setting up data_bn
I0405 20:46:44.338049  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:46:44.338111  1665 net.cpp:137] Memory required for data: 39322800
I0405 20:46:44.338203  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:46:44.338268  1665 net.cpp:84] Creating Layer data_scale
I0405 20:46:44.338328  1665 net.cpp:406] data_scale <- data_bn
I0405 20:46:44.338393  1665 net.cpp:367] data_scale -> data_bn (in-place)
I0405 20:46:44.340209  1665 layer_factory.hpp:77] Creating layer data_scale
I0405 20:46:44.340476  1665 net.cpp:122] Setting up data_scale
I0405 20:46:44.340587  1665 net.cpp:129] Top shape: 100 3 128 128 (4915200)
I0405 20:46:44.340648  1665 net.cpp:137] Memory required for data: 58983600
I0405 20:46:44.340724  1665 layer_factory.hpp:77] Creating layer conv1
I0405 20:46:44.340806  1665 net.cpp:84] Creating Layer conv1
I0405 20:46:44.340867  1665 net.cpp:406] conv1 <- data_bn
I0405 20:46:44.340927  1665 net.cpp:380] conv1 -> conv1
I0405 20:46:44.341277  1665 net.cpp:122] Setting up conv1
I0405 20:46:44.341387  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:46:44.341449  1665 net.cpp:137] Memory required for data: 163841200
I0405 20:46:44.341526  1665 layer_factory.hpp:77] Creating layer conv1_bn
I0405 20:46:44.341584  1665 net.cpp:84] Creating Layer conv1_bn
I0405 20:46:44.341645  1665 net.cpp:406] conv1_bn <- conv1
I0405 20:46:44.341706  1665 net.cpp:367] conv1_bn -> conv1 (in-place)
I0405 20:46:44.341954  1665 net.cpp:122] Setting up conv1_bn
I0405 20:46:44.342043  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:46:44.342116  1665 net.cpp:137] Memory required for data: 268698800
I0405 20:46:44.342180  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:46:44.342242  1665 net.cpp:84] Creating Layer conv1_scale
I0405 20:46:44.342300  1665 net.cpp:406] conv1_scale <- conv1
I0405 20:46:44.342377  1665 net.cpp:367] conv1_scale -> conv1 (in-place)
I0405 20:46:44.342491  1665 layer_factory.hpp:77] Creating layer conv1_scale
I0405 20:46:44.342650  1665 net.cpp:122] Setting up conv1_scale
I0405 20:46:44.342757  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:46:44.342819  1665 net.cpp:137] Memory required for data: 373556400
I0405 20:46:44.342895  1665 layer_factory.hpp:77] Creating layer conv1_relu
I0405 20:46:44.342957  1665 net.cpp:84] Creating Layer conv1_relu
I0405 20:46:44.343027  1665 net.cpp:406] conv1_relu <- conv1
I0405 20:46:44.343088  1665 net.cpp:367] conv1_relu -> conv1 (in-place)
I0405 20:46:44.343158  1665 net.cpp:122] Setting up conv1_relu
I0405 20:46:44.343219  1665 net.cpp:129] Top shape: 100 64 64 64 (26214400)
I0405 20:46:44.343276  1665 net.cpp:137] Memory required for data: 478414000
I0405 20:46:44.343333  1665 layer_factory.hpp:77] Creating layer conv1_pool
I0405 20:46:44.343418  1665 net.cpp:84] Creating Layer conv1_pool
I0405 20:46:44.343485  1665 net.cpp:406] conv1_pool <- conv1
I0405 20:46:44.343545  1665 net.cpp:380] conv1_pool -> conv1_pool
I0405 20:46:44.343644  1665 net.cpp:122] Setting up conv1_pool
I0405 20:46:44.343710  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:46:44.343786  1665 net.cpp:137] Memory required for data: 504628400
I0405 20:46:44.343855  1665 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0405 20:46:44.343926  1665 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0405 20:46:44.343984  1665 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0405 20:46:44.344054  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0405 20:46:44.344118  1665 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0405 20:46:44.344202  1665 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0405 20:46:44.344269  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:46:44.344327  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:46:44.344390  1665 net.cpp:137] Memory required for data: 557057200
I0405 20:46:44.344470  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0405 20:46:44.344535  1665 net.cpp:84] Creating Layer layer_64_1_conv1
I0405 20:46:44.344595  1665 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0405 20:46:44.344677  1665 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0405 20:46:44.345216  1665 net.cpp:122] Setting up layer_64_1_conv1
I0405 20:46:44.345314  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:46:44.345393  1665 net.cpp:137] Memory required for data: 583271600
I0405 20:46:44.345461  1665 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0405 20:46:44.345520  1665 net.cpp:84] Creating Layer layer_64_1_bn2
I0405 20:46:44.345579  1665 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0405 20:46:44.345640  1665 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0405 20:46:44.345860  1665 net.cpp:122] Setting up layer_64_1_bn2
I0405 20:46:44.345953  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:46:44.346012  1665 net.cpp:137] Memory required for data: 609486000
I0405 20:46:44.346089  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:46:44.346153  1665 net.cpp:84] Creating Layer layer_64_1_scale2
I0405 20:46:44.346230  1665 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0405 20:46:44.346294  1665 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0405 20:46:44.346395  1665 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0405 20:46:44.346561  1665 net.cpp:122] Setting up layer_64_1_scale2
I0405 20:46:44.346644  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:46:44.346702  1665 net.cpp:137] Memory required for data: 635700400
I0405 20:46:44.346776  1665 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0405 20:46:44.346853  1665 net.cpp:84] Creating Layer layer_64_1_relu2
I0405 20:46:44.346906  1665 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0405 20:46:44.346967  1665 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0405 20:46:44.347039  1665 net.cpp:122] Setting up layer_64_1_relu2
I0405 20:46:44.347100  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:46:44.347157  1665 net.cpp:137] Memory required for data: 661914800
I0405 20:46:44.347213  1665 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0405 20:46:44.347276  1665 net.cpp:84] Creating Layer layer_64_1_conv2
I0405 20:46:44.347333  1665 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0405 20:46:44.347401  1665 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0405 20:46:44.348016  1665 net.cpp:122] Setting up layer_64_1_conv2
I0405 20:46:44.348114  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:46:44.348191  1665 net.cpp:137] Memory required for data: 688129200
I0405 20:46:44.348253  1665 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0405 20:46:44.348315  1665 net.cpp:84] Creating Layer layer_64_1_sum
I0405 20:46:44.348377  1665 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0405 20:46:44.348445  1665 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0405 20:46:44.348507  1665 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0405 20:46:44.348614  1665 net.cpp:122] Setting up layer_64_1_sum
I0405 20:46:44.348685  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:46:44.348754  1665 net.cpp:137] Memory required for data: 714343600
I0405 20:46:44.348812  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0405 20:46:44.348875  1665 net.cpp:84] Creating Layer layer_128_1_bn1
I0405 20:46:44.348932  1665 net.cpp:406] layer_128_1_bn1 <- layer_64_1_sum
I0405 20:46:44.348992  1665 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0405 20:46:44.349217  1665 net.cpp:122] Setting up layer_128_1_bn1
I0405 20:46:44.349290  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:46:44.349362  1665 net.cpp:137] Memory required for data: 740558000
I0405 20:46:44.349431  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:46:44.349501  1665 net.cpp:84] Creating Layer layer_128_1_scale1
I0405 20:46:44.349561  1665 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0405 20:46:44.349622  1665 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0405 20:46:44.349735  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0405 20:46:44.349915  1665 net.cpp:122] Setting up layer_128_1_scale1
I0405 20:46:44.350021  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:46:44.350082  1665 net.cpp:137] Memory required for data: 766772400
I0405 20:46:44.350153  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0405 20:46:44.350216  1665 net.cpp:84] Creating Layer layer_128_1_relu1
I0405 20:46:44.350270  1665 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0405 20:46:44.350329  1665 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0405 20:46:44.350396  1665 net.cpp:122] Setting up layer_128_1_relu1
I0405 20:46:44.350457  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:46:44.350515  1665 net.cpp:137] Memory required for data: 792986800
I0405 20:46:44.350574  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:46:44.350636  1665 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:46:44.350693  1665 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0405 20:46:44.350775  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:46:44.350836  1665 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:46:44.350968  1665 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0405 20:46:44.351027  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:46:44.351089  1665 net.cpp:129] Top shape: 100 64 32 32 (6553600)
I0405 20:46:44.351146  1665 net.cpp:137] Memory required for data: 845415600
I0405 20:46:44.351203  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0405 20:46:44.351269  1665 net.cpp:84] Creating Layer layer_128_1_conv1
I0405 20:46:44.351326  1665 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0405 20:46:44.351403  1665 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0405 20:46:44.352296  1665 net.cpp:122] Setting up layer_128_1_conv1
I0405 20:46:44.352389  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:46:44.352452  1665 net.cpp:137] Memory required for data: 858522800
I0405 20:46:44.352517  1665 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0405 20:46:44.352586  1665 net.cpp:84] Creating Layer layer_128_1_bn2
I0405 20:46:44.352646  1665 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0405 20:46:44.352706  1665 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0405 20:46:44.352917  1665 net.cpp:122] Setting up layer_128_1_bn2
I0405 20:46:44.353026  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:46:44.353080  1665 net.cpp:137] Memory required for data: 871630000
I0405 20:46:44.353144  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:46:44.353216  1665 net.cpp:84] Creating Layer layer_128_1_scale2
I0405 20:46:44.353277  1665 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0405 20:46:44.353334  1665 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0405 20:46:44.353435  1665 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0405 20:46:44.353593  1665 net.cpp:122] Setting up layer_128_1_scale2
I0405 20:46:44.353677  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:46:44.353760  1665 net.cpp:137] Memory required for data: 884737200
I0405 20:46:44.353821  1665 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0405 20:46:44.353888  1665 net.cpp:84] Creating Layer layer_128_1_relu2
I0405 20:46:44.353947  1665 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0405 20:46:44.354009  1665 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0405 20:46:44.354069  1665 net.cpp:122] Setting up layer_128_1_relu2
I0405 20:46:44.354130  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:46:44.354187  1665 net.cpp:137] Memory required for data: 897844400
I0405 20:46:44.354243  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0405 20:46:44.354321  1665 net.cpp:84] Creating Layer layer_128_1_conv2
I0405 20:46:44.354378  1665 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0405 20:46:44.354440  1665 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0405 20:46:44.355957  1665 net.cpp:122] Setting up layer_128_1_conv2
I0405 20:46:44.356084  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:46:44.356156  1665 net.cpp:137] Memory required for data: 910951600
I0405 20:46:44.356218  1665 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0405 20:46:44.356284  1665 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0405 20:46:44.356364  1665 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0405 20:46:44.356427  1665 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0405 20:46:44.356748  1665 net.cpp:122] Setting up layer_128_1_conv_expand
I0405 20:46:44.356834  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:46:44.356902  1665 net.cpp:137] Memory required for data: 924058800
I0405 20:46:44.356962  1665 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0405 20:46:44.357023  1665 net.cpp:84] Creating Layer layer_128_1_sum
I0405 20:46:44.357082  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0405 20:46:44.357141  1665 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0405 20:46:44.357200  1665 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0405 20:46:44.357283  1665 net.cpp:122] Setting up layer_128_1_sum
I0405 20:46:44.357353  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:46:44.357414  1665 net.cpp:137] Memory required for data: 937166000
I0405 20:46:44.357479  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0405 20:46:44.357543  1665 net.cpp:84] Creating Layer layer_256_1_bn1
I0405 20:46:44.357602  1665 net.cpp:406] layer_256_1_bn1 <- layer_128_1_sum
I0405 20:46:44.357664  1665 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0405 20:46:44.357888  1665 net.cpp:122] Setting up layer_256_1_bn1
I0405 20:46:44.358021  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:46:44.358080  1665 net.cpp:137] Memory required for data: 950273200
I0405 20:46:44.358162  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:46:44.358235  1665 net.cpp:84] Creating Layer layer_256_1_scale1
I0405 20:46:44.358301  1665 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0405 20:46:44.358367  1665 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0405 20:46:44.358471  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0405 20:46:44.358618  1665 net.cpp:122] Setting up layer_256_1_scale1
I0405 20:46:44.358700  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:46:44.358793  1665 net.cpp:137] Memory required for data: 963380400
I0405 20:46:44.358853  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0405 20:46:44.358916  1665 net.cpp:84] Creating Layer layer_256_1_relu1
I0405 20:46:44.358992  1665 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0405 20:46:44.359056  1665 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0405 20:46:44.359138  1665 net.cpp:122] Setting up layer_256_1_relu1
I0405 20:46:44.359225  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:46:44.359293  1665 net.cpp:137] Memory required for data: 976487600
I0405 20:46:44.359366  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:46:44.359438  1665 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:46:44.359508  1665 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0405 20:46:44.359578  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:46:44.359671  1665 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:46:44.359792  1665 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0405 20:46:44.359874  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:46:44.359961  1665 net.cpp:129] Top shape: 100 128 16 16 (3276800)
I0405 20:46:44.360033  1665 net.cpp:137] Memory required for data: 1002702000
I0405 20:46:44.360100  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0405 20:46:44.360174  1665 net.cpp:84] Creating Layer layer_256_1_conv1
I0405 20:46:44.360246  1665 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0405 20:46:44.360318  1665 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0405 20:46:44.364132  1665 net.cpp:122] Setting up layer_256_1_conv1
I0405 20:46:44.364224  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:46:44.364284  1665 net.cpp:137] Memory required for data: 1009255600
I0405 20:46:44.364343  1665 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0405 20:46:44.364403  1665 net.cpp:84] Creating Layer layer_256_1_bn2
I0405 20:46:44.364460  1665 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0405 20:46:44.364519  1665 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0405 20:46:44.364740  1665 net.cpp:122] Setting up layer_256_1_bn2
I0405 20:46:44.364825  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:46:44.364886  1665 net.cpp:137] Memory required for data: 1015809200
I0405 20:46:44.364948  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:46:44.365010  1665 net.cpp:84] Creating Layer layer_256_1_scale2
I0405 20:46:44.365064  1665 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0405 20:46:44.365121  1665 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0405 20:46:44.365219  1665 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0405 20:46:44.365393  1665 net.cpp:122] Setting up layer_256_1_scale2
I0405 20:46:44.365460  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:46:44.365516  1665 net.cpp:137] Memory required for data: 1022362800
I0405 20:46:44.365594  1665 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0405 20:46:44.365656  1665 net.cpp:84] Creating Layer layer_256_1_relu2
I0405 20:46:44.365731  1665 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0405 20:46:44.365794  1665 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0405 20:46:44.365859  1665 net.cpp:122] Setting up layer_256_1_relu2
I0405 20:46:44.365921  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:46:44.365975  1665 net.cpp:137] Memory required for data: 1028916400
I0405 20:46:44.366030  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0405 20:46:44.366091  1665 net.cpp:84] Creating Layer layer_256_1_conv2
I0405 20:46:44.366173  1665 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0405 20:46:44.366232  1665 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0405 20:46:44.372445  1665 net.cpp:122] Setting up layer_256_1_conv2
I0405 20:46:44.372555  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:46:44.372622  1665 net.cpp:137] Memory required for data: 1035470000
I0405 20:46:44.372699  1665 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0405 20:46:44.372793  1665 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0405 20:46:44.372859  1665 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0405 20:46:44.372918  1665 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0405 20:46:44.373404  1665 net.cpp:122] Setting up layer_256_1_conv_expand
I0405 20:46:44.373478  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:46:44.373553  1665 net.cpp:137] Memory required for data: 1042023600
I0405 20:46:44.373621  1665 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0405 20:46:44.373684  1665 net.cpp:84] Creating Layer layer_256_1_sum
I0405 20:46:44.373754  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0405 20:46:44.373816  1665 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0405 20:46:44.373883  1665 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0405 20:46:44.373968  1665 net.cpp:122] Setting up layer_256_1_sum
I0405 20:46:44.374049  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:46:44.374115  1665 net.cpp:137] Memory required for data: 1048577200
I0405 20:46:44.374174  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0405 20:46:44.374236  1665 net.cpp:84] Creating Layer layer_512_1_bn1
I0405 20:46:44.374298  1665 net.cpp:406] layer_512_1_bn1 <- layer_256_1_sum
I0405 20:46:44.374369  1665 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0405 20:46:44.374573  1665 net.cpp:122] Setting up layer_512_1_bn1
I0405 20:46:44.374661  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:46:44.374724  1665 net.cpp:137] Memory required for data: 1055130800
I0405 20:46:44.374786  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:46:44.374852  1665 net.cpp:84] Creating Layer layer_512_1_scale1
I0405 20:46:44.374917  1665 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0405 20:46:44.374977  1665 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0405 20:46:44.375080  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0405 20:46:44.375233  1665 net.cpp:122] Setting up layer_512_1_scale1
I0405 20:46:44.375319  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:46:44.375375  1665 net.cpp:137] Memory required for data: 1061684400
I0405 20:46:44.375437  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0405 20:46:44.375500  1665 net.cpp:84] Creating Layer layer_512_1_relu1
I0405 20:46:44.375560  1665 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0405 20:46:44.375630  1665 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0405 20:46:44.375691  1665 net.cpp:122] Setting up layer_512_1_relu1
I0405 20:46:44.375766  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:46:44.375830  1665 net.cpp:137] Memory required for data: 1068238000
I0405 20:46:44.375895  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:46:44.375955  1665 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:46:44.376013  1665 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0405 20:46:44.376073  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:46:44.376133  1665 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:46:44.376238  1665 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0405 20:46:44.376303  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:46:44.376379  1665 net.cpp:129] Top shape: 100 256 8 8 (1638400)
I0405 20:46:44.376435  1665 net.cpp:137] Memory required for data: 1081345200
I0405 20:46:44.376492  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0405 20:46:44.376565  1665 net.cpp:84] Creating Layer layer_512_1_conv1
I0405 20:46:44.376633  1665 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0405 20:46:44.376694  1665 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0405 20:46:44.388872  1665 net.cpp:122] Setting up layer_512_1_conv1
I0405 20:46:44.388962  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:46:44.389036  1665 net.cpp:137] Memory required for data: 1084622000
I0405 20:46:44.389098  1665 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0405 20:46:44.389161  1665 net.cpp:84] Creating Layer layer_512_1_bn2
I0405 20:46:44.389238  1665 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0405 20:46:44.389312  1665 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0405 20:46:44.389523  1665 net.cpp:122] Setting up layer_512_1_bn2
I0405 20:46:44.389603  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:46:44.389664  1665 net.cpp:137] Memory required for data: 1087898800
I0405 20:46:44.389773  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:46:44.389854  1665 net.cpp:84] Creating Layer layer_512_1_scale2
I0405 20:46:44.389914  1665 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0405 20:46:44.389976  1665 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0405 20:46:44.390074  1665 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0405 20:46:44.390249  1665 net.cpp:122] Setting up layer_512_1_scale2
I0405 20:46:44.390332  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:46:44.390406  1665 net.cpp:137] Memory required for data: 1091175600
I0405 20:46:44.390470  1665 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0405 20:46:44.390532  1665 net.cpp:84] Creating Layer layer_512_1_relu2
I0405 20:46:44.390594  1665 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0405 20:46:44.390658  1665 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0405 20:46:44.390722  1665 net.cpp:122] Setting up layer_512_1_relu2
I0405 20:46:44.390781  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:46:44.390843  1665 net.cpp:137] Memory required for data: 1094452400
I0405 20:46:44.390902  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0405 20:46:44.390965  1665 net.cpp:84] Creating Layer layer_512_1_conv2
I0405 20:46:44.391022  1665 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0405 20:46:44.391083  1665 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0405 20:46:44.416492  1665 net.cpp:122] Setting up layer_512_1_conv2
I0405 20:46:44.416672  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:46:44.416793  1665 net.cpp:137] Memory required for data: 1097729200
I0405 20:46:44.416878  1665 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0405 20:46:44.416965  1665 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0405 20:46:44.417052  1665 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0405 20:46:44.417126  1665 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0405 20:46:44.418618  1665 net.cpp:122] Setting up layer_512_1_conv_expand
I0405 20:46:44.418756  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:46:44.418843  1665 net.cpp:137] Memory required for data: 1101006000
I0405 20:46:44.418936  1665 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0405 20:46:44.419013  1665 net.cpp:84] Creating Layer layer_512_1_sum
I0405 20:46:44.419103  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0405 20:46:44.419346  1665 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0405 20:46:44.419570  1665 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0405 20:46:44.419695  1665 net.cpp:122] Setting up layer_512_1_sum
I0405 20:46:44.419795  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:46:44.419876  1665 net.cpp:137] Memory required for data: 1104282800
I0405 20:46:44.419946  1665 layer_factory.hpp:77] Creating layer last_bn
I0405 20:46:44.420019  1665 net.cpp:84] Creating Layer last_bn
I0405 20:46:44.420090  1665 net.cpp:406] last_bn <- layer_512_1_sum
I0405 20:46:44.420182  1665 net.cpp:367] last_bn -> layer_512_1_sum (in-place)
I0405 20:46:44.420444  1665 net.cpp:122] Setting up last_bn
I0405 20:46:44.420547  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:46:44.420619  1665 net.cpp:137] Memory required for data: 1107559600
I0405 20:46:44.420692  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:46:44.420783  1665 net.cpp:84] Creating Layer last_scale
I0405 20:46:44.420852  1665 net.cpp:406] last_scale <- layer_512_1_sum
I0405 20:46:44.420922  1665 net.cpp:367] last_scale -> layer_512_1_sum (in-place)
I0405 20:46:44.423132  1665 layer_factory.hpp:77] Creating layer last_scale
I0405 20:46:44.423389  1665 net.cpp:122] Setting up last_scale
I0405 20:46:44.423537  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:46:44.423624  1665 net.cpp:137] Memory required for data: 1110836400
I0405 20:46:44.423699  1665 layer_factory.hpp:77] Creating layer last_relu
I0405 20:46:44.423801  1665 net.cpp:84] Creating Layer last_relu
I0405 20:46:44.423913  1665 net.cpp:406] last_relu <- layer_512_1_sum
I0405 20:46:44.423985  1665 net.cpp:367] last_relu -> layer_512_1_sum (in-place)
I0405 20:46:44.424058  1665 net.cpp:122] Setting up last_relu
I0405 20:46:44.424136  1665 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0405 20:46:44.424206  1665 net.cpp:137] Memory required for data: 1114113200
I0405 20:46:44.424276  1665 layer_factory.hpp:77] Creating layer global_pool
I0405 20:46:44.424355  1665 net.cpp:84] Creating Layer global_pool
I0405 20:46:44.424427  1665 net.cpp:406] global_pool <- layer_512_1_sum
I0405 20:46:44.424497  1665 net.cpp:380] global_pool -> global_pool
I0405 20:46:44.424602  1665 net.cpp:122] Setting up global_pool
I0405 20:46:44.424700  1665 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0405 20:46:44.424808  1665 net.cpp:137] Memory required for data: 1114318000
I0405 20:46:44.424885  1665 layer_factory.hpp:77] Creating layer score
I0405 20:46:44.424959  1665 net.cpp:84] Creating Layer score
I0405 20:46:44.425031  1665 net.cpp:406] score <- global_pool
I0405 20:46:44.425107  1665 net.cpp:380] score -> score
I0405 20:46:44.426627  1665 net.cpp:122] Setting up score
I0405 20:46:44.426764  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:46:44.426895  1665 net.cpp:137] Memory required for data: 1114718000
I0405 20:46:44.426987  1665 layer_factory.hpp:77] Creating layer score_score_0_split
I0405 20:46:44.427058  1665 net.cpp:84] Creating Layer score_score_0_split
I0405 20:46:44.427127  1665 net.cpp:406] score_score_0_split <- score
I0405 20:46:44.427196  1665 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0405 20:46:44.427264  1665 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0405 20:46:44.427381  1665 net.cpp:122] Setting up score_score_0_split
I0405 20:46:44.427474  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:46:44.427543  1665 net.cpp:129] Top shape: 100 1000 (100000)
I0405 20:46:44.427609  1665 net.cpp:137] Memory required for data: 1115518000
I0405 20:46:44.427690  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:46:44.427783  1665 net.cpp:84] Creating Layer loss
I0405 20:46:44.427851  1665 net.cpp:406] loss <- score_score_0_split_0
I0405 20:46:44.427932  1665 net.cpp:406] loss <- label_data_1_split_0
I0405 20:46:44.428006  1665 net.cpp:380] loss -> loss
I0405 20:46:44.428078  1665 layer_factory.hpp:77] Creating layer loss
I0405 20:46:44.429473  1665 net.cpp:122] Setting up loss
I0405 20:46:44.429606  1665 net.cpp:129] Top shape: (1)
I0405 20:46:44.429677  1665 net.cpp:132]     with loss weight 1
I0405 20:46:44.429790  1665 net.cpp:137] Memory required for data: 1115518004
I0405 20:46:44.429864  1665 layer_factory.hpp:77] Creating layer accuracy
I0405 20:46:44.429936  1665 net.cpp:84] Creating Layer accuracy
I0405 20:46:44.430004  1665 net.cpp:406] accuracy <- score_score_0_split_1
I0405 20:46:44.430073  1665 net.cpp:406] accuracy <- label_data_1_split_1
I0405 20:46:44.430140  1665 net.cpp:380] accuracy -> accuracy
I0405 20:46:44.430217  1665 net.cpp:122] Setting up accuracy
I0405 20:46:44.430305  1665 net.cpp:129] Top shape: (1)
I0405 20:46:44.430371  1665 net.cpp:137] Memory required for data: 1115518008
I0405 20:46:44.430438  1665 net.cpp:200] accuracy does not need backward computation.
I0405 20:46:44.430512  1665 net.cpp:198] loss needs backward computation.
I0405 20:46:44.430584  1665 net.cpp:198] score_score_0_split needs backward computation.
I0405 20:46:44.430651  1665 net.cpp:198] score needs backward computation.
I0405 20:46:44.430727  1665 net.cpp:198] global_pool needs backward computation.
I0405 20:46:44.430795  1665 net.cpp:198] last_relu needs backward computation.
I0405 20:46:44.430867  1665 net.cpp:198] last_scale needs backward computation.
I0405 20:46:44.430936  1665 net.cpp:198] last_bn needs backward computation.
I0405 20:46:44.431001  1665 net.cpp:198] layer_512_1_sum needs backward computation.
I0405 20:46:44.431068  1665 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0405 20:46:44.431140  1665 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0405 20:46:44.431221  1665 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0405 20:46:44.431285  1665 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0405 20:46:44.431355  1665 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0405 20:46:44.431442  1665 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0405 20:46:44.431516  1665 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0405 20:46:44.431581  1665 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0405 20:46:44.431648  1665 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0405 20:46:44.431742  1665 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0405 20:46:44.431819  1665 net.cpp:198] layer_256_1_sum needs backward computation.
I0405 20:46:44.431881  1665 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0405 20:46:44.431938  1665 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0405 20:46:44.431994  1665 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0405 20:46:44.432051  1665 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0405 20:46:44.432114  1665 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0405 20:46:44.432170  1665 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0405 20:46:44.432229  1665 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0405 20:46:44.432292  1665 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0405 20:46:44.432354  1665 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0405 20:46:44.432411  1665 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0405 20:46:44.432468  1665 net.cpp:198] layer_128_1_sum needs backward computation.
I0405 20:46:44.432524  1665 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0405 20:46:44.432581  1665 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0405 20:46:44.432637  1665 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0405 20:46:44.432693  1665 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0405 20:46:44.432762  1665 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0405 20:46:44.432819  1665 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0405 20:46:44.432890  1665 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0405 20:46:44.432948  1665 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0405 20:46:44.433004  1665 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0405 20:46:44.433068  1665 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0405 20:46:44.433130  1665 net.cpp:198] layer_64_1_sum needs backward computation.
I0405 20:46:44.433187  1665 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0405 20:46:44.433243  1665 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0405 20:46:44.433300  1665 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0405 20:46:44.433357  1665 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0405 20:46:44.433413  1665 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0405 20:46:44.433468  1665 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0405 20:46:44.433524  1665 net.cpp:198] conv1_pool needs backward computation.
I0405 20:46:44.433580  1665 net.cpp:198] conv1_relu needs backward computation.
I0405 20:46:44.433655  1665 net.cpp:198] conv1_scale needs backward computation.
I0405 20:46:44.433712  1665 net.cpp:198] conv1_bn needs backward computation.
I0405 20:46:44.433789  1665 net.cpp:198] conv1 needs backward computation.
I0405 20:46:44.433858  1665 net.cpp:198] data_scale needs backward computation.
I0405 20:46:44.433921  1665 net.cpp:200] data_bn does not need backward computation.
I0405 20:46:44.433980  1665 net.cpp:200] label_data_1_split does not need backward computation.
I0405 20:46:44.434036  1665 net.cpp:200] data does not need backward computation.
I0405 20:46:44.434092  1665 net.cpp:242] This network produces output accuracy
I0405 20:46:44.434149  1665 net.cpp:242] This network produces output loss
I0405 20:46:44.434238  1665 net.cpp:255] Network initialization done.
I0405 20:47:19.121835  1665 blocking_queue.cpp:49] Waiting for data
/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
INFO - core50 incremental finetuning - Completed after 2:04:51
